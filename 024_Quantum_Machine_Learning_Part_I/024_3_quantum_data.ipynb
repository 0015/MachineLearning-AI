{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLOXFOT5Q40E"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iiQkM5ZgQ8r2"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6331ZSsQGY3"
      },
      "source": [
        "# Quantum data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Jcnb8bQQyd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/quantum/tutorials/quantum_data\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/quantum/blob/master/docs/tutorials/quantum_data.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/quantum_data.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/quantum/docs/tutorials/quantum_data.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2HoEn9BEWfn"
      },
      "source": [
        "Building off of the comparisons made in the [MNIST](https://www.tensorflow.org/quantum/tutorials/mnist) tutorial, this tutorial explores the recent work of [Huang et al.](https://arxiv.org/abs/2011.01938) that shows how different datasets affect performance comparisons. In the work, the authors seek to understand how and when classical machine learning models can learn as well as (or better than) quantum models. The work also showcases an empirical performance separation between classical and quantum machine learning model via a carefully crafted dataset. You will:\n",
        "\n",
        "1.   Prepare a reduced dimension Fashion-MNIST dataset.\n",
        "2.   Use quantum circuits to re-label the dataset and compute Projected Quantum Kernel features (PQK).\n",
        "3.   Train a classical neural network on the re-labeled dataset and compare the performance with a model that has access to the PQK features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQvswYv7LAaU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X3Y5vLL9K_Ai",
        "outputId": "b02197d8-ac44-46a4-c732-6bff622448fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 10 kB/s \n",
            "\u001b[?25hCollecting tensorflow-quantum\n",
            "  Downloading tensorflow_quantum-0.5.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 18.5 MB/s \n",
            "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.1)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 35.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 37.7 MB/s \n",
            "\u001b[?25hCollecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.7.0)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
            "Collecting google-api-core==1.21.0\n",
            "  Downloading google_api_core-1.21.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting googleapis-common-protos==1.52.0\n",
            "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.9.2\n",
            "  Downloading protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 39.5 MB/s \n",
            "\u001b[?25hCollecting cirq==0.11.0\n",
            "  Downloading cirq-0.11.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-1.18.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting sympy==1.5\n",
            "  Downloading sympy-1.5-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 16.7 MB/s \n",
            "\u001b[?25hCollecting cirq-google==0.11.0\n",
            "  Downloading cirq_google-0.11.0-py3-none-any.whl (380 kB)\n",
            "\u001b[K     |████████████████████████████████| 380 kB 52.1 MB/s \n",
            "\u001b[?25hCollecting cirq-core==0.11.0\n",
            "  Downloading cirq_core-0.11.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 68.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.11.0->cirq==0.11.0->tensorflow-quantum) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.11.0->cirq==0.11.0->tensorflow-quantum) (1.1.5)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.11.0->cirq==0.11.0->tensorflow-quantum) (2.4.0)\n",
            "Requirement already satisfied: networkx~=2.4 in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.11.0->cirq==0.11.0->tensorflow-quantum) (2.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.11.0->cirq==0.11.0->tensorflow-quantum) (4.62.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.11.0->cirq==0.11.0->tensorflow-quantum) (3.2.2)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from cirq-google==0.11.0->cirq==0.11.0->tensorflow-quantum) (1.26.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (2018.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy==1.5->tensorflow-quantum) (1.2.1)\n",
            "Collecting google-api-core[grpc]<2.0.0dev,>=1.14.0\n",
            "  Downloading google_api_core-1.31.5-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.4 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.4-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.3 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.3-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.4 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.2-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.3 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.1-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.2 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 932 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.30.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.1 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.29.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.0 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.28.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 1.0 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.27.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.2 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.2-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 722 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 886 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 880 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.25.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 203 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.25.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 158 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.24.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 9.7 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.24.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 8.2 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.23.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 9.3 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.4-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 10.0 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.3-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 7.9 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.2-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 7.7 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.1-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 9.1 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tensorflow-quantum) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tensorflow-quantum) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tensorflow-quantum) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tensorflow-quantum) (0.11.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68719 sha256=34059c65aa88d8b155e3f618e1943a71eb6cb30fede602493611ff5875559895\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: protobuf, googleapis-common-protos, google-auth, typing-extensions, sympy, grpcio, google-api-core, cirq-core, cirq-google, absl-py, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, cirq, tensorflow-quantum, tensorflow\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.54.0\n",
            "    Uninstalling googleapis-common-protos-1.54.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.54.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 1.35.0\n",
            "    Uninstalling google-auth-1.35.0:\n",
            "      Successfully uninstalled google-auth-1.35.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.7.1\n",
            "    Uninstalling sympy-1.7.1:\n",
            "      Successfully uninstalled sympy-1.7.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.43.0\n",
            "    Uninstalling grpcio-1.43.0:\n",
            "      Successfully uninstalled grpcio-1.43.0\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 1.26.3\n",
            "    Uninstalling google-api-core-1.26.3:\n",
            "      Successfully uninstalled google-api-core-1.26.3\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydata-google-auth 1.3.0 requires google-auth<3.0dev,>=1.25.0; python_version >= \"3.6\", but you have google-auth 1.18.0 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 cirq-0.11.0 cirq-core-0.11.0 cirq-google-0.11.0 flatbuffers-1.12 gast-0.3.3 google-api-core-1.21.0 google-auth-1.18.0 googleapis-common-protos-1.52.0 grpcio-1.32.0 h5py-2.10.0 protobuf-3.13.0 sympy-1.5 tensorflow-2.4.1 tensorflow-estimator-2.4.0 tensorflow-quantum-0.5.1 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow==2.4.1 tensorflow-quantum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Ql5PW-ACO0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae559c9-ae12-4ea5-dcc0-907276fbfc5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'pkg_resources' from '/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Update package resources to account for version changes.\n",
        "import importlib, pkg_resources\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FTKfetslL5eE"
      },
      "outputs": [],
      "source": [
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCOHgdILONs-"
      },
      "source": [
        "## 1. Data preparation\n",
        "\n",
        "You will begin by preparing the fashion-MNIST dataset for running on a quantum computer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDl61cN6WPDk"
      },
      "source": [
        "### 1.1 Download fashion-MNIST\n",
        "\n",
        "The first step is to get the traditional fashion-mnist dataset. This can be done using the `tf.keras.datasets` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTKmzeH3MBvR",
        "outputId": "72b9da0b-5476-42b7-c977-25357d7b3c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Number of original training examples: 60000\n",
            "Number of original test examples: 10000\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "print(\"Number of original training examples:\", len(x_train))\n",
        "print(\"Number of original test examples:\", len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq3eeFv2PyQz"
      },
      "source": [
        "Filter the dataset to keep just the T-shirts/tops and dresses, remove the other classes. At the same time convert the label, `y`, to boolean: True for 0 and False for 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LmprnNbDP4Z6"
      },
      "outputs": [],
      "source": [
        "def filter_03(x, y):\n",
        "    keep = (y == 0) | (y == 3)\n",
        "    x, y = x[keep], y[keep]\n",
        "    y = y == 0\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KycvXPllQH-t",
        "outputId": "041a4cf0-48f0-4cca-ce15-52c11a992af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of filtered training examples: 12000\n",
            "Number of filtered test examples: 2000\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = filter_03(x_train, y_train)\n",
        "x_test, y_test = filter_03(x_test, y_test)\n",
        "\n",
        "print(\"Number of filtered training examples:\", len(x_train))\n",
        "print(\"Number of filtered test examples:\", len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "c-2Fx9E1O63h",
        "outputId": "da555b89-b928-4f6c-ee7a-9ad0209ad668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f6043364f50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(y_train[0])\n",
        "\n",
        "plt.imshow(x_train[0, :, :])\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ASbMvu6SFST"
      },
      "source": [
        "### 1.2 Downscale the images\n",
        "\n",
        "Just like the MNIST example, you will need to downscale these images in order to be within the boundaries for current quantum computers. This time however you will use a PCA transformation to reduce the dimensions instead of a `tf.image.resize` operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0_EvK2kJPKDk"
      },
      "outputs": [],
      "source": [
        "def truncate_x(x_train, x_test, n_components=10):\n",
        "  \"\"\"Perform PCA on image dataset keeping the top `n_components` components.\"\"\"\n",
        "  n_points_train = tf.gather(tf.shape(x_train), 0)\n",
        "  n_points_test = tf.gather(tf.shape(x_test), 0)\n",
        "\n",
        "  # Flatten to 1D\n",
        "  x_train = tf.reshape(x_train, [n_points_train, -1])\n",
        "  x_test = tf.reshape(x_test, [n_points_test, -1])\n",
        "\n",
        "  # Normalize.\n",
        "  feature_mean = tf.reduce_mean(x_train, axis=0)\n",
        "  x_train_normalized = x_train - feature_mean\n",
        "  x_test_normalized = x_test - feature_mean\n",
        "\n",
        "  # Truncate.\n",
        "  e_values, e_vectors = tf.linalg.eigh(\n",
        "      tf.einsum('ji,jk->ik', x_train_normalized, x_train_normalized))\n",
        "  return tf.einsum('ij,jk->ik', x_train_normalized, e_vectors[:,-n_components:]), \\\n",
        "    tf.einsum('ij,jk->ik', x_test_normalized, e_vectors[:, -n_components:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WhtP5RRkYSI",
        "outputId": "538fd0a9-67ca-4db3-d2b6-3ebeede20115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New datapoint dimension: 10\n"
          ]
        }
      ],
      "source": [
        "DATASET_DIM = 10\n",
        "x_train, x_test = truncate_x(x_train, x_test, n_components=DATASET_DIM)\n",
        "print(f'New datapoint dimension:', len(x_train[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXAEeE50FS9G"
      },
      "source": [
        "The last step is to reduce the size of the dataset to just 1000 training datapoints and 200 testing datapoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EMxlW2kZDtvn"
      },
      "outputs": [],
      "source": [
        "N_TRAIN = 1000\n",
        "N_TEST = 200\n",
        "x_train, x_test = x_train[:N_TRAIN], x_test[:N_TEST]\n",
        "y_train, y_test = y_train[:N_TRAIN], y_test[:N_TEST]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7vqUjDMGF2S",
        "outputId": "582d8f50-687d-48d4-9d49-aff97308246a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New number of training examples: 1000\n",
            "New number of test examples: 200\n"
          ]
        }
      ],
      "source": [
        "print(\"New number of training examples:\", len(x_train))\n",
        "print(\"New number of test examples:\", len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-26obVJtHQne"
      },
      "source": [
        "## 2. Relabeling and computing PQK features\n",
        "\n",
        "You will now prepare a \"stilted\" quantum dataset by incorporating quantum components and re-labeling the truncated fashion-MNIST dataset you've created above. In order to get the most seperation between quantum and classical methods, you will first prepare the PQK features and then relabel outputs based on their values. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJEK8CwKWgC2"
      },
      "source": [
        "### 2.1 Quantum encoding and PQK features\n",
        "You will create a new set of features, based on `x_train`, `y_train`, `x_test` and `y_test` that is defined to be the 1-RDM on all qubits of: \n",
        "\n",
        "$V(x_{\\text{train}} / n_{\\text{trotter}}) ^ {n_{\\text{trotter}}} U_{\\text{1qb}} | 0 \\rangle$\n",
        "\n",
        "Where $U_\\text{1qb}$ is a wall of single qubit rotations and $V(\\hat{\\theta}) = e^{-i\\sum_i \\hat{\\theta_i} (X_i X_{i+1} + Y_i Y_{i+1} + Z_i Z_{i+1})}$\n",
        "\n",
        "First, you can generate the wall of single qubit rotations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hVTlHdGvEuaT"
      },
      "outputs": [],
      "source": [
        "def single_qubit_wall(qubits, rotations):\n",
        "  \"\"\"Prepare a single qubit X,Y,Z rotation wall on `qubits`.\"\"\"\n",
        "  wall_circuit = cirq.Circuit()\n",
        "  for i, qubit in enumerate(qubits):\n",
        "    for j, gate in enumerate([cirq.X, cirq.Y, cirq.Z]):\n",
        "      wall_circuit.append(gate(qubit) ** rotations[i][j])\n",
        "\n",
        "  return wall_circuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCfFcs-nGFH5"
      },
      "source": [
        "You can quickly verify this works by looking at the circuit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "tfJkWj88Fqwl",
        "outputId": "d82dfa49-e02c-406e-9e5a-0f26e7efe75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7f60433347d0>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"393.80875000000003\" height=\"200.0\"><line x1=\"34.7588671875\" x2=\"363.80875000000003\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"363.80875000000003\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"363.80875000000003\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"363.80875000000003\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"105.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 2): </text><rect x=\"10.0\" y=\"155.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 3): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"80.97015625000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.0028125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^0.192</text><rect x=\"79.517734375\" y=\"55.0\" width=\"80.97015625000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.0028125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^(11/14)</text><rect x=\"79.517734375\" y=\"105.0\" width=\"80.97015625000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.0028125\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^0.276</text><rect x=\"79.517734375\" y=\"155.0\" width=\"80.97015625000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.0028125\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^0.876</text><rect x=\"180.48789062500003\" y=\"5.0\" width=\"71.47011718750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"216.22294921875005\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Y^0.622</text><rect x=\"180.48789062500003\" y=\"55.0\" width=\"71.47011718750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"216.22294921875005\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Y^0.78</text><rect x=\"180.48789062500003\" y=\"105.0\" width=\"71.47011718750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"216.22294921875005\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Y^0.802</text><rect x=\"180.48789062500003\" y=\"155.0\" width=\"71.47011718750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"216.22294921875005\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Y^(5/14)</text><rect x=\"271.95800781250006\" y=\"5.0\" width=\"71.8507421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"307.8833789062501\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Z^(7/16)</text><rect x=\"271.95800781250006\" y=\"55.0\" width=\"71.8507421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"307.8833789062501\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Z^(3/11)</text><rect x=\"271.95800781250006\" y=\"105.0\" width=\"71.8507421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"307.8833789062501\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Z^0.958</text><rect x=\"271.95800781250006\" y=\"155.0\" width=\"71.8507421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"307.8833789062501\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Z^0.501</text></svg>"
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "SVGCircuit(single_qubit_wall(\n",
        "    cirq.GridQubit.rect(1,4), np.random.uniform(size=(4, 3))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPniCQWnHGXz"
      },
      "source": [
        "Next you can prepare $V(\\hat{\\theta})$ with the help of `tfq.util.exponential` which can exponentiate any commuting `cirq.PauliSum` objects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4w2em6c0HOIO"
      },
      "outputs": [],
      "source": [
        "def v_theta(qubits):\n",
        "  \"\"\"Prepares a circuit that generates V(\\theta).\"\"\"\n",
        "  ref_paulis = [\n",
        "      cirq.X(q0) * cirq.X(q1) + \\\n",
        "      cirq.Y(q0) * cirq.Y(q1) + \\\n",
        "      cirq.Z(q0) * cirq.Z(q1) for q0, q1 in zip(qubits, qubits[1:])\n",
        "  ]\n",
        "  exp_symbols = list(sympy.symbols('ref_0:'+str(len(ref_paulis))))\n",
        "  return tfq.util.exponential(ref_paulis, exp_symbols), exp_symbols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo6ArnnqIkTL"
      },
      "source": [
        "This circuit might be a little bit harder to verify by looking at, but you can still examine a two qubit case to see what is happening:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "r7YIeOrzJDlT",
        "outputId": "d3157580-aafa-4352-e9db-b0aeae6b40dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symbols found in circuit:[ref_0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7f60432c6350>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1127.4104296875\" height=\"100.0\"><line x1=\"34.7588671875\" x2=\"1097.4104296875\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"1097.4104296875\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"159.517734375\" x2=\"159.517734375\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"339.09585937500003\" x2=\"339.09585937500003\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"546.149140625\" x2=\"546.149140625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"725.727265625\" x2=\"725.727265625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"877.8323046875\" x2=\"877.8323046875\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1057.4104296875\" x2=\"1057.4104296875\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"79.517734375\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><circle cx=\"159.517734375\" cy=\"25.0\" r=\"10.0\" /><rect x=\"139.517734375\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"159.517734375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"199.517734375\" y=\"55.0\" width=\"99.57812500000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"249.306796875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(2.0*ref_0)</text><circle cx=\"339.09585937500003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"319.09585937500003\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"339.09585937500003\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"379.09585937500003\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"399.09585937500003\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"379.09585937500003\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"399.09585937500003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"439.09585937500003\" y=\"5.0\" width=\"67.05328125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"472.62250000000006\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(0.5π)</text><rect x=\"439.09585937500003\" y=\"55.0\" width=\"67.05328125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"472.62250000000006\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(0.5π)</text><circle cx=\"546.149140625\" cy=\"25.0\" r=\"10.0\" /><rect x=\"526.149140625\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"546.149140625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"586.149140625\" y=\"55.0\" width=\"99.57812500000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"635.938203125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(2.0*ref_0)</text><circle cx=\"725.727265625\" cy=\"25.0\" r=\"10.0\" /><rect x=\"705.727265625\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"725.727265625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"765.727265625\" y=\"55.0\" width=\"72.1050390625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"801.77978515625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(-0.5π)</text><rect x=\"765.727265625\" y=\"5.0\" width=\"72.1050390625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"801.77978515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(-0.5π)</text><circle cx=\"877.8323046875\" cy=\"25.0\" r=\"10.0\" /><rect x=\"857.8323046875\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"877.8323046875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"917.8323046875\" y=\"55.0\" width=\"99.57812500000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"967.6213671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(2.0*ref_0)</text><circle cx=\"1057.4104296875\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1037.4104296875\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1057.4104296875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "test_circuit, test_symbols = v_theta(cirq.GridQubit.rect(1, 2))\n",
        "print(f'Symbols found in circuit:{test_symbols}')\n",
        "SVGCircuit(test_circuit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN8oWtEXJXj-"
      },
      "source": [
        "Now you have all the building blocks you need to put your full encoding circuits together:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LReAUF6CSwn5"
      },
      "outputs": [],
      "source": [
        "def prepare_pqk_circuits(qubits, classical_source, n_trotter=10):\n",
        "  \"\"\"Prepare the pqk feature circuits around a dataset.\"\"\"\n",
        "  n_qubits = len(qubits)\n",
        "  n_points = len(classical_source)\n",
        "\n",
        "  # Prepare random single qubit rotation wall.\n",
        "  random_rots = np.random.uniform(-2, 2, size=(n_qubits, 3))\n",
        "  initial_U = single_qubit_wall(qubits, random_rots)\n",
        "\n",
        "  # Prepare parametrized V\n",
        "  V_circuit, symbols = v_theta(qubits)\n",
        "  exp_circuit = cirq.Circuit(V_circuit for t in range(n_trotter))\n",
        "  \n",
        "  # Convert to `tf.Tensor`\n",
        "  initial_U_tensor = tfq.convert_to_tensor([initial_U])\n",
        "  initial_U_splat = tf.tile(initial_U_tensor, [n_points])\n",
        "\n",
        "  full_circuits = tfq.layers.AddCircuit()(\n",
        "      initial_U_splat, append=exp_circuit)\n",
        "  # Replace placeholders in circuits with values from `classical_source`.\n",
        "  return tfq.resolve_parameters(\n",
        "      full_circuits, tf.convert_to_tensor([str(x) for x in symbols]),\n",
        "      tf.convert_to_tensor(classical_source*(n_qubits/3)/n_trotter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNliqKFdYacD"
      },
      "source": [
        "Choose some qubits and prepare the data encoding circuits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5F47SaRERKx_"
      },
      "outputs": [],
      "source": [
        "qubits = cirq.GridQubit.rect(1, DATASET_DIM + 1)\n",
        "q_x_train_circuits = prepare_pqk_circuits(qubits, x_train)\n",
        "q_x_test_circuits = prepare_pqk_circuits(qubits, x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD1ojMb5PbOG"
      },
      "source": [
        "Next, compute the PQK features based on the 1-RDM of the dataset circuits above and store the results in `rdm`, a `tf.Tensor` with shape `[n_points, n_qubits, 3]`. The entries in `rdm[i][j][k]` = $\\langle \\psi_i | OP^k_j | \\psi_i \\rangle$ where `i` indexes over datapoints, `j` indexes over qubits and `k` indexes over $\\lbrace \\hat{X}, \\hat{Y}, \\hat{Z} \\rbrace$ ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cEGko5t-SZ14"
      },
      "outputs": [],
      "source": [
        "def get_pqk_features(qubits, data_batch):\n",
        "  \"\"\"Get PQK features based on above construction.\"\"\"\n",
        "  ops = [[cirq.X(q), cirq.Y(q), cirq.Z(q)] for q in qubits]\n",
        "  ops_tensor = tf.expand_dims(tf.reshape(tfq.convert_to_tensor(ops), -1), 0)\n",
        "  batch_dim = tf.gather(tf.shape(data_batch), 0)\n",
        "  ops_splat = tf.tile(ops_tensor, [batch_dim, 1])\n",
        "  exp_vals = tfq.layers.Expectation()(data_batch, operators=ops_splat)\n",
        "  rdm = tf.reshape(exp_vals, [batch_dim, len(qubits), -1])\n",
        "  return rdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZOEdNMzS8hW",
        "outputId": "48c012d3-9900-4f23-dd12-d40e61526721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New PQK training dataset has shape: (1000, 11, 3)\n",
            "New PQK testing dataset has shape: (200, 11, 3)\n"
          ]
        }
      ],
      "source": [
        "x_train_pqk = get_pqk_features(qubits, q_x_train_circuits)\n",
        "x_test_pqk = get_pqk_features(qubits, q_x_test_circuits)\n",
        "print('New PQK training dataset has shape:', x_train_pqk.shape)\n",
        "print('New PQK testing dataset has shape:', x_test_pqk.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9tNBzIxT__6"
      },
      "source": [
        "### 2.2 Re-labeling based on PQK features\n",
        "Now that you have these quantum generated features in `x_train_pqk` and `x_test_pqk`, it is time to re-label the dataset. To achieve maximum seperation between quantum and classical performance you can re-label the dataset based on the spectrum information found in `x_train_pqk` and `x_test_pqk`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFSRWagZMTTn"
      },
      "source": [
        "Note: This preparation of your dataset to explicitly maximize the seperation in performance between the classical and quantum models might feel like cheating, but it provides a **very** important proof of existance for datasets that are hard for classical computers and easy for quantum computers to model. There would be no point in searching for quantum advantage in QML if you couldn't first create something like this to demonstrate advantage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BLyGksxvGINl"
      },
      "outputs": [],
      "source": [
        "def compute_kernel_matrix(vecs, gamma):\n",
        "  \"\"\"Computes d[i][j] = e^ -gamma * (vecs[i] - vecs[j]) ** 2 \"\"\"\n",
        "  scaled_gamma = gamma / (\n",
        "      tf.cast(tf.gather(tf.shape(vecs), 1), tf.float32) * tf.math.reduce_std(vecs))\n",
        "  return scaled_gamma * tf.einsum('ijk->ij',(vecs[:,None,:] - vecs) ** 2)\n",
        "\n",
        "def get_spectrum(datapoints, gamma=1.0):\n",
        "  \"\"\"Compute the eigenvalues and eigenvectors of the kernel of datapoints.\"\"\"\n",
        "  KC_qs = compute_kernel_matrix(datapoints, gamma)\n",
        "  S, V = tf.linalg.eigh(KC_qs)\n",
        "  S = tf.math.abs(S)\n",
        "  return S, V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4AxcKa4RRJr",
        "outputId": "dfbdb9ba-3e5b-4069-84cc-de91acd8e62e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvectors of pqk kernel matrix: tf.Tensor(\n",
            "[[-0.02095693  0.01059748  0.02166323 ...  0.08224609 -0.00881088\n",
            "   0.0282678 ]\n",
            " [-0.02293041  0.04663549  0.00791166 ...  0.00211753  0.69808227\n",
            "   0.02859017]\n",
            " [-0.01778547 -0.0030076  -0.02552242 ... -0.05322435  0.00538726\n",
            "   0.02690097]\n",
            " ...\n",
            " [ 0.06057929  0.01324829  0.02695337 ...  0.04392945  0.03018732\n",
            "   0.03853427]\n",
            " [ 0.06333083 -0.00304103  0.00977415 ... -0.02690826  0.00655905\n",
            "   0.03674839]\n",
            " [ 0.05860284  0.00584425  0.00264836 ...  0.02565543  0.02491427\n",
            "   0.03299441]], shape=(1200, 1200), dtype=float32)\n",
            "Eigenvectors of original kernel matrix: tf.Tensor(\n",
            "[[ 0.03835681  0.0283473  -0.01169789 ...  0.02343717  0.0211248\n",
            "   0.03206972]\n",
            " [-0.04018159  0.00888097 -0.01388255 ...  0.00582427  0.717551\n",
            "   0.02881948]\n",
            " [-0.0166719   0.01350376 -0.03663862 ...  0.02467175 -0.00415936\n",
            "   0.02195409]\n",
            " ...\n",
            " [-0.03015648 -0.01671632 -0.01603392 ...  0.00100583 -0.00261221\n",
            "   0.02365689]\n",
            " [ 0.0039777  -0.04998879 -0.00528336 ...  0.01560401 -0.04330755\n",
            "   0.02782002]\n",
            " [-0.01665728 -0.00818616 -0.0432341  ...  0.00088256  0.00927396\n",
            "   0.01875088]], shape=(1200, 1200), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "S_pqk, V_pqk = get_spectrum(\n",
        "    tf.reshape(tf.concat([x_train_pqk, x_test_pqk], 0), [-1, len(qubits) * 3]))\n",
        "\n",
        "S_original, V_original = get_spectrum(\n",
        "    tf.cast(tf.concat([x_train, x_test], 0), tf.float32), gamma=0.005)\n",
        "\n",
        "print('Eigenvectors of pqk kernel matrix:', V_pqk)\n",
        "print('Eigenvectors of original kernel matrix:', V_original)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1oULyGmcWC9"
      },
      "source": [
        "Now you have everything you need to re-label the dataset! Now you can consult with the flowchart to better understand how to maximize performance seperation when re-labeling the dataset:\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/images/quantum_data_1.png?raw=1\">\n",
        "\n",
        "In order to maximize the seperation between quantum and classical models, you will attempt to maximize the geometric difference between the original dataset and the PQK features kernel matrices $g(K_1 || K_2) = \\sqrt{ || \\sqrt{K_2} K_1^{-1} \\sqrt{K_2} || _\\infty}$ using `S_pqk, V_pqk` and `S_original, V_original`. A large value of $g$ ensures that you initially move to the right in the flowchart down towards a prediction advantage in the quantum case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz1Jmhgglhgd"
      },
      "source": [
        "Note: Computing quantities for $s$ and $d$ are also very useful when looking to better understand performance seperations. In this case ensuring a large $g$ value is enough to see performance seperation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "g-D_939PZoOH"
      },
      "outputs": [],
      "source": [
        "def get_stilted_dataset(S, V, S_2, V_2, lambdav=1.1):\n",
        "  \"\"\"Prepare new labels that maximize geometric distance between kernels.\"\"\"\n",
        "  S_diag = tf.linalg.diag(S ** 0.5)\n",
        "  S_2_diag = tf.linalg.diag(S_2 / (S_2 + lambdav) ** 2)\n",
        "  scaling = S_diag @ tf.transpose(V) @ \\\n",
        "            V_2 @ S_2_diag @ tf.transpose(V_2) @ \\\n",
        "            V @ S_diag\n",
        "\n",
        "  # Generate new lables using the largest eigenvector.\n",
        "  _, vecs = tf.linalg.eig(scaling)\n",
        "  new_labels = tf.math.real(\n",
        "      tf.einsum('ij,j->i', tf.cast(V @ S_diag, tf.complex64), vecs[-1])).numpy()\n",
        "  # Create new labels and add some small amount of noise.\n",
        "  final_y = new_labels > np.median(new_labels)\n",
        "  noisy_y = (final_y ^ (np.random.uniform(size=final_y.shape) > 0.95))\n",
        "  return noisy_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3IkuiFmZRUby"
      },
      "outputs": [],
      "source": [
        "y_relabel = get_stilted_dataset(S_pqk, V_pqk, S_original, V_original)\n",
        "y_train_new, y_test_new = y_relabel[:N_TRAIN], y_relabel[N_TRAIN:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NcCVfLGKsU9"
      },
      "source": [
        "## 3. Comparing models\n",
        "Now that you have prepared your dataset it is time to compare model performance. You will create two small feedforward neural networks and compare performance when they are given access to the PQK features found in `x_train_pqk`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqfjpBOZWmar"
      },
      "source": [
        "### 3.1 Create PQK enhanced model\n",
        "Using standard `tf.keras` library features you can now create and a train a model on the `x_train_pqk` and `y_train_new` datapoints:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK94tGyf--q2",
        "outputId": "e0706510-7c0c-4e85-d641-3befa98ccb15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                1088      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,633\n",
            "Trainable params: 1,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#docs_infra: no_execute\n",
        "def create_pqk_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(32, activation='sigmoid', input_shape=[len(qubits) * 3,]))\n",
        "    model.add(tf.keras.layers.Dense(16, activation='sigmoid'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "pqk_model = create_pqk_model()\n",
        "pqk_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "pqk_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QUL8ygMn_zOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c9e4d6-57a0-42cf-e31e-9b75154bb1aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.1262e-05 - accuracy: 1.0000 - val_loss: 12.0744 - val_accuracy: 0.3300\n",
            "Epoch 2/1000\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 4.8620e-05 - accuracy: 1.0000 - val_loss: 12.0435 - val_accuracy: 0.3300\n",
            "Epoch 3/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.7213e-05 - accuracy: 1.0000 - val_loss: 12.0910 - val_accuracy: 0.3300\n",
            "Epoch 4/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 4.7461e-05 - accuracy: 1.0000 - val_loss: 12.0283 - val_accuracy: 0.3300\n",
            "Epoch 5/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 4.7197e-05 - accuracy: 1.0000 - val_loss: 12.0462 - val_accuracy: 0.3350\n",
            "Epoch 6/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 4.6367e-05 - accuracy: 1.0000 - val_loss: 12.0655 - val_accuracy: 0.3300\n",
            "Epoch 7/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 4.4999e-05 - accuracy: 1.0000 - val_loss: 12.1582 - val_accuracy: 0.3250\n",
            "Epoch 8/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 4.3974e-05 - accuracy: 1.0000 - val_loss: 12.0820 - val_accuracy: 0.3350\n",
            "Epoch 9/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.4626e-05 - accuracy: 1.0000 - val_loss: 12.1306 - val_accuracy: 0.3300\n",
            "Epoch 10/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.2935e-05 - accuracy: 1.0000 - val_loss: 12.1424 - val_accuracy: 0.3350\n",
            "Epoch 11/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.0939e-05 - accuracy: 1.0000 - val_loss: 12.1463 - val_accuracy: 0.3300\n",
            "Epoch 12/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.0562e-05 - accuracy: 1.0000 - val_loss: 12.2317 - val_accuracy: 0.3150\n",
            "Epoch 13/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.0747e-05 - accuracy: 1.0000 - val_loss: 12.2336 - val_accuracy: 0.3200\n",
            "Epoch 14/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.8498e-05 - accuracy: 1.0000 - val_loss: 12.2710 - val_accuracy: 0.3150\n",
            "Epoch 15/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.0047e-05 - accuracy: 1.0000 - val_loss: 12.2569 - val_accuracy: 0.3250\n",
            "Epoch 16/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.0862e-05 - accuracy: 1.0000 - val_loss: 12.2085 - val_accuracy: 0.3250\n",
            "Epoch 17/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.7726e-05 - accuracy: 1.0000 - val_loss: 12.3218 - val_accuracy: 0.3250\n",
            "Epoch 18/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.7050e-05 - accuracy: 1.0000 - val_loss: 12.2809 - val_accuracy: 0.3250\n",
            "Epoch 19/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.6000e-05 - accuracy: 1.0000 - val_loss: 12.2987 - val_accuracy: 0.3250\n",
            "Epoch 20/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 3.6048e-05 - accuracy: 1.0000 - val_loss: 12.3449 - val_accuracy: 0.3250\n",
            "Epoch 21/1000\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 3.4863e-05 - accuracy: 1.0000 - val_loss: 12.3732 - val_accuracy: 0.3250\n",
            "Epoch 22/1000\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 3.3530e-05 - accuracy: 1.0000 - val_loss: 12.3875 - val_accuracy: 0.3250\n",
            "Epoch 23/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.4091e-05 - accuracy: 1.0000 - val_loss: 12.3913 - val_accuracy: 0.3200\n",
            "Epoch 24/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.4503e-05 - accuracy: 1.0000 - val_loss: 12.3651 - val_accuracy: 0.3250\n",
            "Epoch 25/1000\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 3.9139e-05 - accuracy: 1.0000 - val_loss: 12.3631 - val_accuracy: 0.3350\n",
            "Epoch 26/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.2530e-05 - accuracy: 1.0000 - val_loss: 12.4046 - val_accuracy: 0.3300\n",
            "Epoch 27/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.2732e-05 - accuracy: 1.0000 - val_loss: 12.4123 - val_accuracy: 0.3250\n",
            "Epoch 28/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.1312e-05 - accuracy: 1.0000 - val_loss: 12.4702 - val_accuracy: 0.3200\n",
            "Epoch 29/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.0904e-05 - accuracy: 1.0000 - val_loss: 12.4837 - val_accuracy: 0.3250\n",
            "Epoch 30/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.9869e-05 - accuracy: 1.0000 - val_loss: 12.4263 - val_accuracy: 0.3250\n",
            "Epoch 31/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.8820e-05 - accuracy: 1.0000 - val_loss: 12.5312 - val_accuracy: 0.3250\n",
            "Epoch 32/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.8902e-05 - accuracy: 1.0000 - val_loss: 12.4483 - val_accuracy: 0.3250\n",
            "Epoch 33/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.8310e-05 - accuracy: 1.0000 - val_loss: 12.4913 - val_accuracy: 0.3250\n",
            "Epoch 34/1000\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 2.7535e-05 - accuracy: 1.0000 - val_loss: 12.5678 - val_accuracy: 0.3200\n",
            "Epoch 35/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.7084e-05 - accuracy: 1.0000 - val_loss: 12.5006 - val_accuracy: 0.3250\n",
            "Epoch 36/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.7294e-05 - accuracy: 1.0000 - val_loss: 12.5868 - val_accuracy: 0.3250\n",
            "Epoch 37/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.6426e-05 - accuracy: 1.0000 - val_loss: 12.5396 - val_accuracy: 0.3250\n",
            "Epoch 38/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.7028e-05 - accuracy: 1.0000 - val_loss: 12.5444 - val_accuracy: 0.3300\n",
            "Epoch 39/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.5063e-05 - accuracy: 1.0000 - val_loss: 12.6037 - val_accuracy: 0.3200\n",
            "Epoch 40/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.4824e-05 - accuracy: 1.0000 - val_loss: 12.6449 - val_accuracy: 0.3200\n",
            "Epoch 41/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.4625e-05 - accuracy: 1.0000 - val_loss: 12.6241 - val_accuracy: 0.3250\n",
            "Epoch 42/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.3791e-05 - accuracy: 1.0000 - val_loss: 12.6949 - val_accuracy: 0.3250\n",
            "Epoch 43/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.3986e-05 - accuracy: 1.0000 - val_loss: 12.7179 - val_accuracy: 0.3250\n",
            "Epoch 44/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.3245e-05 - accuracy: 1.0000 - val_loss: 12.6901 - val_accuracy: 0.3200\n",
            "Epoch 45/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 2.2177e-05 - accuracy: 1.0000 - val_loss: 12.7103 - val_accuracy: 0.3200\n",
            "Epoch 46/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.2482e-05 - accuracy: 1.0000 - val_loss: 12.6835 - val_accuracy: 0.3250\n",
            "Epoch 47/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.2528e-05 - accuracy: 1.0000 - val_loss: 12.7342 - val_accuracy: 0.3200\n",
            "Epoch 48/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.1285e-05 - accuracy: 1.0000 - val_loss: 12.7260 - val_accuracy: 0.3250\n",
            "Epoch 49/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.1844e-05 - accuracy: 1.0000 - val_loss: 12.6885 - val_accuracy: 0.3250\n",
            "Epoch 50/1000\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 2.0397e-05 - accuracy: 1.0000 - val_loss: 12.7942 - val_accuracy: 0.3300\n",
            "Epoch 51/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.0364e-05 - accuracy: 1.0000 - val_loss: 12.7924 - val_accuracy: 0.3250\n",
            "Epoch 52/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.9917e-05 - accuracy: 1.0000 - val_loss: 12.7732 - val_accuracy: 0.3250\n",
            "Epoch 53/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.9798e-05 - accuracy: 1.0000 - val_loss: 12.7861 - val_accuracy: 0.3250\n",
            "Epoch 54/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.9899e-05 - accuracy: 1.0000 - val_loss: 12.8514 - val_accuracy: 0.3250\n",
            "Epoch 55/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.8692e-05 - accuracy: 1.0000 - val_loss: 12.8275 - val_accuracy: 0.3250\n",
            "Epoch 56/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.8494e-05 - accuracy: 1.0000 - val_loss: 12.8516 - val_accuracy: 0.3250\n",
            "Epoch 57/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7930e-05 - accuracy: 1.0000 - val_loss: 12.8941 - val_accuracy: 0.3250\n",
            "Epoch 58/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.8550e-05 - accuracy: 1.0000 - val_loss: 12.8636 - val_accuracy: 0.3300\n",
            "Epoch 59/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.8030e-05 - accuracy: 1.0000 - val_loss: 12.8776 - val_accuracy: 0.3250\n",
            "Epoch 60/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.7404e-05 - accuracy: 1.0000 - val_loss: 12.8553 - val_accuracy: 0.3250\n",
            "Epoch 61/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.7303e-05 - accuracy: 1.0000 - val_loss: 12.8488 - val_accuracy: 0.3250\n",
            "Epoch 62/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.7875e-05 - accuracy: 1.0000 - val_loss: 12.9661 - val_accuracy: 0.3250\n",
            "Epoch 63/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6614e-05 - accuracy: 1.0000 - val_loss: 12.8945 - val_accuracy: 0.3200\n",
            "Epoch 64/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.6084e-05 - accuracy: 1.0000 - val_loss: 12.9605 - val_accuracy: 0.3300\n",
            "Epoch 65/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.5676e-05 - accuracy: 1.0000 - val_loss: 12.9150 - val_accuracy: 0.3250\n",
            "Epoch 66/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.5803e-05 - accuracy: 1.0000 - val_loss: 13.0054 - val_accuracy: 0.3250\n",
            "Epoch 67/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 1.5477e-05 - accuracy: 1.0000 - val_loss: 13.0082 - val_accuracy: 0.3250\n",
            "Epoch 68/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.5369e-05 - accuracy: 1.0000 - val_loss: 13.0941 - val_accuracy: 0.3250\n",
            "Epoch 69/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5396e-05 - accuracy: 1.0000 - val_loss: 13.0440 - val_accuracy: 0.3250\n",
            "Epoch 70/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.4459e-05 - accuracy: 1.0000 - val_loss: 13.0669 - val_accuracy: 0.3250\n",
            "Epoch 71/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4238e-05 - accuracy: 1.0000 - val_loss: 13.0217 - val_accuracy: 0.3300\n",
            "Epoch 72/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4187e-05 - accuracy: 1.0000 - val_loss: 13.0137 - val_accuracy: 0.3300\n",
            "Epoch 73/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.5016e-05 - accuracy: 1.0000 - val_loss: 13.0928 - val_accuracy: 0.3300\n",
            "Epoch 74/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.3718e-05 - accuracy: 1.0000 - val_loss: 13.0989 - val_accuracy: 0.3250\n",
            "Epoch 75/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3354e-05 - accuracy: 1.0000 - val_loss: 13.0986 - val_accuracy: 0.3300\n",
            "Epoch 76/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3773e-05 - accuracy: 1.0000 - val_loss: 13.1489 - val_accuracy: 0.3300\n",
            "Epoch 77/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.2765e-05 - accuracy: 1.0000 - val_loss: 13.2335 - val_accuracy: 0.3250\n",
            "Epoch 78/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2862e-05 - accuracy: 1.0000 - val_loss: 13.2375 - val_accuracy: 0.3250\n",
            "Epoch 79/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4755e-05 - accuracy: 1.0000 - val_loss: 13.2439 - val_accuracy: 0.3250\n",
            "Epoch 80/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.2278e-05 - accuracy: 1.0000 - val_loss: 13.2436 - val_accuracy: 0.3250\n",
            "Epoch 81/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2137e-05 - accuracy: 1.0000 - val_loss: 13.2413 - val_accuracy: 0.3250\n",
            "Epoch 82/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1742e-05 - accuracy: 1.0000 - val_loss: 13.2809 - val_accuracy: 0.3250\n",
            "Epoch 83/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.1669e-05 - accuracy: 1.0000 - val_loss: 13.2657 - val_accuracy: 0.3250\n",
            "Epoch 84/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1396e-05 - accuracy: 1.0000 - val_loss: 13.2624 - val_accuracy: 0.3250\n",
            "Epoch 85/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1003e-05 - accuracy: 1.0000 - val_loss: 13.2611 - val_accuracy: 0.3250\n",
            "Epoch 86/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.1156e-05 - accuracy: 1.0000 - val_loss: 13.2700 - val_accuracy: 0.3250\n",
            "Epoch 87/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0551e-05 - accuracy: 1.0000 - val_loss: 13.3255 - val_accuracy: 0.3250\n",
            "Epoch 88/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.0590e-05 - accuracy: 1.0000 - val_loss: 13.3292 - val_accuracy: 0.3250\n",
            "Epoch 89/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0416e-05 - accuracy: 1.0000 - val_loss: 13.3079 - val_accuracy: 0.3250\n",
            "Epoch 90/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0097e-05 - accuracy: 1.0000 - val_loss: 13.3294 - val_accuracy: 0.3250\n",
            "Epoch 91/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0065e-05 - accuracy: 1.0000 - val_loss: 13.3363 - val_accuracy: 0.3250\n",
            "Epoch 92/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.6282e-06 - accuracy: 1.0000 - val_loss: 13.4327 - val_accuracy: 0.3250\n",
            "Epoch 93/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.8346e-06 - accuracy: 1.0000 - val_loss: 13.4144 - val_accuracy: 0.3250\n",
            "Epoch 94/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.5735e-06 - accuracy: 1.0000 - val_loss: 13.3835 - val_accuracy: 0.3250\n",
            "Epoch 95/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.3041e-06 - accuracy: 1.0000 - val_loss: 13.3854 - val_accuracy: 0.3250\n",
            "Epoch 96/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.3362e-06 - accuracy: 1.0000 - val_loss: 13.3897 - val_accuracy: 0.3250\n",
            "Epoch 97/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 9.6692e-06 - accuracy: 1.0000 - val_loss: 13.3605 - val_accuracy: 0.3300\n",
            "Epoch 98/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 9.2292e-06 - accuracy: 1.0000 - val_loss: 13.4120 - val_accuracy: 0.3300\n",
            "Epoch 99/1000\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 8.5427e-06 - accuracy: 1.0000 - val_loss: 13.4721 - val_accuracy: 0.3250\n",
            "Epoch 100/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 8.9115e-06 - accuracy: 1.0000 - val_loss: 13.4602 - val_accuracy: 0.3300\n",
            "Epoch 101/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.5082e-06 - accuracy: 1.0000 - val_loss: 13.4310 - val_accuracy: 0.3250\n",
            "Epoch 102/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.5551e-06 - accuracy: 1.0000 - val_loss: 13.4440 - val_accuracy: 0.3250\n",
            "Epoch 103/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.1686e-06 - accuracy: 1.0000 - val_loss: 13.4953 - val_accuracy: 0.3250\n",
            "Epoch 104/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.9416e-06 - accuracy: 1.0000 - val_loss: 13.5490 - val_accuracy: 0.3250\n",
            "Epoch 105/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.9633e-06 - accuracy: 1.0000 - val_loss: 13.5000 - val_accuracy: 0.3250\n",
            "Epoch 106/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.8304e-06 - accuracy: 1.0000 - val_loss: 13.5175 - val_accuracy: 0.3250\n",
            "Epoch 107/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.5958e-06 - accuracy: 1.0000 - val_loss: 13.5615 - val_accuracy: 0.3250\n",
            "Epoch 108/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.4214e-06 - accuracy: 1.0000 - val_loss: 13.5899 - val_accuracy: 0.3250\n",
            "Epoch 109/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.3828e-06 - accuracy: 1.0000 - val_loss: 13.5849 - val_accuracy: 0.3250\n",
            "Epoch 110/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.1396e-06 - accuracy: 1.0000 - val_loss: 13.5812 - val_accuracy: 0.3250\n",
            "Epoch 111/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.9813e-06 - accuracy: 1.0000 - val_loss: 13.6742 - val_accuracy: 0.3250\n",
            "Epoch 112/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 7.0038e-06 - accuracy: 1.0000 - val_loss: 13.6950 - val_accuracy: 0.3250\n",
            "Epoch 113/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 6.9842e-06 - accuracy: 1.0000 - val_loss: 13.6438 - val_accuracy: 0.3250\n",
            "Epoch 114/1000\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 6.7377e-06 - accuracy: 1.0000 - val_loss: 13.6681 - val_accuracy: 0.3250\n",
            "Epoch 115/1000\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 6.5829e-06 - accuracy: 1.0000 - val_loss: 13.7020 - val_accuracy: 0.3250\n",
            "Epoch 116/1000\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 6.6704e-06 - accuracy: 1.0000 - val_loss: 13.6975 - val_accuracy: 0.3250\n",
            "Epoch 117/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 6.7196e-06 - accuracy: 1.0000 - val_loss: 13.6795 - val_accuracy: 0.3300\n",
            "Epoch 118/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.2999e-06 - accuracy: 1.0000 - val_loss: 13.6691 - val_accuracy: 0.3300\n",
            "Epoch 119/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.2820e-06 - accuracy: 1.0000 - val_loss: 13.7343 - val_accuracy: 0.3250\n",
            "Epoch 120/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.9760e-06 - accuracy: 1.0000 - val_loss: 13.6802 - val_accuracy: 0.3250\n",
            "Epoch 121/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 6.2955e-06 - accuracy: 1.0000 - val_loss: 13.7070 - val_accuracy: 0.3250\n",
            "Epoch 122/1000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 5.8661e-06 - accuracy: 1.0000 - val_loss: 13.7631 - val_accuracy: 0.3250\n",
            "Epoch 123/1000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 5.8324e-06 - accuracy: 1.0000 - val_loss: 13.7310 - val_accuracy: 0.3250\n",
            "Epoch 124/1000\n",
            "32/32 [==============================] - 1s 24ms/step - loss: 5.6821e-06 - accuracy: 1.0000 - val_loss: 13.8289 - val_accuracy: 0.3250\n",
            "Epoch 125/1000\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 5.4902e-06 - accuracy: 1.0000 - val_loss: 13.7903 - val_accuracy: 0.3250\n",
            "Epoch 126/1000\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 5.3246e-06 - accuracy: 1.0000 - val_loss: 13.8474 - val_accuracy: 0.3250\n",
            "Epoch 127/1000\n",
            "32/32 [==============================] - 1s 24ms/step - loss: 5.2412e-06 - accuracy: 1.0000 - val_loss: 13.8684 - val_accuracy: 0.3250\n",
            "Epoch 128/1000\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 5.2748e-06 - accuracy: 1.0000 - val_loss: 13.8785 - val_accuracy: 0.3250\n",
            "Epoch 129/1000\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 5.0998e-06 - accuracy: 1.0000 - val_loss: 13.8272 - val_accuracy: 0.3250\n",
            "Epoch 130/1000\n",
            "32/32 [==============================] - 1s 24ms/step - loss: 5.1439e-06 - accuracy: 1.0000 - val_loss: 13.9222 - val_accuracy: 0.3250\n",
            "Epoch 131/1000\n",
            "32/32 [==============================] - 1s 24ms/step - loss: 5.0087e-06 - accuracy: 1.0000 - val_loss: 13.8656 - val_accuracy: 0.3250\n",
            "Epoch 132/1000\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 5.0118e-06 - accuracy: 1.0000 - val_loss: 13.8594 - val_accuracy: 0.3300\n",
            "Epoch 133/1000\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 4.9203e-06 - accuracy: 1.0000 - val_loss: 13.9321 - val_accuracy: 0.3250\n",
            "Epoch 134/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.6699e-06 - accuracy: 1.0000 - val_loss: 13.9723 - val_accuracy: 0.3250\n",
            "Epoch 135/1000\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 4.9002e-06 - accuracy: 1.0000 - val_loss: 13.9593 - val_accuracy: 0.3250\n",
            "Epoch 136/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 5.1756e-06 - accuracy: 1.0000 - val_loss: 13.9599 - val_accuracy: 0.3250\n",
            "Epoch 137/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.4870e-06 - accuracy: 1.0000 - val_loss: 14.0175 - val_accuracy: 0.3250\n",
            "Epoch 138/1000\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 4.4449e-06 - accuracy: 1.0000 - val_loss: 14.0340 - val_accuracy: 0.3250\n",
            "Epoch 139/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.3304e-06 - accuracy: 1.0000 - val_loss: 13.9691 - val_accuracy: 0.3300\n",
            "Epoch 140/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.3322e-06 - accuracy: 1.0000 - val_loss: 14.0127 - val_accuracy: 0.3250\n",
            "Epoch 141/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 4.2091e-06 - accuracy: 1.0000 - val_loss: 13.9789 - val_accuracy: 0.3250\n",
            "Epoch 142/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.3404e-06 - accuracy: 1.0000 - val_loss: 13.9675 - val_accuracy: 0.3250\n",
            "Epoch 143/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.4653e-06 - accuracy: 1.0000 - val_loss: 13.9930 - val_accuracy: 0.3250\n",
            "Epoch 144/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.3683e-06 - accuracy: 1.0000 - val_loss: 14.0779 - val_accuracy: 0.3250\n",
            "Epoch 145/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.9269e-06 - accuracy: 1.0000 - val_loss: 14.0960 - val_accuracy: 0.3250\n",
            "Epoch 146/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 3.7955e-06 - accuracy: 1.0000 - val_loss: 14.0886 - val_accuracy: 0.3250\n",
            "Epoch 147/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.8348e-06 - accuracy: 1.0000 - val_loss: 14.0543 - val_accuracy: 0.3250\n",
            "Epoch 148/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.7625e-06 - accuracy: 1.0000 - val_loss: 14.1063 - val_accuracy: 0.3250\n",
            "Epoch 149/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.6010e-06 - accuracy: 1.0000 - val_loss: 14.0932 - val_accuracy: 0.3250\n",
            "Epoch 150/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 3.7768e-06 - accuracy: 1.0000 - val_loss: 14.1376 - val_accuracy: 0.3250\n",
            "Epoch 151/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.5359e-06 - accuracy: 1.0000 - val_loss: 14.1813 - val_accuracy: 0.3250\n",
            "Epoch 152/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.4568e-06 - accuracy: 1.0000 - val_loss: 14.1983 - val_accuracy: 0.3250\n",
            "Epoch 153/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.3972e-06 - accuracy: 1.0000 - val_loss: 14.2200 - val_accuracy: 0.3250\n",
            "Epoch 154/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 3.3704e-06 - accuracy: 1.0000 - val_loss: 14.1857 - val_accuracy: 0.3250\n",
            "Epoch 155/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.2559e-06 - accuracy: 1.0000 - val_loss: 14.2494 - val_accuracy: 0.3250\n",
            "Epoch 156/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.3518e-06 - accuracy: 1.0000 - val_loss: 14.2692 - val_accuracy: 0.3250\n",
            "Epoch 157/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.2784e-06 - accuracy: 1.0000 - val_loss: 14.2651 - val_accuracy: 0.3250\n",
            "Epoch 158/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.0716e-06 - accuracy: 1.0000 - val_loss: 14.3278 - val_accuracy: 0.3200\n",
            "Epoch 159/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.1348e-06 - accuracy: 1.0000 - val_loss: 14.2733 - val_accuracy: 0.3250\n",
            "Epoch 160/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.9977e-06 - accuracy: 1.0000 - val_loss: 14.3101 - val_accuracy: 0.3250\n",
            "Epoch 161/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.0569e-06 - accuracy: 1.0000 - val_loss: 14.3311 - val_accuracy: 0.3250\n",
            "Epoch 162/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.9322e-06 - accuracy: 1.0000 - val_loss: 14.3812 - val_accuracy: 0.3200\n",
            "Epoch 163/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.9824e-06 - accuracy: 1.0000 - val_loss: 14.3482 - val_accuracy: 0.3250\n",
            "Epoch 164/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.9119e-06 - accuracy: 1.0000 - val_loss: 14.3258 - val_accuracy: 0.3250\n",
            "Epoch 165/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.8311e-06 - accuracy: 1.0000 - val_loss: 14.3643 - val_accuracy: 0.3250\n",
            "Epoch 166/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.7316e-06 - accuracy: 1.0000 - val_loss: 14.3712 - val_accuracy: 0.3200\n",
            "Epoch 167/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.7078e-06 - accuracy: 1.0000 - val_loss: 14.3737 - val_accuracy: 0.3250\n",
            "Epoch 168/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.7084e-06 - accuracy: 1.0000 - val_loss: 14.3808 - val_accuracy: 0.3250\n",
            "Epoch 169/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.6462e-06 - accuracy: 1.0000 - val_loss: 14.4017 - val_accuracy: 0.3250\n",
            "Epoch 170/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.5766e-06 - accuracy: 1.0000 - val_loss: 14.3890 - val_accuracy: 0.3250\n",
            "Epoch 171/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.5527e-06 - accuracy: 1.0000 - val_loss: 14.4234 - val_accuracy: 0.3250\n",
            "Epoch 172/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.4759e-06 - accuracy: 1.0000 - val_loss: 14.4620 - val_accuracy: 0.3250\n",
            "Epoch 173/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.4479e-06 - accuracy: 1.0000 - val_loss: 14.4931 - val_accuracy: 0.3200\n",
            "Epoch 174/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.4188e-06 - accuracy: 1.0000 - val_loss: 14.4828 - val_accuracy: 0.3250\n",
            "Epoch 175/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.3618e-06 - accuracy: 1.0000 - val_loss: 14.5376 - val_accuracy: 0.3200\n",
            "Epoch 176/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.2827e-06 - accuracy: 1.0000 - val_loss: 14.5112 - val_accuracy: 0.3200\n",
            "Epoch 177/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.2524e-06 - accuracy: 1.0000 - val_loss: 14.5465 - val_accuracy: 0.3200\n",
            "Epoch 178/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.2171e-06 - accuracy: 1.0000 - val_loss: 14.5575 - val_accuracy: 0.3200\n",
            "Epoch 179/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.1797e-06 - accuracy: 1.0000 - val_loss: 14.5870 - val_accuracy: 0.3200\n",
            "Epoch 180/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.1599e-06 - accuracy: 1.0000 - val_loss: 14.6055 - val_accuracy: 0.3200\n",
            "Epoch 181/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.1021e-06 - accuracy: 1.0000 - val_loss: 14.5653 - val_accuracy: 0.3200\n",
            "Epoch 182/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.1416e-06 - accuracy: 1.0000 - val_loss: 14.5983 - val_accuracy: 0.3200\n",
            "Epoch 183/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.0336e-06 - accuracy: 1.0000 - val_loss: 14.6393 - val_accuracy: 0.3200\n",
            "Epoch 184/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.0099e-06 - accuracy: 1.0000 - val_loss: 14.6409 - val_accuracy: 0.3200\n",
            "Epoch 185/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.0180e-06 - accuracy: 1.0000 - val_loss: 14.6548 - val_accuracy: 0.3200\n",
            "Epoch 186/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.9597e-06 - accuracy: 1.0000 - val_loss: 14.6157 - val_accuracy: 0.3200\n",
            "Epoch 187/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.9382e-06 - accuracy: 1.0000 - val_loss: 14.6542 - val_accuracy: 0.3200\n",
            "Epoch 188/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.8785e-06 - accuracy: 1.0000 - val_loss: 14.6800 - val_accuracy: 0.3200\n",
            "Epoch 189/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.8084e-06 - accuracy: 1.0000 - val_loss: 14.6831 - val_accuracy: 0.3200\n",
            "Epoch 190/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.8509e-06 - accuracy: 1.0000 - val_loss: 14.6810 - val_accuracy: 0.3200\n",
            "Epoch 191/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.7636e-06 - accuracy: 1.0000 - val_loss: 14.6808 - val_accuracy: 0.3200\n",
            "Epoch 192/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7675e-06 - accuracy: 1.0000 - val_loss: 14.7498 - val_accuracy: 0.3200\n",
            "Epoch 193/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.7573e-06 - accuracy: 1.0000 - val_loss: 14.7334 - val_accuracy: 0.3200\n",
            "Epoch 194/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.7037e-06 - accuracy: 1.0000 - val_loss: 14.7725 - val_accuracy: 0.3250\n",
            "Epoch 195/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.6849e-06 - accuracy: 1.0000 - val_loss: 14.7732 - val_accuracy: 0.3200\n",
            "Epoch 196/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7118e-06 - accuracy: 1.0000 - val_loss: 14.7553 - val_accuracy: 0.3200\n",
            "Epoch 197/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.6140e-06 - accuracy: 1.0000 - val_loss: 14.7436 - val_accuracy: 0.3200\n",
            "Epoch 198/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5779e-06 - accuracy: 1.0000 - val_loss: 14.7703 - val_accuracy: 0.3200\n",
            "Epoch 199/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.5779e-06 - accuracy: 1.0000 - val_loss: 14.7876 - val_accuracy: 0.3200\n",
            "Epoch 200/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.5290e-06 - accuracy: 1.0000 - val_loss: 14.8076 - val_accuracy: 0.3200\n",
            "Epoch 201/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4998e-06 - accuracy: 1.0000 - val_loss: 14.8089 - val_accuracy: 0.3200\n",
            "Epoch 202/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4573e-06 - accuracy: 1.0000 - val_loss: 14.8295 - val_accuracy: 0.3200\n",
            "Epoch 203/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5309e-06 - accuracy: 1.0000 - val_loss: 14.8267 - val_accuracy: 0.3200\n",
            "Epoch 204/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.4162e-06 - accuracy: 1.0000 - val_loss: 14.8714 - val_accuracy: 0.3200\n",
            "Epoch 205/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4261e-06 - accuracy: 1.0000 - val_loss: 14.8869 - val_accuracy: 0.3200\n",
            "Epoch 206/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.3853e-06 - accuracy: 1.0000 - val_loss: 14.8875 - val_accuracy: 0.3200\n",
            "Epoch 207/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.3857e-06 - accuracy: 1.0000 - val_loss: 14.8434 - val_accuracy: 0.3200\n",
            "Epoch 208/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.3308e-06 - accuracy: 1.0000 - val_loss: 14.9032 - val_accuracy: 0.3200\n",
            "Epoch 209/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.2848e-06 - accuracy: 1.0000 - val_loss: 14.8818 - val_accuracy: 0.3200\n",
            "Epoch 210/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.3066e-06 - accuracy: 1.0000 - val_loss: 14.9127 - val_accuracy: 0.3200\n",
            "Epoch 211/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2623e-06 - accuracy: 1.0000 - val_loss: 14.9218 - val_accuracy: 0.3200\n",
            "Epoch 212/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2300e-06 - accuracy: 1.0000 - val_loss: 14.9689 - val_accuracy: 0.3200\n",
            "Epoch 213/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2264e-06 - accuracy: 1.0000 - val_loss: 14.9448 - val_accuracy: 0.3200\n",
            "Epoch 214/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.2090e-06 - accuracy: 1.0000 - val_loss: 14.9217 - val_accuracy: 0.3200\n",
            "Epoch 215/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1683e-06 - accuracy: 1.0000 - val_loss: 14.9592 - val_accuracy: 0.3200\n",
            "Epoch 216/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1662e-06 - accuracy: 1.0000 - val_loss: 14.9870 - val_accuracy: 0.3200\n",
            "Epoch 217/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1577e-06 - accuracy: 1.0000 - val_loss: 14.9454 - val_accuracy: 0.3200\n",
            "Epoch 218/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.1492e-06 - accuracy: 1.0000 - val_loss: 14.9962 - val_accuracy: 0.3200\n",
            "Epoch 219/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1024e-06 - accuracy: 1.0000 - val_loss: 15.0533 - val_accuracy: 0.3200\n",
            "Epoch 220/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1142e-06 - accuracy: 1.0000 - val_loss: 15.0489 - val_accuracy: 0.3200\n",
            "Epoch 221/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0653e-06 - accuracy: 1.0000 - val_loss: 15.0481 - val_accuracy: 0.3200\n",
            "Epoch 222/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0705e-06 - accuracy: 1.0000 - val_loss: 15.1047 - val_accuracy: 0.3200\n",
            "Epoch 223/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.0630e-06 - accuracy: 1.0000 - val_loss: 15.0524 - val_accuracy: 0.3200\n",
            "Epoch 224/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0332e-06 - accuracy: 1.0000 - val_loss: 15.1027 - val_accuracy: 0.3250\n",
            "Epoch 225/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0120e-06 - accuracy: 1.0000 - val_loss: 15.1242 - val_accuracy: 0.3250\n",
            "Epoch 226/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.8704e-07 - accuracy: 1.0000 - val_loss: 15.1029 - val_accuracy: 0.3200\n",
            "Epoch 227/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.8516e-07 - accuracy: 1.0000 - val_loss: 15.1738 - val_accuracy: 0.3250\n",
            "Epoch 228/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.4464e-07 - accuracy: 1.0000 - val_loss: 15.1153 - val_accuracy: 0.3200\n",
            "Epoch 229/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.4129e-07 - accuracy: 1.0000 - val_loss: 15.1552 - val_accuracy: 0.3250\n",
            "Epoch 230/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.2927e-07 - accuracy: 1.0000 - val_loss: 15.1690 - val_accuracy: 0.3200\n",
            "Epoch 231/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.3599e-07 - accuracy: 1.0000 - val_loss: 15.1899 - val_accuracy: 0.3250\n",
            "Epoch 232/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.9339e-07 - accuracy: 1.0000 - val_loss: 15.2223 - val_accuracy: 0.3250\n",
            "Epoch 233/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.9255e-07 - accuracy: 1.0000 - val_loss: 15.1906 - val_accuracy: 0.3250\n",
            "Epoch 234/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.7361e-07 - accuracy: 1.0000 - val_loss: 15.1887 - val_accuracy: 0.3200\n",
            "Epoch 235/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.6555e-07 - accuracy: 1.0000 - val_loss: 15.1625 - val_accuracy: 0.3200\n",
            "Epoch 236/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.5441e-07 - accuracy: 1.0000 - val_loss: 15.2639 - val_accuracy: 0.3250\n",
            "Epoch 237/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.2246e-07 - accuracy: 1.0000 - val_loss: 15.2257 - val_accuracy: 0.3200\n",
            "Epoch 238/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.2212e-07 - accuracy: 1.0000 - val_loss: 15.2538 - val_accuracy: 0.3200\n",
            "Epoch 239/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.9685e-07 - accuracy: 1.0000 - val_loss: 15.2793 - val_accuracy: 0.3250\n",
            "Epoch 240/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.9809e-07 - accuracy: 1.0000 - val_loss: 15.2895 - val_accuracy: 0.3250\n",
            "Epoch 241/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.8216e-07 - accuracy: 1.0000 - val_loss: 15.2690 - val_accuracy: 0.3250\n",
            "Epoch 242/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.7446e-07 - accuracy: 1.0000 - val_loss: 15.2852 - val_accuracy: 0.3200\n",
            "Epoch 243/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.6429e-07 - accuracy: 1.0000 - val_loss: 15.3092 - val_accuracy: 0.3200\n",
            "Epoch 244/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.5456e-07 - accuracy: 1.0000 - val_loss: 15.2867 - val_accuracy: 0.3200\n",
            "Epoch 245/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.2362e-07 - accuracy: 1.0000 - val_loss: 15.3310 - val_accuracy: 0.3200\n",
            "Epoch 246/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.2085e-07 - accuracy: 1.0000 - val_loss: 15.3569 - val_accuracy: 0.3250\n",
            "Epoch 247/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.2954e-07 - accuracy: 1.0000 - val_loss: 15.4082 - val_accuracy: 0.3250\n",
            "Epoch 248/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.3260e-07 - accuracy: 1.0000 - val_loss: 15.3705 - val_accuracy: 0.3250\n",
            "Epoch 249/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.8544e-07 - accuracy: 1.0000 - val_loss: 15.3675 - val_accuracy: 0.3250\n",
            "Epoch 250/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.7777e-07 - accuracy: 1.0000 - val_loss: 15.3540 - val_accuracy: 0.3200\n",
            "Epoch 251/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.6113e-07 - accuracy: 1.0000 - val_loss: 15.4005 - val_accuracy: 0.3200\n",
            "Epoch 252/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.4964e-07 - accuracy: 1.0000 - val_loss: 15.3963 - val_accuracy: 0.3200\n",
            "Epoch 253/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.3811e-07 - accuracy: 1.0000 - val_loss: 15.4014 - val_accuracy: 0.3250\n",
            "Epoch 254/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.1691e-07 - accuracy: 1.0000 - val_loss: 15.4099 - val_accuracy: 0.3200\n",
            "Epoch 255/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.0620e-07 - accuracy: 1.0000 - val_loss: 15.4084 - val_accuracy: 0.3250\n",
            "Epoch 256/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.9848e-07 - accuracy: 1.0000 - val_loss: 15.4127 - val_accuracy: 0.3250\n",
            "Epoch 257/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.9727e-07 - accuracy: 1.0000 - val_loss: 15.4889 - val_accuracy: 0.3250\n",
            "Epoch 258/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.8436e-07 - accuracy: 1.0000 - val_loss: 15.4780 - val_accuracy: 0.3200\n",
            "Epoch 259/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.7807e-07 - accuracy: 1.0000 - val_loss: 15.5074 - val_accuracy: 0.3200\n",
            "Epoch 260/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.5929e-07 - accuracy: 1.0000 - val_loss: 15.5070 - val_accuracy: 0.3250\n",
            "Epoch 261/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5406e-07 - accuracy: 1.0000 - val_loss: 15.5320 - val_accuracy: 0.3250\n",
            "Epoch 262/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.4035e-07 - accuracy: 1.0000 - val_loss: 15.5281 - val_accuracy: 0.3250\n",
            "Epoch 263/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.3568e-07 - accuracy: 1.0000 - val_loss: 15.4999 - val_accuracy: 0.3250\n",
            "Epoch 264/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.4513e-07 - accuracy: 1.0000 - val_loss: 15.6075 - val_accuracy: 0.3300\n",
            "Epoch 265/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.5109e-07 - accuracy: 1.0000 - val_loss: 15.5726 - val_accuracy: 0.3250\n",
            "Epoch 266/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.0862e-07 - accuracy: 1.0000 - val_loss: 15.5584 - val_accuracy: 0.3250\n",
            "Epoch 267/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.9536e-07 - accuracy: 1.0000 - val_loss: 15.6023 - val_accuracy: 0.3300\n",
            "Epoch 268/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.9574e-07 - accuracy: 1.0000 - val_loss: 15.6230 - val_accuracy: 0.3300\n",
            "Epoch 269/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 4.8414e-07 - accuracy: 1.0000 - val_loss: 15.6327 - val_accuracy: 0.3300\n",
            "Epoch 270/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.8040e-07 - accuracy: 1.0000 - val_loss: 15.6324 - val_accuracy: 0.3300\n",
            "Epoch 271/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.9350e-07 - accuracy: 1.0000 - val_loss: 15.6543 - val_accuracy: 0.3300\n",
            "Epoch 272/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.6348e-07 - accuracy: 1.0000 - val_loss: 15.6574 - val_accuracy: 0.3300\n",
            "Epoch 273/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.4934e-07 - accuracy: 1.0000 - val_loss: 15.6844 - val_accuracy: 0.3300\n",
            "Epoch 274/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.4886e-07 - accuracy: 1.0000 - val_loss: 15.6850 - val_accuracy: 0.3300\n",
            "Epoch 275/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.4292e-07 - accuracy: 1.0000 - val_loss: 15.6780 - val_accuracy: 0.3300\n",
            "Epoch 276/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.5015e-07 - accuracy: 1.0000 - val_loss: 15.7002 - val_accuracy: 0.3250\n",
            "Epoch 277/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.2477e-07 - accuracy: 1.0000 - val_loss: 15.6580 - val_accuracy: 0.3250\n",
            "Epoch 278/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.1363e-07 - accuracy: 1.0000 - val_loss: 15.7348 - val_accuracy: 0.3300\n",
            "Epoch 279/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.1582e-07 - accuracy: 1.0000 - val_loss: 15.7042 - val_accuracy: 0.3250\n",
            "Epoch 280/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.1029e-07 - accuracy: 1.0000 - val_loss: 15.7154 - val_accuracy: 0.3250\n",
            "Epoch 281/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.0814e-07 - accuracy: 1.0000 - val_loss: 15.7072 - val_accuracy: 0.3250\n",
            "Epoch 282/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.0471e-07 - accuracy: 1.0000 - val_loss: 15.7739 - val_accuracy: 0.3300\n",
            "Epoch 283/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.9404e-07 - accuracy: 1.0000 - val_loss: 15.7735 - val_accuracy: 0.3300\n",
            "Epoch 284/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.7930e-07 - accuracy: 1.0000 - val_loss: 15.7444 - val_accuracy: 0.3250\n",
            "Epoch 285/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.7706e-07 - accuracy: 1.0000 - val_loss: 15.7624 - val_accuracy: 0.3250\n",
            "Epoch 286/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.7742e-07 - accuracy: 1.0000 - val_loss: 15.7930 - val_accuracy: 0.3250\n",
            "Epoch 287/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.6289e-07 - accuracy: 1.0000 - val_loss: 15.7969 - val_accuracy: 0.3250\n",
            "Epoch 288/1000\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 3.5388e-07 - accuracy: 1.0000 - val_loss: 15.8511 - val_accuracy: 0.3300\n",
            "Epoch 289/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.5794e-07 - accuracy: 1.0000 - val_loss: 15.8364 - val_accuracy: 0.3300\n",
            "Epoch 290/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.5352e-07 - accuracy: 1.0000 - val_loss: 15.8818 - val_accuracy: 0.3300\n",
            "Epoch 291/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.4540e-07 - accuracy: 1.0000 - val_loss: 15.8500 - val_accuracy: 0.3250\n",
            "Epoch 292/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.4285e-07 - accuracy: 1.0000 - val_loss: 15.8842 - val_accuracy: 0.3300\n",
            "Epoch 293/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.2751e-07 - accuracy: 1.0000 - val_loss: 15.8630 - val_accuracy: 0.3250\n",
            "Epoch 294/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.3052e-07 - accuracy: 1.0000 - val_loss: 15.8789 - val_accuracy: 0.3250\n",
            "Epoch 295/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.1789e-07 - accuracy: 1.0000 - val_loss: 15.8949 - val_accuracy: 0.3250\n",
            "Epoch 296/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.1676e-07 - accuracy: 1.0000 - val_loss: 15.8914 - val_accuracy: 0.3250\n",
            "Epoch 297/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.1345e-07 - accuracy: 1.0000 - val_loss: 15.8872 - val_accuracy: 0.3250\n",
            "Epoch 298/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.0521e-07 - accuracy: 1.0000 - val_loss: 15.9286 - val_accuracy: 0.3250\n",
            "Epoch 299/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.9995e-07 - accuracy: 1.0000 - val_loss: 15.8811 - val_accuracy: 0.3300\n",
            "Epoch 300/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.2082e-07 - accuracy: 1.0000 - val_loss: 15.8994 - val_accuracy: 0.3300\n",
            "Epoch 301/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.9071e-07 - accuracy: 1.0000 - val_loss: 15.9291 - val_accuracy: 0.3350\n",
            "Epoch 302/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.9745e-07 - accuracy: 1.0000 - val_loss: 15.9155 - val_accuracy: 0.3300\n",
            "Epoch 303/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.9315e-07 - accuracy: 1.0000 - val_loss: 15.9006 - val_accuracy: 0.3300\n",
            "Epoch 304/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.7812e-07 - accuracy: 1.0000 - val_loss: 15.9843 - val_accuracy: 0.3350\n",
            "Epoch 305/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.7276e-07 - accuracy: 1.0000 - val_loss: 16.0144 - val_accuracy: 0.3350\n",
            "Epoch 306/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.7157e-07 - accuracy: 1.0000 - val_loss: 15.9813 - val_accuracy: 0.3250\n",
            "Epoch 307/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.6371e-07 - accuracy: 1.0000 - val_loss: 15.9960 - val_accuracy: 0.3350\n",
            "Epoch 308/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.6335e-07 - accuracy: 1.0000 - val_loss: 16.0060 - val_accuracy: 0.3250\n",
            "Epoch 309/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.5125e-07 - accuracy: 1.0000 - val_loss: 16.0832 - val_accuracy: 0.3300\n",
            "Epoch 310/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.5833e-07 - accuracy: 1.0000 - val_loss: 16.0592 - val_accuracy: 0.3250\n",
            "Epoch 311/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.4716e-07 - accuracy: 1.0000 - val_loss: 16.1046 - val_accuracy: 0.3300\n",
            "Epoch 312/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.5162e-07 - accuracy: 1.0000 - val_loss: 16.0681 - val_accuracy: 0.3250\n",
            "Epoch 313/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.4159e-07 - accuracy: 1.0000 - val_loss: 16.0958 - val_accuracy: 0.3300\n",
            "Epoch 314/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.3887e-07 - accuracy: 1.0000 - val_loss: 16.1179 - val_accuracy: 0.3300\n",
            "Epoch 315/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.3818e-07 - accuracy: 1.0000 - val_loss: 16.0861 - val_accuracy: 0.3300\n",
            "Epoch 316/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.3298e-07 - accuracy: 1.0000 - val_loss: 16.0910 - val_accuracy: 0.3300\n",
            "Epoch 317/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.3187e-07 - accuracy: 1.0000 - val_loss: 16.1010 - val_accuracy: 0.3300\n",
            "Epoch 318/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.2517e-07 - accuracy: 1.0000 - val_loss: 16.1402 - val_accuracy: 0.3350\n",
            "Epoch 319/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.1951e-07 - accuracy: 1.0000 - val_loss: 16.1434 - val_accuracy: 0.3350\n",
            "Epoch 320/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.1714e-07 - accuracy: 1.0000 - val_loss: 16.1609 - val_accuracy: 0.3350\n",
            "Epoch 321/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.1252e-07 - accuracy: 1.0000 - val_loss: 16.1661 - val_accuracy: 0.3350\n",
            "Epoch 322/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.0979e-07 - accuracy: 1.0000 - val_loss: 16.1503 - val_accuracy: 0.3300\n",
            "Epoch 323/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.0679e-07 - accuracy: 1.0000 - val_loss: 16.1708 - val_accuracy: 0.3300\n",
            "Epoch 324/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.0382e-07 - accuracy: 1.0000 - val_loss: 16.2070 - val_accuracy: 0.3350\n",
            "Epoch 325/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.0140e-07 - accuracy: 1.0000 - val_loss: 16.1657 - val_accuracy: 0.3400\n",
            "Epoch 326/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.9758e-07 - accuracy: 1.0000 - val_loss: 16.1805 - val_accuracy: 0.3400\n",
            "Epoch 327/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.9721e-07 - accuracy: 1.0000 - val_loss: 16.1972 - val_accuracy: 0.3350\n",
            "Epoch 328/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.9150e-07 - accuracy: 1.0000 - val_loss: 16.1890 - val_accuracy: 0.3400\n",
            "Epoch 329/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.9150e-07 - accuracy: 1.0000 - val_loss: 16.2337 - val_accuracy: 0.3350\n",
            "Epoch 330/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.8601e-07 - accuracy: 1.0000 - val_loss: 16.2238 - val_accuracy: 0.3350\n",
            "Epoch 331/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.8442e-07 - accuracy: 1.0000 - val_loss: 16.2313 - val_accuracy: 0.3350\n",
            "Epoch 332/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.8057e-07 - accuracy: 1.0000 - val_loss: 16.2264 - val_accuracy: 0.3400\n",
            "Epoch 333/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7931e-07 - accuracy: 1.0000 - val_loss: 16.2808 - val_accuracy: 0.3450\n",
            "Epoch 334/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.7712e-07 - accuracy: 1.0000 - val_loss: 16.2558 - val_accuracy: 0.3400\n",
            "Epoch 335/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.7136e-07 - accuracy: 1.0000 - val_loss: 16.2896 - val_accuracy: 0.3350\n",
            "Epoch 336/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7152e-07 - accuracy: 1.0000 - val_loss: 16.2938 - val_accuracy: 0.3350\n",
            "Epoch 337/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6728e-07 - accuracy: 1.0000 - val_loss: 16.3118 - val_accuracy: 0.3350\n",
            "Epoch 338/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6903e-07 - accuracy: 1.0000 - val_loss: 16.2990 - val_accuracy: 0.3400\n",
            "Epoch 339/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.6713e-07 - accuracy: 1.0000 - val_loss: 16.2847 - val_accuracy: 0.3400\n",
            "Epoch 340/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.6202e-07 - accuracy: 1.0000 - val_loss: 16.3284 - val_accuracy: 0.3400\n",
            "Epoch 341/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5878e-07 - accuracy: 1.0000 - val_loss: 16.3638 - val_accuracy: 0.3350\n",
            "Epoch 342/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.5879e-07 - accuracy: 1.0000 - val_loss: 16.3287 - val_accuracy: 0.3400\n",
            "Epoch 343/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5304e-07 - accuracy: 1.0000 - val_loss: 16.3688 - val_accuracy: 0.3400\n",
            "Epoch 344/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5487e-07 - accuracy: 1.0000 - val_loss: 16.3508 - val_accuracy: 0.3400\n",
            "Epoch 345/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5778e-07 - accuracy: 1.0000 - val_loss: 16.3870 - val_accuracy: 0.3400\n",
            "Epoch 346/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.4724e-07 - accuracy: 1.0000 - val_loss: 16.4172 - val_accuracy: 0.3400\n",
            "Epoch 347/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4955e-07 - accuracy: 1.0000 - val_loss: 16.4170 - val_accuracy: 0.3450\n",
            "Epoch 348/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4266e-07 - accuracy: 1.0000 - val_loss: 16.4167 - val_accuracy: 0.3400\n",
            "Epoch 349/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4279e-07 - accuracy: 1.0000 - val_loss: 16.4534 - val_accuracy: 0.3450\n",
            "Epoch 350/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4273e-07 - accuracy: 1.0000 - val_loss: 16.4752 - val_accuracy: 0.3450\n",
            "Epoch 351/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4808e-07 - accuracy: 1.0000 - val_loss: 16.4395 - val_accuracy: 0.3400\n",
            "Epoch 352/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3815e-07 - accuracy: 1.0000 - val_loss: 16.4634 - val_accuracy: 0.3400\n",
            "Epoch 353/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3581e-07 - accuracy: 1.0000 - val_loss: 16.4328 - val_accuracy: 0.3400\n",
            "Epoch 354/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3416e-07 - accuracy: 1.0000 - val_loss: 16.4963 - val_accuracy: 0.3400\n",
            "Epoch 355/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3152e-07 - accuracy: 1.0000 - val_loss: 16.4634 - val_accuracy: 0.3400\n",
            "Epoch 356/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2857e-07 - accuracy: 1.0000 - val_loss: 16.5020 - val_accuracy: 0.3400\n",
            "Epoch 357/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2505e-07 - accuracy: 1.0000 - val_loss: 16.4578 - val_accuracy: 0.3400\n",
            "Epoch 358/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2433e-07 - accuracy: 1.0000 - val_loss: 16.4907 - val_accuracy: 0.3400\n",
            "Epoch 359/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2265e-07 - accuracy: 1.0000 - val_loss: 16.5230 - val_accuracy: 0.3400\n",
            "Epoch 360/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2089e-07 - accuracy: 1.0000 - val_loss: 16.5306 - val_accuracy: 0.3400\n",
            "Epoch 361/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1878e-07 - accuracy: 1.0000 - val_loss: 16.5286 - val_accuracy: 0.3400\n",
            "Epoch 362/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1662e-07 - accuracy: 1.0000 - val_loss: 16.5495 - val_accuracy: 0.3400\n",
            "Epoch 363/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1616e-07 - accuracy: 1.0000 - val_loss: 16.5896 - val_accuracy: 0.3400\n",
            "Epoch 364/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1443e-07 - accuracy: 1.0000 - val_loss: 16.5784 - val_accuracy: 0.3400\n",
            "Epoch 365/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1080e-07 - accuracy: 1.0000 - val_loss: 16.5632 - val_accuracy: 0.3400\n",
            "Epoch 366/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1016e-07 - accuracy: 1.0000 - val_loss: 16.5791 - val_accuracy: 0.3400\n",
            "Epoch 367/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.0981e-07 - accuracy: 1.0000 - val_loss: 16.5254 - val_accuracy: 0.3400\n",
            "Epoch 368/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0757e-07 - accuracy: 1.0000 - val_loss: 16.5944 - val_accuracy: 0.3400\n",
            "Epoch 369/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0764e-07 - accuracy: 1.0000 - val_loss: 16.6314 - val_accuracy: 0.3400\n",
            "Epoch 370/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0584e-07 - accuracy: 1.0000 - val_loss: 16.6163 - val_accuracy: 0.3400\n",
            "Epoch 371/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0933e-07 - accuracy: 1.0000 - val_loss: 16.6352 - val_accuracy: 0.3400\n",
            "Epoch 372/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0311e-07 - accuracy: 1.0000 - val_loss: 16.6408 - val_accuracy: 0.3400\n",
            "Epoch 373/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0019e-07 - accuracy: 1.0000 - val_loss: 16.6235 - val_accuracy: 0.3400\n",
            "Epoch 374/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.9108e-08 - accuracy: 1.0000 - val_loss: 16.6319 - val_accuracy: 0.3400\n",
            "Epoch 375/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.9844e-08 - accuracy: 1.0000 - val_loss: 16.6277 - val_accuracy: 0.3450\n",
            "Epoch 376/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.6297e-08 - accuracy: 1.0000 - val_loss: 16.6792 - val_accuracy: 0.3400\n",
            "Epoch 377/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.5551e-08 - accuracy: 1.0000 - val_loss: 16.6959 - val_accuracy: 0.3400\n",
            "Epoch 378/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.4027e-08 - accuracy: 1.0000 - val_loss: 16.6606 - val_accuracy: 0.3400\n",
            "Epoch 379/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.2715e-08 - accuracy: 1.0000 - val_loss: 16.6527 - val_accuracy: 0.3400\n",
            "Epoch 380/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.8459e-08 - accuracy: 1.0000 - val_loss: 16.7299 - val_accuracy: 0.3350\n",
            "Epoch 381/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.1781e-08 - accuracy: 1.0000 - val_loss: 16.7124 - val_accuracy: 0.3400\n",
            "Epoch 382/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.8266e-08 - accuracy: 1.0000 - val_loss: 16.7618 - val_accuracy: 0.3400\n",
            "Epoch 383/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.8997e-08 - accuracy: 1.0000 - val_loss: 16.7103 - val_accuracy: 0.3400\n",
            "Epoch 384/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.7213e-08 - accuracy: 1.0000 - val_loss: 16.7253 - val_accuracy: 0.3400\n",
            "Epoch 385/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.6443e-08 - accuracy: 1.0000 - val_loss: 16.7722 - val_accuracy: 0.3400\n",
            "Epoch 386/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.4998e-08 - accuracy: 1.0000 - val_loss: 16.7442 - val_accuracy: 0.3400\n",
            "Epoch 387/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.3869e-08 - accuracy: 1.0000 - val_loss: 16.7610 - val_accuracy: 0.3400\n",
            "Epoch 388/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.0957e-08 - accuracy: 1.0000 - val_loss: 16.8090 - val_accuracy: 0.3400\n",
            "Epoch 389/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.5483e-08 - accuracy: 1.0000 - val_loss: 16.8380 - val_accuracy: 0.3400\n",
            "Epoch 390/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.3455e-08 - accuracy: 1.0000 - val_loss: 16.8190 - val_accuracy: 0.3400\n",
            "Epoch 391/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.9220e-08 - accuracy: 1.0000 - val_loss: 16.8212 - val_accuracy: 0.3400\n",
            "Epoch 392/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.9090e-08 - accuracy: 1.0000 - val_loss: 16.8279 - val_accuracy: 0.3400\n",
            "Epoch 393/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.8310e-08 - accuracy: 1.0000 - val_loss: 16.7898 - val_accuracy: 0.3450\n",
            "Epoch 394/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.4998e-08 - accuracy: 1.0000 - val_loss: 16.8330 - val_accuracy: 0.3400\n",
            "Epoch 395/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.4527e-08 - accuracy: 1.0000 - val_loss: 16.8244 - val_accuracy: 0.3400\n",
            "Epoch 396/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.4122e-08 - accuracy: 1.0000 - val_loss: 16.8600 - val_accuracy: 0.3400\n",
            "Epoch 397/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.4066e-08 - accuracy: 1.0000 - val_loss: 16.8338 - val_accuracy: 0.3400\n",
            "Epoch 398/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 7.2389e-08 - accuracy: 1.0000 - val_loss: 16.8592 - val_accuracy: 0.3400\n",
            "Epoch 399/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.1476e-08 - accuracy: 1.0000 - val_loss: 16.8822 - val_accuracy: 0.3400\n",
            "Epoch 400/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 7.0534e-08 - accuracy: 1.0000 - val_loss: 16.8686 - val_accuracy: 0.3400\n",
            "Epoch 401/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.0608e-08 - accuracy: 1.0000 - val_loss: 16.8784 - val_accuracy: 0.3450\n",
            "Epoch 402/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.7857e-08 - accuracy: 1.0000 - val_loss: 16.8927 - val_accuracy: 0.3400\n",
            "Epoch 403/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.8075e-08 - accuracy: 1.0000 - val_loss: 16.8728 - val_accuracy: 0.3400\n",
            "Epoch 404/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.7758e-08 - accuracy: 1.0000 - val_loss: 16.9024 - val_accuracy: 0.3450\n",
            "Epoch 405/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.6627e-08 - accuracy: 1.0000 - val_loss: 16.9295 - val_accuracy: 0.3400\n",
            "Epoch 406/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.5415e-08 - accuracy: 1.0000 - val_loss: 16.9176 - val_accuracy: 0.3400\n",
            "Epoch 407/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.6700e-08 - accuracy: 1.0000 - val_loss: 16.9563 - val_accuracy: 0.3450\n",
            "Epoch 408/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.5198e-08 - accuracy: 1.0000 - val_loss: 16.9182 - val_accuracy: 0.3400\n",
            "Epoch 409/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.2632e-08 - accuracy: 1.0000 - val_loss: 16.9419 - val_accuracy: 0.3450\n",
            "Epoch 410/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 6.1543e-08 - accuracy: 1.0000 - val_loss: 16.9684 - val_accuracy: 0.3400\n",
            "Epoch 411/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.2185e-08 - accuracy: 1.0000 - val_loss: 16.9436 - val_accuracy: 0.3450\n",
            "Epoch 412/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.9872e-08 - accuracy: 1.0000 - val_loss: 16.9950 - val_accuracy: 0.3450\n",
            "Epoch 413/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.1576e-08 - accuracy: 1.0000 - val_loss: 16.9792 - val_accuracy: 0.3450\n",
            "Epoch 414/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.8456e-08 - accuracy: 1.0000 - val_loss: 17.0080 - val_accuracy: 0.3450\n",
            "Epoch 415/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.7831e-08 - accuracy: 1.0000 - val_loss: 17.0039 - val_accuracy: 0.3450\n",
            "Epoch 416/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.8454e-08 - accuracy: 1.0000 - val_loss: 17.0281 - val_accuracy: 0.3450\n",
            "Epoch 417/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.7404e-08 - accuracy: 1.0000 - val_loss: 17.0104 - val_accuracy: 0.3450\n",
            "Epoch 418/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.5756e-08 - accuracy: 1.0000 - val_loss: 17.0339 - val_accuracy: 0.3450\n",
            "Epoch 419/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.5428e-08 - accuracy: 1.0000 - val_loss: 17.0635 - val_accuracy: 0.3400\n",
            "Epoch 420/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.5588e-08 - accuracy: 1.0000 - val_loss: 17.0273 - val_accuracy: 0.3450\n",
            "Epoch 421/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.4249e-08 - accuracy: 1.0000 - val_loss: 17.0565 - val_accuracy: 0.3450\n",
            "Epoch 422/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.4638e-08 - accuracy: 1.0000 - val_loss: 17.0805 - val_accuracy: 0.3450\n",
            "Epoch 423/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.2484e-08 - accuracy: 1.0000 - val_loss: 17.0960 - val_accuracy: 0.3450\n",
            "Epoch 424/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.4141e-08 - accuracy: 1.0000 - val_loss: 17.0844 - val_accuracy: 0.3450\n",
            "Epoch 425/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.2196e-08 - accuracy: 1.0000 - val_loss: 17.0867 - val_accuracy: 0.3450\n",
            "Epoch 426/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.1689e-08 - accuracy: 1.0000 - val_loss: 17.1081 - val_accuracy: 0.3450\n",
            "Epoch 427/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.1811e-08 - accuracy: 1.0000 - val_loss: 17.1075 - val_accuracy: 0.3450\n",
            "Epoch 428/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.9629e-08 - accuracy: 1.0000 - val_loss: 17.1369 - val_accuracy: 0.3400\n",
            "Epoch 429/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.8745e-08 - accuracy: 1.0000 - val_loss: 17.1375 - val_accuracy: 0.3450\n",
            "Epoch 430/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.9810e-08 - accuracy: 1.0000 - val_loss: 17.1217 - val_accuracy: 0.3450\n",
            "Epoch 431/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.8758e-08 - accuracy: 1.0000 - val_loss: 17.1247 - val_accuracy: 0.3450\n",
            "Epoch 432/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.7327e-08 - accuracy: 1.0000 - val_loss: 17.1498 - val_accuracy: 0.3400\n",
            "Epoch 433/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.6667e-08 - accuracy: 1.0000 - val_loss: 17.1456 - val_accuracy: 0.3450\n",
            "Epoch 434/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.6848e-08 - accuracy: 1.0000 - val_loss: 17.1342 - val_accuracy: 0.3450\n",
            "Epoch 435/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.8384e-08 - accuracy: 1.0000 - val_loss: 17.1325 - val_accuracy: 0.3450\n",
            "Epoch 436/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.7550e-08 - accuracy: 1.0000 - val_loss: 17.1892 - val_accuracy: 0.3450\n",
            "Epoch 437/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.6113e-08 - accuracy: 1.0000 - val_loss: 17.1862 - val_accuracy: 0.3450\n",
            "Epoch 438/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.4567e-08 - accuracy: 1.0000 - val_loss: 17.2034 - val_accuracy: 0.3450\n",
            "Epoch 439/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.3874e-08 - accuracy: 1.0000 - val_loss: 17.1923 - val_accuracy: 0.3450\n",
            "Epoch 440/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.3171e-08 - accuracy: 1.0000 - val_loss: 17.2087 - val_accuracy: 0.3450\n",
            "Epoch 441/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.3139e-08 - accuracy: 1.0000 - val_loss: 17.1945 - val_accuracy: 0.3450\n",
            "Epoch 442/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.2295e-08 - accuracy: 1.0000 - val_loss: 17.2023 - val_accuracy: 0.3450\n",
            "Epoch 443/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.2117e-08 - accuracy: 1.0000 - val_loss: 17.2214 - val_accuracy: 0.3450\n",
            "Epoch 444/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.1116e-08 - accuracy: 1.0000 - val_loss: 17.2621 - val_accuracy: 0.3400\n",
            "Epoch 445/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.1847e-08 - accuracy: 1.0000 - val_loss: 17.2406 - val_accuracy: 0.3400\n",
            "Epoch 446/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.0767e-08 - accuracy: 1.0000 - val_loss: 17.2603 - val_accuracy: 0.3400\n",
            "Epoch 447/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 4.1113e-08 - accuracy: 1.0000 - val_loss: 17.2539 - val_accuracy: 0.3450\n",
            "Epoch 448/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 4.0879e-08 - accuracy: 1.0000 - val_loss: 17.2212 - val_accuracy: 0.3450\n",
            "Epoch 449/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.9531e-08 - accuracy: 1.0000 - val_loss: 17.2705 - val_accuracy: 0.3450\n",
            "Epoch 450/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.0132e-08 - accuracy: 1.0000 - val_loss: 17.2895 - val_accuracy: 0.3400\n",
            "Epoch 451/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 4.0035e-08 - accuracy: 1.0000 - val_loss: 17.2866 - val_accuracy: 0.3450\n",
            "Epoch 452/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.8104e-08 - accuracy: 1.0000 - val_loss: 17.3104 - val_accuracy: 0.3400\n",
            "Epoch 453/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.8110e-08 - accuracy: 1.0000 - val_loss: 17.2574 - val_accuracy: 0.3450\n",
            "Epoch 454/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.8650e-08 - accuracy: 1.0000 - val_loss: 17.2886 - val_accuracy: 0.3450\n",
            "Epoch 455/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 3.6398e-08 - accuracy: 1.0000 - val_loss: 17.3067 - val_accuracy: 0.3450\n",
            "Epoch 456/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.6905e-08 - accuracy: 1.0000 - val_loss: 17.3483 - val_accuracy: 0.3400\n",
            "Epoch 457/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.7478e-08 - accuracy: 1.0000 - val_loss: 17.3571 - val_accuracy: 0.3400\n",
            "Epoch 458/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 3.5707e-08 - accuracy: 1.0000 - val_loss: 17.3684 - val_accuracy: 0.3400\n",
            "Epoch 459/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.5523e-08 - accuracy: 1.0000 - val_loss: 17.3469 - val_accuracy: 0.3400\n",
            "Epoch 460/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.7044e-08 - accuracy: 1.0000 - val_loss: 17.3589 - val_accuracy: 0.3450\n",
            "Epoch 461/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.5492e-08 - accuracy: 1.0000 - val_loss: 17.3727 - val_accuracy: 0.3400\n",
            "Epoch 462/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.6827e-08 - accuracy: 1.0000 - val_loss: 17.3858 - val_accuracy: 0.3350\n",
            "Epoch 463/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.3808e-08 - accuracy: 1.0000 - val_loss: 17.3898 - val_accuracy: 0.3350\n",
            "Epoch 464/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.3341e-08 - accuracy: 1.0000 - val_loss: 17.4191 - val_accuracy: 0.3350\n",
            "Epoch 465/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.3378e-08 - accuracy: 1.0000 - val_loss: 17.3967 - val_accuracy: 0.3350\n",
            "Epoch 466/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.3045e-08 - accuracy: 1.0000 - val_loss: 17.3732 - val_accuracy: 0.3450\n",
            "Epoch 467/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.2970e-08 - accuracy: 1.0000 - val_loss: 17.4282 - val_accuracy: 0.3400\n",
            "Epoch 468/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.1785e-08 - accuracy: 1.0000 - val_loss: 17.4370 - val_accuracy: 0.3350\n",
            "Epoch 469/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.1830e-08 - accuracy: 1.0000 - val_loss: 17.4591 - val_accuracy: 0.3350\n",
            "Epoch 470/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 3.1519e-08 - accuracy: 1.0000 - val_loss: 17.4430 - val_accuracy: 0.3400\n",
            "Epoch 471/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.1115e-08 - accuracy: 1.0000 - val_loss: 17.4585 - val_accuracy: 0.3400\n",
            "Epoch 472/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.1021e-08 - accuracy: 1.0000 - val_loss: 17.4645 - val_accuracy: 0.3350\n",
            "Epoch 473/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.1374e-08 - accuracy: 1.0000 - val_loss: 17.4404 - val_accuracy: 0.3450\n",
            "Epoch 474/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.0156e-08 - accuracy: 1.0000 - val_loss: 17.4819 - val_accuracy: 0.3400\n",
            "Epoch 475/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.9795e-08 - accuracy: 1.0000 - val_loss: 17.4793 - val_accuracy: 0.3400\n",
            "Epoch 476/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.0197e-08 - accuracy: 1.0000 - val_loss: 17.4558 - val_accuracy: 0.3450\n",
            "Epoch 477/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.9056e-08 - accuracy: 1.0000 - val_loss: 17.5365 - val_accuracy: 0.3400\n",
            "Epoch 478/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.9349e-08 - accuracy: 1.0000 - val_loss: 17.5122 - val_accuracy: 0.3400\n",
            "Epoch 479/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.9356e-08 - accuracy: 1.0000 - val_loss: 17.5208 - val_accuracy: 0.3400\n",
            "Epoch 480/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.8330e-08 - accuracy: 1.0000 - val_loss: 17.5151 - val_accuracy: 0.3400\n",
            "Epoch 481/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.8691e-08 - accuracy: 1.0000 - val_loss: 17.5646 - val_accuracy: 0.3350\n",
            "Epoch 482/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.7782e-08 - accuracy: 1.0000 - val_loss: 17.5530 - val_accuracy: 0.3400\n",
            "Epoch 483/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.7752e-08 - accuracy: 1.0000 - val_loss: 17.5439 - val_accuracy: 0.3400\n",
            "Epoch 484/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.7616e-08 - accuracy: 1.0000 - val_loss: 17.5506 - val_accuracy: 0.3400\n",
            "Epoch 485/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.6794e-08 - accuracy: 1.0000 - val_loss: 17.5268 - val_accuracy: 0.3450\n",
            "Epoch 486/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.9714e-08 - accuracy: 1.0000 - val_loss: 17.5434 - val_accuracy: 0.3450\n",
            "Epoch 487/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.7339e-08 - accuracy: 1.0000 - val_loss: 17.5540 - val_accuracy: 0.3450\n",
            "Epoch 488/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.6489e-08 - accuracy: 1.0000 - val_loss: 17.5673 - val_accuracy: 0.3400\n",
            "Epoch 489/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.6424e-08 - accuracy: 1.0000 - val_loss: 17.6070 - val_accuracy: 0.3400\n",
            "Epoch 490/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.6322e-08 - accuracy: 1.0000 - val_loss: 17.6259 - val_accuracy: 0.3400\n",
            "Epoch 491/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.5919e-08 - accuracy: 1.0000 - val_loss: 17.6142 - val_accuracy: 0.3400\n",
            "Epoch 492/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.5691e-08 - accuracy: 1.0000 - val_loss: 17.6023 - val_accuracy: 0.3400\n",
            "Epoch 493/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.5389e-08 - accuracy: 1.0000 - val_loss: 17.6195 - val_accuracy: 0.3400\n",
            "Epoch 494/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.5015e-08 - accuracy: 1.0000 - val_loss: 17.6109 - val_accuracy: 0.3400\n",
            "Epoch 495/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.5014e-08 - accuracy: 1.0000 - val_loss: 17.6544 - val_accuracy: 0.3400\n",
            "Epoch 496/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.4763e-08 - accuracy: 1.0000 - val_loss: 17.6656 - val_accuracy: 0.3350\n",
            "Epoch 497/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.5066e-08 - accuracy: 1.0000 - val_loss: 17.6947 - val_accuracy: 0.3350\n",
            "Epoch 498/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.4561e-08 - accuracy: 1.0000 - val_loss: 17.6942 - val_accuracy: 0.3400\n",
            "Epoch 499/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.3885e-08 - accuracy: 1.0000 - val_loss: 17.6613 - val_accuracy: 0.3400\n",
            "Epoch 500/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.3982e-08 - accuracy: 1.0000 - val_loss: 17.6620 - val_accuracy: 0.3450\n",
            "Epoch 501/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.3936e-08 - accuracy: 1.0000 - val_loss: 17.6766 - val_accuracy: 0.3400\n",
            "Epoch 502/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.4240e-08 - accuracy: 1.0000 - val_loss: 17.7290 - val_accuracy: 0.3400\n",
            "Epoch 503/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.3107e-08 - accuracy: 1.0000 - val_loss: 17.7334 - val_accuracy: 0.3300\n",
            "Epoch 504/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.3160e-08 - accuracy: 1.0000 - val_loss: 17.7332 - val_accuracy: 0.3400\n",
            "Epoch 505/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.2689e-08 - accuracy: 1.0000 - val_loss: 17.6966 - val_accuracy: 0.3450\n",
            "Epoch 506/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.2510e-08 - accuracy: 1.0000 - val_loss: 17.7483 - val_accuracy: 0.3350\n",
            "Epoch 507/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.2261e-08 - accuracy: 1.0000 - val_loss: 17.7434 - val_accuracy: 0.3400\n",
            "Epoch 508/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.2138e-08 - accuracy: 1.0000 - val_loss: 17.7906 - val_accuracy: 0.3350\n",
            "Epoch 509/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.1967e-08 - accuracy: 1.0000 - val_loss: 17.7456 - val_accuracy: 0.3450\n",
            "Epoch 510/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.1730e-08 - accuracy: 1.0000 - val_loss: 17.7710 - val_accuracy: 0.3350\n",
            "Epoch 511/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.1377e-08 - accuracy: 1.0000 - val_loss: 17.7415 - val_accuracy: 0.3450\n",
            "Epoch 512/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.1355e-08 - accuracy: 1.0000 - val_loss: 17.7915 - val_accuracy: 0.3350\n",
            "Epoch 513/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.2003e-08 - accuracy: 1.0000 - val_loss: 17.8117 - val_accuracy: 0.3350\n",
            "Epoch 514/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.0965e-08 - accuracy: 1.0000 - val_loss: 17.7726 - val_accuracy: 0.3300\n",
            "Epoch 515/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.0781e-08 - accuracy: 1.0000 - val_loss: 17.7799 - val_accuracy: 0.3400\n",
            "Epoch 516/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.1007e-08 - accuracy: 1.0000 - val_loss: 17.8350 - val_accuracy: 0.3350\n",
            "Epoch 517/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 2.0406e-08 - accuracy: 1.0000 - val_loss: 17.8106 - val_accuracy: 0.3350\n",
            "Epoch 518/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 2.0440e-08 - accuracy: 1.0000 - val_loss: 17.8108 - val_accuracy: 0.3350\n",
            "Epoch 519/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.0261e-08 - accuracy: 1.0000 - val_loss: 17.8329 - val_accuracy: 0.3350\n",
            "Epoch 520/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.0233e-08 - accuracy: 1.0000 - val_loss: 17.8132 - val_accuracy: 0.3450\n",
            "Epoch 521/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.9821e-08 - accuracy: 1.0000 - val_loss: 17.8707 - val_accuracy: 0.3350\n",
            "Epoch 522/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.0087e-08 - accuracy: 1.0000 - val_loss: 17.8924 - val_accuracy: 0.3350\n",
            "Epoch 523/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.9908e-08 - accuracy: 1.0000 - val_loss: 17.8670 - val_accuracy: 0.3300\n",
            "Epoch 524/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.9517e-08 - accuracy: 1.0000 - val_loss: 17.8486 - val_accuracy: 0.3350\n",
            "Epoch 525/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.9140e-08 - accuracy: 1.0000 - val_loss: 17.8936 - val_accuracy: 0.3350\n",
            "Epoch 526/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.9123e-08 - accuracy: 1.0000 - val_loss: 17.8798 - val_accuracy: 0.3350\n",
            "Epoch 527/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.8784e-08 - accuracy: 1.0000 - val_loss: 17.8685 - val_accuracy: 0.3450\n",
            "Epoch 528/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.8957e-08 - accuracy: 1.0000 - val_loss: 17.8776 - val_accuracy: 0.3350\n",
            "Epoch 529/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.9353e-08 - accuracy: 1.0000 - val_loss: 17.8668 - val_accuracy: 0.3450\n",
            "Epoch 530/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.8948e-08 - accuracy: 1.0000 - val_loss: 17.9052 - val_accuracy: 0.3400\n",
            "Epoch 531/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.8534e-08 - accuracy: 1.0000 - val_loss: 17.8936 - val_accuracy: 0.3350\n",
            "Epoch 532/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.8619e-08 - accuracy: 1.0000 - val_loss: 17.8956 - val_accuracy: 0.3450\n",
            "Epoch 533/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.8486e-08 - accuracy: 1.0000 - val_loss: 17.9004 - val_accuracy: 0.3400\n",
            "Epoch 534/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7941e-08 - accuracy: 1.0000 - val_loss: 17.9559 - val_accuracy: 0.3400\n",
            "Epoch 535/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.8036e-08 - accuracy: 1.0000 - val_loss: 17.9472 - val_accuracy: 0.3300\n",
            "Epoch 536/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.7900e-08 - accuracy: 1.0000 - val_loss: 17.9404 - val_accuracy: 0.3300\n",
            "Epoch 537/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.7818e-08 - accuracy: 1.0000 - val_loss: 17.9350 - val_accuracy: 0.3400\n",
            "Epoch 538/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.7681e-08 - accuracy: 1.0000 - val_loss: 17.9504 - val_accuracy: 0.3400\n",
            "Epoch 539/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7228e-08 - accuracy: 1.0000 - val_loss: 17.9447 - val_accuracy: 0.3400\n",
            "Epoch 540/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.7124e-08 - accuracy: 1.0000 - val_loss: 17.9699 - val_accuracy: 0.3350\n",
            "Epoch 541/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6950e-08 - accuracy: 1.0000 - val_loss: 17.9699 - val_accuracy: 0.3300\n",
            "Epoch 542/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.6980e-08 - accuracy: 1.0000 - val_loss: 17.9799 - val_accuracy: 0.3300\n",
            "Epoch 543/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.6610e-08 - accuracy: 1.0000 - val_loss: 17.9781 - val_accuracy: 0.3300\n",
            "Epoch 544/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.6721e-08 - accuracy: 1.0000 - val_loss: 17.9637 - val_accuracy: 0.3300\n",
            "Epoch 545/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6666e-08 - accuracy: 1.0000 - val_loss: 18.0054 - val_accuracy: 0.3350\n",
            "Epoch 546/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.6198e-08 - accuracy: 1.0000 - val_loss: 17.9743 - val_accuracy: 0.3450\n",
            "Epoch 547/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.6356e-08 - accuracy: 1.0000 - val_loss: 17.9883 - val_accuracy: 0.3350\n",
            "Epoch 548/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6045e-08 - accuracy: 1.0000 - val_loss: 18.0347 - val_accuracy: 0.3350\n",
            "Epoch 549/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.5926e-08 - accuracy: 1.0000 - val_loss: 18.0111 - val_accuracy: 0.3300\n",
            "Epoch 550/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.6008e-08 - accuracy: 1.0000 - val_loss: 18.0066 - val_accuracy: 0.3400\n",
            "Epoch 551/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.5866e-08 - accuracy: 1.0000 - val_loss: 18.0231 - val_accuracy: 0.3350\n",
            "Epoch 552/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.5828e-08 - accuracy: 1.0000 - val_loss: 18.0306 - val_accuracy: 0.3350\n",
            "Epoch 553/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5701e-08 - accuracy: 1.0000 - val_loss: 18.0372 - val_accuracy: 0.3350\n",
            "Epoch 554/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5604e-08 - accuracy: 1.0000 - val_loss: 18.0644 - val_accuracy: 0.3350\n",
            "Epoch 555/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5725e-08 - accuracy: 1.0000 - val_loss: 18.0752 - val_accuracy: 0.3350\n",
            "Epoch 556/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.5343e-08 - accuracy: 1.0000 - val_loss: 18.0796 - val_accuracy: 0.3350\n",
            "Epoch 557/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.5043e-08 - accuracy: 1.0000 - val_loss: 18.0459 - val_accuracy: 0.3400\n",
            "Epoch 558/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.6049e-08 - accuracy: 1.0000 - val_loss: 18.0543 - val_accuracy: 0.3300\n",
            "Epoch 559/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4916e-08 - accuracy: 1.0000 - val_loss: 18.0942 - val_accuracy: 0.3350\n",
            "Epoch 560/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.5005e-08 - accuracy: 1.0000 - val_loss: 18.0999 - val_accuracy: 0.3350\n",
            "Epoch 561/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.4741e-08 - accuracy: 1.0000 - val_loss: 18.0917 - val_accuracy: 0.3350\n",
            "Epoch 562/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4727e-08 - accuracy: 1.0000 - val_loss: 18.0679 - val_accuracy: 0.3300\n",
            "Epoch 563/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4790e-08 - accuracy: 1.0000 - val_loss: 18.0524 - val_accuracy: 0.3400\n",
            "Epoch 564/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4682e-08 - accuracy: 1.0000 - val_loss: 18.0953 - val_accuracy: 0.3350\n",
            "Epoch 565/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4474e-08 - accuracy: 1.0000 - val_loss: 18.1001 - val_accuracy: 0.3350\n",
            "Epoch 566/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.4796e-08 - accuracy: 1.0000 - val_loss: 18.0857 - val_accuracy: 0.3400\n",
            "Epoch 567/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.4384e-08 - accuracy: 1.0000 - val_loss: 18.1010 - val_accuracy: 0.3300\n",
            "Epoch 568/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.4274e-08 - accuracy: 1.0000 - val_loss: 18.1550 - val_accuracy: 0.3350\n",
            "Epoch 569/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4320e-08 - accuracy: 1.0000 - val_loss: 18.1461 - val_accuracy: 0.3350\n",
            "Epoch 570/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.4216e-08 - accuracy: 1.0000 - val_loss: 18.1162 - val_accuracy: 0.3400\n",
            "Epoch 571/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.4134e-08 - accuracy: 1.0000 - val_loss: 18.1390 - val_accuracy: 0.3400\n",
            "Epoch 572/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3700e-08 - accuracy: 1.0000 - val_loss: 18.1447 - val_accuracy: 0.3350\n",
            "Epoch 573/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3609e-08 - accuracy: 1.0000 - val_loss: 18.1517 - val_accuracy: 0.3350\n",
            "Epoch 574/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3583e-08 - accuracy: 1.0000 - val_loss: 18.1834 - val_accuracy: 0.3350\n",
            "Epoch 575/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.3619e-08 - accuracy: 1.0000 - val_loss: 18.1532 - val_accuracy: 0.3400\n",
            "Epoch 576/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3399e-08 - accuracy: 1.0000 - val_loss: 18.1712 - val_accuracy: 0.3350\n",
            "Epoch 577/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3469e-08 - accuracy: 1.0000 - val_loss: 18.1941 - val_accuracy: 0.3350\n",
            "Epoch 578/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.3884e-08 - accuracy: 1.0000 - val_loss: 18.2145 - val_accuracy: 0.3350\n",
            "Epoch 579/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.3273e-08 - accuracy: 1.0000 - val_loss: 18.1886 - val_accuracy: 0.3350\n",
            "Epoch 580/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.3202e-08 - accuracy: 1.0000 - val_loss: 18.1912 - val_accuracy: 0.3350\n",
            "Epoch 581/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.3700e-08 - accuracy: 1.0000 - val_loss: 18.1978 - val_accuracy: 0.3350\n",
            "Epoch 582/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2932e-08 - accuracy: 1.0000 - val_loss: 18.2279 - val_accuracy: 0.3350\n",
            "Epoch 583/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.3005e-08 - accuracy: 1.0000 - val_loss: 18.2052 - val_accuracy: 0.3300\n",
            "Epoch 584/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2729e-08 - accuracy: 1.0000 - val_loss: 18.2009 - val_accuracy: 0.3350\n",
            "Epoch 585/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2643e-08 - accuracy: 1.0000 - val_loss: 18.2022 - val_accuracy: 0.3350\n",
            "Epoch 586/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2711e-08 - accuracy: 1.0000 - val_loss: 18.1757 - val_accuracy: 0.3350\n",
            "Epoch 587/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.2446e-08 - accuracy: 1.0000 - val_loss: 18.2510 - val_accuracy: 0.3350\n",
            "Epoch 588/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.2586e-08 - accuracy: 1.0000 - val_loss: 18.2137 - val_accuracy: 0.3350\n",
            "Epoch 589/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2318e-08 - accuracy: 1.0000 - val_loss: 18.2237 - val_accuracy: 0.3350\n",
            "Epoch 590/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2361e-08 - accuracy: 1.0000 - val_loss: 18.2176 - val_accuracy: 0.3300\n",
            "Epoch 591/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2251e-08 - accuracy: 1.0000 - val_loss: 18.2399 - val_accuracy: 0.3350\n",
            "Epoch 592/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2165e-08 - accuracy: 1.0000 - val_loss: 18.2357 - val_accuracy: 0.3350\n",
            "Epoch 593/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.2066e-08 - accuracy: 1.0000 - val_loss: 18.2521 - val_accuracy: 0.3400\n",
            "Epoch 594/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.2109e-08 - accuracy: 1.0000 - val_loss: 18.2454 - val_accuracy: 0.3350\n",
            "Epoch 595/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.2058e-08 - accuracy: 1.0000 - val_loss: 18.2377 - val_accuracy: 0.3350\n",
            "Epoch 596/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1833e-08 - accuracy: 1.0000 - val_loss: 18.2478 - val_accuracy: 0.3300\n",
            "Epoch 597/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.1801e-08 - accuracy: 1.0000 - val_loss: 18.2236 - val_accuracy: 0.3350\n",
            "Epoch 598/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1952e-08 - accuracy: 1.0000 - val_loss: 18.2656 - val_accuracy: 0.3350\n",
            "Epoch 599/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1876e-08 - accuracy: 1.0000 - val_loss: 18.2596 - val_accuracy: 0.3350\n",
            "Epoch 600/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1737e-08 - accuracy: 1.0000 - val_loss: 18.2346 - val_accuracy: 0.3400\n",
            "Epoch 601/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1858e-08 - accuracy: 1.0000 - val_loss: 18.2577 - val_accuracy: 0.3350\n",
            "Epoch 602/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1600e-08 - accuracy: 1.0000 - val_loss: 18.2750 - val_accuracy: 0.3300\n",
            "Epoch 603/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1477e-08 - accuracy: 1.0000 - val_loss: 18.3085 - val_accuracy: 0.3350\n",
            "Epoch 604/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1370e-08 - accuracy: 1.0000 - val_loss: 18.2849 - val_accuracy: 0.3350\n",
            "Epoch 605/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1395e-08 - accuracy: 1.0000 - val_loss: 18.2927 - val_accuracy: 0.3400\n",
            "Epoch 606/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1416e-08 - accuracy: 1.0000 - val_loss: 18.2949 - val_accuracy: 0.3300\n",
            "Epoch 607/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1200e-08 - accuracy: 1.0000 - val_loss: 18.3097 - val_accuracy: 0.3350\n",
            "Epoch 608/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1085e-08 - accuracy: 1.0000 - val_loss: 18.2883 - val_accuracy: 0.3350\n",
            "Epoch 609/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.1307e-08 - accuracy: 1.0000 - val_loss: 18.3335 - val_accuracy: 0.3350\n",
            "Epoch 610/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1121e-08 - accuracy: 1.0000 - val_loss: 18.3270 - val_accuracy: 0.3350\n",
            "Epoch 611/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1092e-08 - accuracy: 1.0000 - val_loss: 18.3336 - val_accuracy: 0.3350\n",
            "Epoch 612/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.1159e-08 - accuracy: 1.0000 - val_loss: 18.3461 - val_accuracy: 0.3350\n",
            "Epoch 613/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0923e-08 - accuracy: 1.0000 - val_loss: 18.3188 - val_accuracy: 0.3300\n",
            "Epoch 614/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0888e-08 - accuracy: 1.0000 - val_loss: 18.3298 - val_accuracy: 0.3300\n",
            "Epoch 615/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0897e-08 - accuracy: 1.0000 - val_loss: 18.3271 - val_accuracy: 0.3300\n",
            "Epoch 616/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0805e-08 - accuracy: 1.0000 - val_loss: 18.3247 - val_accuracy: 0.3350\n",
            "Epoch 617/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0725e-08 - accuracy: 1.0000 - val_loss: 18.3502 - val_accuracy: 0.3350\n",
            "Epoch 618/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0757e-08 - accuracy: 1.0000 - val_loss: 18.3539 - val_accuracy: 0.3350\n",
            "Epoch 619/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.0814e-08 - accuracy: 1.0000 - val_loss: 18.3897 - val_accuracy: 0.3350\n",
            "Epoch 620/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0707e-08 - accuracy: 1.0000 - val_loss: 18.3681 - val_accuracy: 0.3350\n",
            "Epoch 621/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0470e-08 - accuracy: 1.0000 - val_loss: 18.3263 - val_accuracy: 0.3350\n",
            "Epoch 622/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0544e-08 - accuracy: 1.0000 - val_loss: 18.3590 - val_accuracy: 0.3350\n",
            "Epoch 623/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.0665e-08 - accuracy: 1.0000 - val_loss: 18.3650 - val_accuracy: 0.3350\n",
            "Epoch 624/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0469e-08 - accuracy: 1.0000 - val_loss: 18.3611 - val_accuracy: 0.3400\n",
            "Epoch 625/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0439e-08 - accuracy: 1.0000 - val_loss: 18.3586 - val_accuracy: 0.3300\n",
            "Epoch 626/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0287e-08 - accuracy: 1.0000 - val_loss: 18.3634 - val_accuracy: 0.3350\n",
            "Epoch 627/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0374e-08 - accuracy: 1.0000 - val_loss: 18.3624 - val_accuracy: 0.3350\n",
            "Epoch 628/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 1.0251e-08 - accuracy: 1.0000 - val_loss: 18.3519 - val_accuracy: 0.3400\n",
            "Epoch 629/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0212e-08 - accuracy: 1.0000 - val_loss: 18.3875 - val_accuracy: 0.3350\n",
            "Epoch 630/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0090e-08 - accuracy: 1.0000 - val_loss: 18.3939 - val_accuracy: 0.3300\n",
            "Epoch 631/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0019e-08 - accuracy: 1.0000 - val_loss: 18.3671 - val_accuracy: 0.3400\n",
            "Epoch 632/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0106e-08 - accuracy: 1.0000 - val_loss: 18.3967 - val_accuracy: 0.3300\n",
            "Epoch 633/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0177e-08 - accuracy: 1.0000 - val_loss: 18.4087 - val_accuracy: 0.3350\n",
            "Epoch 634/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.9616e-09 - accuracy: 1.0000 - val_loss: 18.4224 - val_accuracy: 0.3350\n",
            "Epoch 635/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 9.9119e-09 - accuracy: 1.0000 - val_loss: 18.4346 - val_accuracy: 0.3350\n",
            "Epoch 636/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 1.0016e-08 - accuracy: 1.0000 - val_loss: 18.4127 - val_accuracy: 0.3400\n",
            "Epoch 637/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.7949e-09 - accuracy: 1.0000 - val_loss: 18.4053 - val_accuracy: 0.3350\n",
            "Epoch 638/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.8394e-09 - accuracy: 1.0000 - val_loss: 18.4264 - val_accuracy: 0.3300\n",
            "Epoch 639/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.5911e-09 - accuracy: 1.0000 - val_loss: 18.3978 - val_accuracy: 0.3450\n",
            "Epoch 640/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 9.9864e-09 - accuracy: 1.0000 - val_loss: 18.4227 - val_accuracy: 0.3350\n",
            "Epoch 641/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.7514e-09 - accuracy: 1.0000 - val_loss: 18.4360 - val_accuracy: 0.3300\n",
            "Epoch 642/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.6675e-09 - accuracy: 1.0000 - val_loss: 18.4519 - val_accuracy: 0.3350\n",
            "Epoch 643/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.6164e-09 - accuracy: 1.0000 - val_loss: 18.4349 - val_accuracy: 0.3350\n",
            "Epoch 644/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.5414e-09 - accuracy: 1.0000 - val_loss: 18.4311 - val_accuracy: 0.3350\n",
            "Epoch 645/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.4594e-09 - accuracy: 1.0000 - val_loss: 18.4171 - val_accuracy: 0.3450\n",
            "Epoch 646/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.5065e-09 - accuracy: 1.0000 - val_loss: 18.4412 - val_accuracy: 0.3350\n",
            "Epoch 647/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.5456e-09 - accuracy: 1.0000 - val_loss: 18.4478 - val_accuracy: 0.3350\n",
            "Epoch 648/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.3696e-09 - accuracy: 1.0000 - val_loss: 18.4454 - val_accuracy: 0.3400\n",
            "Epoch 649/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.3808e-09 - accuracy: 1.0000 - val_loss: 18.4438 - val_accuracy: 0.3400\n",
            "Epoch 650/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.4533e-09 - accuracy: 1.0000 - val_loss: 18.4591 - val_accuracy: 0.3400\n",
            "Epoch 651/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.3473e-09 - accuracy: 1.0000 - val_loss: 18.4632 - val_accuracy: 0.3400\n",
            "Epoch 652/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.2259e-09 - accuracy: 1.0000 - val_loss: 18.4416 - val_accuracy: 0.3400\n",
            "Epoch 653/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.2965e-09 - accuracy: 1.0000 - val_loss: 18.4586 - val_accuracy: 0.3400\n",
            "Epoch 654/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.3359e-09 - accuracy: 1.0000 - val_loss: 18.4499 - val_accuracy: 0.3400\n",
            "Epoch 655/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.1379e-09 - accuracy: 1.0000 - val_loss: 18.4567 - val_accuracy: 0.3400\n",
            "Epoch 656/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.1885e-09 - accuracy: 1.0000 - val_loss: 18.4548 - val_accuracy: 0.3400\n",
            "Epoch 657/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.0517e-09 - accuracy: 1.0000 - val_loss: 18.4543 - val_accuracy: 0.3400\n",
            "Epoch 658/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 9.1921e-09 - accuracy: 1.0000 - val_loss: 18.4663 - val_accuracy: 0.3400\n",
            "Epoch 659/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.0553e-09 - accuracy: 1.0000 - val_loss: 18.4752 - val_accuracy: 0.3400\n",
            "Epoch 660/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 9.0325e-09 - accuracy: 1.0000 - val_loss: 18.4758 - val_accuracy: 0.3400\n",
            "Epoch 661/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.0022e-09 - accuracy: 1.0000 - val_loss: 18.4978 - val_accuracy: 0.3400\n",
            "Epoch 662/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.9770e-09 - accuracy: 1.0000 - val_loss: 18.4915 - val_accuracy: 0.3400\n",
            "Epoch 663/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.9137e-09 - accuracy: 1.0000 - val_loss: 18.4884 - val_accuracy: 0.3350\n",
            "Epoch 664/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.8600e-09 - accuracy: 1.0000 - val_loss: 18.5113 - val_accuracy: 0.3400\n",
            "Epoch 665/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.9135e-09 - accuracy: 1.0000 - val_loss: 18.5023 - val_accuracy: 0.3400\n",
            "Epoch 666/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.8059e-09 - accuracy: 1.0000 - val_loss: 18.4955 - val_accuracy: 0.3400\n",
            "Epoch 667/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.7818e-09 - accuracy: 1.0000 - val_loss: 18.5013 - val_accuracy: 0.3400\n",
            "Epoch 668/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.8281e-09 - accuracy: 1.0000 - val_loss: 18.5075 - val_accuracy: 0.3350\n",
            "Epoch 669/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.8202e-09 - accuracy: 1.0000 - val_loss: 18.5277 - val_accuracy: 0.3400\n",
            "Epoch 670/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.6694e-09 - accuracy: 1.0000 - val_loss: 18.5038 - val_accuracy: 0.3400\n",
            "Epoch 671/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.6615e-09 - accuracy: 1.0000 - val_loss: 18.5069 - val_accuracy: 0.3400\n",
            "Epoch 672/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.6768e-09 - accuracy: 1.0000 - val_loss: 18.5273 - val_accuracy: 0.3400\n",
            "Epoch 673/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.5735e-09 - accuracy: 1.0000 - val_loss: 18.5469 - val_accuracy: 0.3400\n",
            "Epoch 674/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.5685e-09 - accuracy: 1.0000 - val_loss: 18.5338 - val_accuracy: 0.3400\n",
            "Epoch 675/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.5391e-09 - accuracy: 1.0000 - val_loss: 18.5245 - val_accuracy: 0.3450\n",
            "Epoch 676/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.5457e-09 - accuracy: 1.0000 - val_loss: 18.5244 - val_accuracy: 0.3450\n",
            "Epoch 677/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.4419e-09 - accuracy: 1.0000 - val_loss: 18.5334 - val_accuracy: 0.3450\n",
            "Epoch 678/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.4255e-09 - accuracy: 1.0000 - val_loss: 18.5273 - val_accuracy: 0.3500\n",
            "Epoch 679/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 8.4414e-09 - accuracy: 1.0000 - val_loss: 18.5440 - val_accuracy: 0.3400\n",
            "Epoch 680/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.3709e-09 - accuracy: 1.0000 - val_loss: 18.5566 - val_accuracy: 0.3400\n",
            "Epoch 681/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.4915e-09 - accuracy: 1.0000 - val_loss: 18.5560 - val_accuracy: 0.3400\n",
            "Epoch 682/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.3488e-09 - accuracy: 1.0000 - val_loss: 18.5379 - val_accuracy: 0.3450\n",
            "Epoch 683/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.3835e-09 - accuracy: 1.0000 - val_loss: 18.5515 - val_accuracy: 0.3400\n",
            "Epoch 684/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.3594e-09 - accuracy: 1.0000 - val_loss: 18.5567 - val_accuracy: 0.3450\n",
            "Epoch 685/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.3164e-09 - accuracy: 1.0000 - val_loss: 18.5654 - val_accuracy: 0.3400\n",
            "Epoch 686/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.2855e-09 - accuracy: 1.0000 - val_loss: 18.5499 - val_accuracy: 0.3450\n",
            "Epoch 687/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.2797e-09 - accuracy: 1.0000 - val_loss: 18.5452 - val_accuracy: 0.3450\n",
            "Epoch 688/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.3139e-09 - accuracy: 1.0000 - val_loss: 18.5599 - val_accuracy: 0.3400\n",
            "Epoch 689/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.1636e-09 - accuracy: 1.0000 - val_loss: 18.5584 - val_accuracy: 0.3450\n",
            "Epoch 690/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.1506e-09 - accuracy: 1.0000 - val_loss: 18.5411 - val_accuracy: 0.3450\n",
            "Epoch 691/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.2301e-09 - accuracy: 1.0000 - val_loss: 18.5819 - val_accuracy: 0.3400\n",
            "Epoch 692/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 8.0823e-09 - accuracy: 1.0000 - val_loss: 18.5739 - val_accuracy: 0.3450\n",
            "Epoch 693/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.0978e-09 - accuracy: 1.0000 - val_loss: 18.5848 - val_accuracy: 0.3400\n",
            "Epoch 694/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.1087e-09 - accuracy: 1.0000 - val_loss: 18.5813 - val_accuracy: 0.3400\n",
            "Epoch 695/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.1014e-09 - accuracy: 1.0000 - val_loss: 18.5862 - val_accuracy: 0.3450\n",
            "Epoch 696/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.9880e-09 - accuracy: 1.0000 - val_loss: 18.6179 - val_accuracy: 0.3400\n",
            "Epoch 697/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 8.0421e-09 - accuracy: 1.0000 - val_loss: 18.6041 - val_accuracy: 0.3400\n",
            "Epoch 698/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.9239e-09 - accuracy: 1.0000 - val_loss: 18.5920 - val_accuracy: 0.3450\n",
            "Epoch 699/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 8.0318e-09 - accuracy: 1.0000 - val_loss: 18.6036 - val_accuracy: 0.3400\n",
            "Epoch 700/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.9703e-09 - accuracy: 1.0000 - val_loss: 18.5956 - val_accuracy: 0.3400\n",
            "Epoch 701/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.8420e-09 - accuracy: 1.0000 - val_loss: 18.5761 - val_accuracy: 0.3450\n",
            "Epoch 702/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.8854e-09 - accuracy: 1.0000 - val_loss: 18.5804 - val_accuracy: 0.3500\n",
            "Epoch 703/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.9303e-09 - accuracy: 1.0000 - val_loss: 18.5993 - val_accuracy: 0.3400\n",
            "Epoch 704/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.8087e-09 - accuracy: 1.0000 - val_loss: 18.6043 - val_accuracy: 0.3450\n",
            "Epoch 705/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.8437e-09 - accuracy: 1.0000 - val_loss: 18.5974 - val_accuracy: 0.3450\n",
            "Epoch 706/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.7901e-09 - accuracy: 1.0000 - val_loss: 18.6066 - val_accuracy: 0.3500\n",
            "Epoch 707/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.7771e-09 - accuracy: 1.0000 - val_loss: 18.5991 - val_accuracy: 0.3450\n",
            "Epoch 708/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.7792e-09 - accuracy: 1.0000 - val_loss: 18.6401 - val_accuracy: 0.3400\n",
            "Epoch 709/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.7780e-09 - accuracy: 1.0000 - val_loss: 18.6143 - val_accuracy: 0.3450\n",
            "Epoch 710/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.7235e-09 - accuracy: 1.0000 - val_loss: 18.6332 - val_accuracy: 0.3400\n",
            "Epoch 711/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.6667e-09 - accuracy: 1.0000 - val_loss: 18.6226 - val_accuracy: 0.3400\n",
            "Epoch 712/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.6553e-09 - accuracy: 1.0000 - val_loss: 18.6120 - val_accuracy: 0.3450\n",
            "Epoch 713/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.8281e-09 - accuracy: 1.0000 - val_loss: 18.6395 - val_accuracy: 0.3400\n",
            "Epoch 714/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.6162e-09 - accuracy: 1.0000 - val_loss: 18.6397 - val_accuracy: 0.3400\n",
            "Epoch 715/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.6296e-09 - accuracy: 1.0000 - val_loss: 18.6245 - val_accuracy: 0.3400\n",
            "Epoch 716/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.6143e-09 - accuracy: 1.0000 - val_loss: 18.6318 - val_accuracy: 0.3400\n",
            "Epoch 717/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.6214e-09 - accuracy: 1.0000 - val_loss: 18.6235 - val_accuracy: 0.3400\n",
            "Epoch 718/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.5633e-09 - accuracy: 1.0000 - val_loss: 18.6282 - val_accuracy: 0.3400\n",
            "Epoch 719/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.6869e-09 - accuracy: 1.0000 - val_loss: 18.6466 - val_accuracy: 0.3400\n",
            "Epoch 720/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.5369e-09 - accuracy: 1.0000 - val_loss: 18.6399 - val_accuracy: 0.3400\n",
            "Epoch 721/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.5300e-09 - accuracy: 1.0000 - val_loss: 18.6537 - val_accuracy: 0.3400\n",
            "Epoch 722/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.5510e-09 - accuracy: 1.0000 - val_loss: 18.6494 - val_accuracy: 0.3400\n",
            "Epoch 723/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.5145e-09 - accuracy: 1.0000 - val_loss: 18.6438 - val_accuracy: 0.3400\n",
            "Epoch 724/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.5423e-09 - accuracy: 1.0000 - val_loss: 18.6495 - val_accuracy: 0.3400\n",
            "Epoch 725/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.3347e-09 - accuracy: 1.0000 - val_loss: 18.6399 - val_accuracy: 0.3400\n",
            "Epoch 726/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.3816e-09 - accuracy: 1.0000 - val_loss: 18.6549 - val_accuracy: 0.3400\n",
            "Epoch 727/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.4437e-09 - accuracy: 1.0000 - val_loss: 18.6579 - val_accuracy: 0.3400\n",
            "Epoch 728/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.3265e-09 - accuracy: 1.0000 - val_loss: 18.6586 - val_accuracy: 0.3400\n",
            "Epoch 729/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.3234e-09 - accuracy: 1.0000 - val_loss: 18.6522 - val_accuracy: 0.3400\n",
            "Epoch 730/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.3517e-09 - accuracy: 1.0000 - val_loss: 18.6419 - val_accuracy: 0.3400\n",
            "Epoch 731/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.3891e-09 - accuracy: 1.0000 - val_loss: 18.6815 - val_accuracy: 0.3400\n",
            "Epoch 732/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.3126e-09 - accuracy: 1.0000 - val_loss: 18.6834 - val_accuracy: 0.3400\n",
            "Epoch 733/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.2270e-09 - accuracy: 1.0000 - val_loss: 18.6589 - val_accuracy: 0.3400\n",
            "Epoch 734/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.2528e-09 - accuracy: 1.0000 - val_loss: 18.6604 - val_accuracy: 0.3400\n",
            "Epoch 735/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.3293e-09 - accuracy: 1.0000 - val_loss: 18.6754 - val_accuracy: 0.3400\n",
            "Epoch 736/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.2885e-09 - accuracy: 1.0000 - val_loss: 18.6881 - val_accuracy: 0.3400\n",
            "Epoch 737/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.2178e-09 - accuracy: 1.0000 - val_loss: 18.6844 - val_accuracy: 0.3400\n",
            "Epoch 738/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.1550e-09 - accuracy: 1.0000 - val_loss: 18.6807 - val_accuracy: 0.3400\n",
            "Epoch 739/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.2974e-09 - accuracy: 1.0000 - val_loss: 18.6793 - val_accuracy: 0.3400\n",
            "Epoch 740/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.2350e-09 - accuracy: 1.0000 - val_loss: 18.6886 - val_accuracy: 0.3400\n",
            "Epoch 741/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.2002e-09 - accuracy: 1.0000 - val_loss: 18.6752 - val_accuracy: 0.3400\n",
            "Epoch 742/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.2248e-09 - accuracy: 1.0000 - val_loss: 18.6803 - val_accuracy: 0.3400\n",
            "Epoch 743/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.1391e-09 - accuracy: 1.0000 - val_loss: 18.7009 - val_accuracy: 0.3400\n",
            "Epoch 744/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 7.1361e-09 - accuracy: 1.0000 - val_loss: 18.6907 - val_accuracy: 0.3400\n",
            "Epoch 745/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.1284e-09 - accuracy: 1.0000 - val_loss: 18.6885 - val_accuracy: 0.3400\n",
            "Epoch 746/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.1683e-09 - accuracy: 1.0000 - val_loss: 18.6780 - val_accuracy: 0.3400\n",
            "Epoch 747/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.0686e-09 - accuracy: 1.0000 - val_loss: 18.6781 - val_accuracy: 0.3400\n",
            "Epoch 748/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.0814e-09 - accuracy: 1.0000 - val_loss: 18.7026 - val_accuracy: 0.3400\n",
            "Epoch 749/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.0746e-09 - accuracy: 1.0000 - val_loss: 18.6919 - val_accuracy: 0.3400\n",
            "Epoch 750/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.0731e-09 - accuracy: 1.0000 - val_loss: 18.7082 - val_accuracy: 0.3400\n",
            "Epoch 751/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.0084e-09 - accuracy: 1.0000 - val_loss: 18.7149 - val_accuracy: 0.3400\n",
            "Epoch 752/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.9321e-09 - accuracy: 1.0000 - val_loss: 18.7052 - val_accuracy: 0.3400\n",
            "Epoch 753/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.0436e-09 - accuracy: 1.0000 - val_loss: 18.7189 - val_accuracy: 0.3400\n",
            "Epoch 754/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.9289e-09 - accuracy: 1.0000 - val_loss: 18.7044 - val_accuracy: 0.3400\n",
            "Epoch 755/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 7.0187e-09 - accuracy: 1.0000 - val_loss: 18.7127 - val_accuracy: 0.3400\n",
            "Epoch 756/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.8705e-09 - accuracy: 1.0000 - val_loss: 18.7082 - val_accuracy: 0.3400\n",
            "Epoch 757/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 7.0630e-09 - accuracy: 1.0000 - val_loss: 18.7127 - val_accuracy: 0.3400\n",
            "Epoch 758/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.8915e-09 - accuracy: 1.0000 - val_loss: 18.7075 - val_accuracy: 0.3400\n",
            "Epoch 759/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.9287e-09 - accuracy: 1.0000 - val_loss: 18.7259 - val_accuracy: 0.3400\n",
            "Epoch 760/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.9408e-09 - accuracy: 1.0000 - val_loss: 18.7233 - val_accuracy: 0.3400\n",
            "Epoch 761/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.8728e-09 - accuracy: 1.0000 - val_loss: 18.7372 - val_accuracy: 0.3400\n",
            "Epoch 762/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.9099e-09 - accuracy: 1.0000 - val_loss: 18.7386 - val_accuracy: 0.3400\n",
            "Epoch 763/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.8608e-09 - accuracy: 1.0000 - val_loss: 18.7336 - val_accuracy: 0.3400\n",
            "Epoch 764/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.8169e-09 - accuracy: 1.0000 - val_loss: 18.7577 - val_accuracy: 0.3400\n",
            "Epoch 765/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.8422e-09 - accuracy: 1.0000 - val_loss: 18.7418 - val_accuracy: 0.3400\n",
            "Epoch 766/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.8498e-09 - accuracy: 1.0000 - val_loss: 18.7323 - val_accuracy: 0.3400\n",
            "Epoch 767/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.8830e-09 - accuracy: 1.0000 - val_loss: 18.7361 - val_accuracy: 0.3400\n",
            "Epoch 768/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.8347e-09 - accuracy: 1.0000 - val_loss: 18.7426 - val_accuracy: 0.3400\n",
            "Epoch 769/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.7922e-09 - accuracy: 1.0000 - val_loss: 18.7428 - val_accuracy: 0.3400\n",
            "Epoch 770/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 6.7745e-09 - accuracy: 1.0000 - val_loss: 18.7634 - val_accuracy: 0.3400\n",
            "Epoch 771/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.7742e-09 - accuracy: 1.0000 - val_loss: 18.7378 - val_accuracy: 0.3400\n",
            "Epoch 772/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.7303e-09 - accuracy: 1.0000 - val_loss: 18.7358 - val_accuracy: 0.3400\n",
            "Epoch 773/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.7617e-09 - accuracy: 1.0000 - val_loss: 18.7463 - val_accuracy: 0.3400\n",
            "Epoch 774/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.7607e-09 - accuracy: 1.0000 - val_loss: 18.7480 - val_accuracy: 0.3400\n",
            "Epoch 775/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.7688e-09 - accuracy: 1.0000 - val_loss: 18.7471 - val_accuracy: 0.3400\n",
            "Epoch 776/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.7111e-09 - accuracy: 1.0000 - val_loss: 18.7456 - val_accuracy: 0.3400\n",
            "Epoch 777/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.6906e-09 - accuracy: 1.0000 - val_loss: 18.7681 - val_accuracy: 0.3400\n",
            "Epoch 778/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.7104e-09 - accuracy: 1.0000 - val_loss: 18.7519 - val_accuracy: 0.3400\n",
            "Epoch 779/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.6700e-09 - accuracy: 1.0000 - val_loss: 18.7559 - val_accuracy: 0.3400\n",
            "Epoch 780/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.7193e-09 - accuracy: 1.0000 - val_loss: 18.7711 - val_accuracy: 0.3400\n",
            "Epoch 781/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.6553e-09 - accuracy: 1.0000 - val_loss: 18.7562 - val_accuracy: 0.3400\n",
            "Epoch 782/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.6961e-09 - accuracy: 1.0000 - val_loss: 18.7752 - val_accuracy: 0.3400\n",
            "Epoch 783/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.6466e-09 - accuracy: 1.0000 - val_loss: 18.7652 - val_accuracy: 0.3400\n",
            "Epoch 784/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.7112e-09 - accuracy: 1.0000 - val_loss: 18.7698 - val_accuracy: 0.3400\n",
            "Epoch 785/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.6616e-09 - accuracy: 1.0000 - val_loss: 18.7542 - val_accuracy: 0.3400\n",
            "Epoch 786/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.6069e-09 - accuracy: 1.0000 - val_loss: 18.7836 - val_accuracy: 0.3400\n",
            "Epoch 787/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.5441e-09 - accuracy: 1.0000 - val_loss: 18.7919 - val_accuracy: 0.3400\n",
            "Epoch 788/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.5657e-09 - accuracy: 1.0000 - val_loss: 18.7761 - val_accuracy: 0.3400\n",
            "Epoch 789/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.5772e-09 - accuracy: 1.0000 - val_loss: 18.7837 - val_accuracy: 0.3400\n",
            "Epoch 790/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.5500e-09 - accuracy: 1.0000 - val_loss: 18.7932 - val_accuracy: 0.3400\n",
            "Epoch 791/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.5479e-09 - accuracy: 1.0000 - val_loss: 18.8016 - val_accuracy: 0.3400\n",
            "Epoch 792/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.4859e-09 - accuracy: 1.0000 - val_loss: 18.7900 - val_accuracy: 0.3400\n",
            "Epoch 793/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.5676e-09 - accuracy: 1.0000 - val_loss: 18.8100 - val_accuracy: 0.3400\n",
            "Epoch 794/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.4850e-09 - accuracy: 1.0000 - val_loss: 18.7771 - val_accuracy: 0.3400\n",
            "Epoch 795/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.5247e-09 - accuracy: 1.0000 - val_loss: 18.8213 - val_accuracy: 0.3400\n",
            "Epoch 796/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.4555e-09 - accuracy: 1.0000 - val_loss: 18.8038 - val_accuracy: 0.3400\n",
            "Epoch 797/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.4942e-09 - accuracy: 1.0000 - val_loss: 18.8162 - val_accuracy: 0.3400\n",
            "Epoch 798/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.4351e-09 - accuracy: 1.0000 - val_loss: 18.8068 - val_accuracy: 0.3400\n",
            "Epoch 799/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.4851e-09 - accuracy: 1.0000 - val_loss: 18.8074 - val_accuracy: 0.3400\n",
            "Epoch 800/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 6.4217e-09 - accuracy: 1.0000 - val_loss: 18.8086 - val_accuracy: 0.3400\n",
            "Epoch 801/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.5495e-09 - accuracy: 1.0000 - val_loss: 18.8130 - val_accuracy: 0.3400\n",
            "Epoch 802/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.3373e-09 - accuracy: 1.0000 - val_loss: 18.8005 - val_accuracy: 0.3400\n",
            "Epoch 803/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.2989e-09 - accuracy: 1.0000 - val_loss: 18.7920 - val_accuracy: 0.3400\n",
            "Epoch 804/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.3863e-09 - accuracy: 1.0000 - val_loss: 18.8188 - val_accuracy: 0.3400\n",
            "Epoch 805/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.3594e-09 - accuracy: 1.0000 - val_loss: 18.8052 - val_accuracy: 0.3400\n",
            "Epoch 806/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.4118e-09 - accuracy: 1.0000 - val_loss: 18.8124 - val_accuracy: 0.3400\n",
            "Epoch 807/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 6.3831e-09 - accuracy: 1.0000 - val_loss: 18.8140 - val_accuracy: 0.3400\n",
            "Epoch 808/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.3842e-09 - accuracy: 1.0000 - val_loss: 18.8094 - val_accuracy: 0.3400\n",
            "Epoch 809/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 6.3245e-09 - accuracy: 1.0000 - val_loss: 18.8371 - val_accuracy: 0.3400\n",
            "Epoch 810/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.3663e-09 - accuracy: 1.0000 - val_loss: 18.8177 - val_accuracy: 0.3400\n",
            "Epoch 811/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.3653e-09 - accuracy: 1.0000 - val_loss: 18.8230 - val_accuracy: 0.3400\n",
            "Epoch 812/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.3259e-09 - accuracy: 1.0000 - val_loss: 18.8249 - val_accuracy: 0.3400\n",
            "Epoch 813/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.3321e-09 - accuracy: 1.0000 - val_loss: 18.8143 - val_accuracy: 0.3400\n",
            "Epoch 814/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.2944e-09 - accuracy: 1.0000 - val_loss: 18.8241 - val_accuracy: 0.3400\n",
            "Epoch 815/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.3439e-09 - accuracy: 1.0000 - val_loss: 18.8210 - val_accuracy: 0.3400\n",
            "Epoch 816/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.3696e-09 - accuracy: 1.0000 - val_loss: 18.8301 - val_accuracy: 0.3400\n",
            "Epoch 817/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.2870e-09 - accuracy: 1.0000 - val_loss: 18.8204 - val_accuracy: 0.3400\n",
            "Epoch 818/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 6.3103e-09 - accuracy: 1.0000 - val_loss: 18.8114 - val_accuracy: 0.3400\n",
            "Epoch 819/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.3313e-09 - accuracy: 1.0000 - val_loss: 18.8310 - val_accuracy: 0.3400\n",
            "Epoch 820/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.3234e-09 - accuracy: 1.0000 - val_loss: 18.8434 - val_accuracy: 0.3400\n",
            "Epoch 821/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.2275e-09 - accuracy: 1.0000 - val_loss: 18.8251 - val_accuracy: 0.3400\n",
            "Epoch 822/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.2902e-09 - accuracy: 1.0000 - val_loss: 18.8419 - val_accuracy: 0.3400\n",
            "Epoch 823/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.2659e-09 - accuracy: 1.0000 - val_loss: 18.8241 - val_accuracy: 0.3400\n",
            "Epoch 824/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.2628e-09 - accuracy: 1.0000 - val_loss: 18.8407 - val_accuracy: 0.3400\n",
            "Epoch 825/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.1683e-09 - accuracy: 1.0000 - val_loss: 18.8549 - val_accuracy: 0.3400\n",
            "Epoch 826/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.1641e-09 - accuracy: 1.0000 - val_loss: 18.8422 - val_accuracy: 0.3400\n",
            "Epoch 827/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.2363e-09 - accuracy: 1.0000 - val_loss: 18.8443 - val_accuracy: 0.3400\n",
            "Epoch 828/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.2321e-09 - accuracy: 1.0000 - val_loss: 18.8399 - val_accuracy: 0.3400\n",
            "Epoch 829/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.2229e-09 - accuracy: 1.0000 - val_loss: 18.8375 - val_accuracy: 0.3400\n",
            "Epoch 830/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.2098e-09 - accuracy: 1.0000 - val_loss: 18.8453 - val_accuracy: 0.3400\n",
            "Epoch 831/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 6.1926e-09 - accuracy: 1.0000 - val_loss: 18.8486 - val_accuracy: 0.3400\n",
            "Epoch 832/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.1673e-09 - accuracy: 1.0000 - val_loss: 18.8441 - val_accuracy: 0.3400\n",
            "Epoch 833/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.1413e-09 - accuracy: 1.0000 - val_loss: 18.8627 - val_accuracy: 0.3400\n",
            "Epoch 834/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.1533e-09 - accuracy: 1.0000 - val_loss: 18.8461 - val_accuracy: 0.3400\n",
            "Epoch 835/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.1682e-09 - accuracy: 1.0000 - val_loss: 18.8427 - val_accuracy: 0.3400\n",
            "Epoch 836/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.1496e-09 - accuracy: 1.0000 - val_loss: 18.8516 - val_accuracy: 0.3400\n",
            "Epoch 837/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0876e-09 - accuracy: 1.0000 - val_loss: 18.8406 - val_accuracy: 0.3400\n",
            "Epoch 838/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.1271e-09 - accuracy: 1.0000 - val_loss: 18.8482 - val_accuracy: 0.3400\n",
            "Epoch 839/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.1145e-09 - accuracy: 1.0000 - val_loss: 18.8547 - val_accuracy: 0.3400\n",
            "Epoch 840/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.0615e-09 - accuracy: 1.0000 - val_loss: 18.8515 - val_accuracy: 0.3400\n",
            "Epoch 841/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.1133e-09 - accuracy: 1.0000 - val_loss: 18.8769 - val_accuracy: 0.3400\n",
            "Epoch 842/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0569e-09 - accuracy: 1.0000 - val_loss: 18.8715 - val_accuracy: 0.3400\n",
            "Epoch 843/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0714e-09 - accuracy: 1.0000 - val_loss: 18.8620 - val_accuracy: 0.3400\n",
            "Epoch 844/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0769e-09 - accuracy: 1.0000 - val_loss: 18.8523 - val_accuracy: 0.3400\n",
            "Epoch 845/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.1563e-09 - accuracy: 1.0000 - val_loss: 18.8574 - val_accuracy: 0.3400\n",
            "Epoch 846/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0694e-09 - accuracy: 1.0000 - val_loss: 18.8579 - val_accuracy: 0.3400\n",
            "Epoch 847/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.1191e-09 - accuracy: 1.0000 - val_loss: 18.8743 - val_accuracy: 0.3400\n",
            "Epoch 848/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.0189e-09 - accuracy: 1.0000 - val_loss: 18.8714 - val_accuracy: 0.3400\n",
            "Epoch 849/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0437e-09 - accuracy: 1.0000 - val_loss: 18.8535 - val_accuracy: 0.3400\n",
            "Epoch 850/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.9885e-09 - accuracy: 1.0000 - val_loss: 18.8703 - val_accuracy: 0.3400\n",
            "Epoch 851/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 6.0352e-09 - accuracy: 1.0000 - val_loss: 18.8575 - val_accuracy: 0.3400\n",
            "Epoch 852/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.0757e-09 - accuracy: 1.0000 - val_loss: 18.8736 - val_accuracy: 0.3400\n",
            "Epoch 853/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0177e-09 - accuracy: 1.0000 - val_loss: 18.8601 - val_accuracy: 0.3400\n",
            "Epoch 854/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0540e-09 - accuracy: 1.0000 - val_loss: 18.8638 - val_accuracy: 0.3400\n",
            "Epoch 855/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0640e-09 - accuracy: 1.0000 - val_loss: 18.8683 - val_accuracy: 0.3400\n",
            "Epoch 856/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0235e-09 - accuracy: 1.0000 - val_loss: 18.8717 - val_accuracy: 0.3400\n",
            "Epoch 857/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0335e-09 - accuracy: 1.0000 - val_loss: 18.8606 - val_accuracy: 0.3400\n",
            "Epoch 858/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.9961e-09 - accuracy: 1.0000 - val_loss: 18.8885 - val_accuracy: 0.3400\n",
            "Epoch 859/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0164e-09 - accuracy: 1.0000 - val_loss: 18.8752 - val_accuracy: 0.3400\n",
            "Epoch 860/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 6.0090e-09 - accuracy: 1.0000 - val_loss: 18.8710 - val_accuracy: 0.3400\n",
            "Epoch 861/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 6.0212e-09 - accuracy: 1.0000 - val_loss: 18.8933 - val_accuracy: 0.3400\n",
            "Epoch 862/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.9154e-09 - accuracy: 1.0000 - val_loss: 18.8735 - val_accuracy: 0.3400\n",
            "Epoch 863/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.9866e-09 - accuracy: 1.0000 - val_loss: 18.8783 - val_accuracy: 0.3400\n",
            "Epoch 864/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.9313e-09 - accuracy: 1.0000 - val_loss: 18.8721 - val_accuracy: 0.3400\n",
            "Epoch 865/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 6.0290e-09 - accuracy: 1.0000 - val_loss: 18.8841 - val_accuracy: 0.3400\n",
            "Epoch 866/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 6.0028e-09 - accuracy: 1.0000 - val_loss: 18.8767 - val_accuracy: 0.3400\n",
            "Epoch 867/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.9588e-09 - accuracy: 1.0000 - val_loss: 18.8877 - val_accuracy: 0.3400\n",
            "Epoch 868/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.9639e-09 - accuracy: 1.0000 - val_loss: 18.8859 - val_accuracy: 0.3400\n",
            "Epoch 869/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.9667e-09 - accuracy: 1.0000 - val_loss: 18.8784 - val_accuracy: 0.3400\n",
            "Epoch 870/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.9721e-09 - accuracy: 1.0000 - val_loss: 18.8954 - val_accuracy: 0.3400\n",
            "Epoch 871/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.8902e-09 - accuracy: 1.0000 - val_loss: 18.8796 - val_accuracy: 0.3400\n",
            "Epoch 872/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.9635e-09 - accuracy: 1.0000 - val_loss: 18.8990 - val_accuracy: 0.3400\n",
            "Epoch 873/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.8743e-09 - accuracy: 1.0000 - val_loss: 18.9130 - val_accuracy: 0.3400\n",
            "Epoch 874/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.8198e-09 - accuracy: 1.0000 - val_loss: 18.9048 - val_accuracy: 0.3400\n",
            "Epoch 875/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.9407e-09 - accuracy: 1.0000 - val_loss: 18.8996 - val_accuracy: 0.3400\n",
            "Epoch 876/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.9145e-09 - accuracy: 1.0000 - val_loss: 18.9069 - val_accuracy: 0.3400\n",
            "Epoch 877/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.8555e-09 - accuracy: 1.0000 - val_loss: 18.9025 - val_accuracy: 0.3400\n",
            "Epoch 878/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.9315e-09 - accuracy: 1.0000 - val_loss: 18.9045 - val_accuracy: 0.3400\n",
            "Epoch 879/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.9073e-09 - accuracy: 1.0000 - val_loss: 18.9058 - val_accuracy: 0.3400\n",
            "Epoch 880/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.8308e-09 - accuracy: 1.0000 - val_loss: 18.8976 - val_accuracy: 0.3400\n",
            "Epoch 881/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.9023e-09 - accuracy: 1.0000 - val_loss: 18.8973 - val_accuracy: 0.3400\n",
            "Epoch 882/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.9264e-09 - accuracy: 1.0000 - val_loss: 18.8935 - val_accuracy: 0.3400\n",
            "Epoch 883/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.9205e-09 - accuracy: 1.0000 - val_loss: 18.8999 - val_accuracy: 0.3400\n",
            "Epoch 884/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.9151e-09 - accuracy: 1.0000 - val_loss: 18.9041 - val_accuracy: 0.3400\n",
            "Epoch 885/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.8506e-09 - accuracy: 1.0000 - val_loss: 18.9052 - val_accuracy: 0.3400\n",
            "Epoch 886/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.9004e-09 - accuracy: 1.0000 - val_loss: 18.9227 - val_accuracy: 0.3400\n",
            "Epoch 887/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6122e-09 - accuracy: 1.0000 - val_loss: 18.9238 - val_accuracy: 0.3400\n",
            "Epoch 888/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.7231e-09 - accuracy: 1.0000 - val_loss: 18.9141 - val_accuracy: 0.3400\n",
            "Epoch 889/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.8488e-09 - accuracy: 1.0000 - val_loss: 18.9220 - val_accuracy: 0.3400\n",
            "Epoch 890/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.7566e-09 - accuracy: 1.0000 - val_loss: 18.9258 - val_accuracy: 0.3400\n",
            "Epoch 891/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.8506e-09 - accuracy: 1.0000 - val_loss: 18.9148 - val_accuracy: 0.3400\n",
            "Epoch 892/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.8389e-09 - accuracy: 1.0000 - val_loss: 18.9113 - val_accuracy: 0.3400\n",
            "Epoch 893/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.8590e-09 - accuracy: 1.0000 - val_loss: 18.9180 - val_accuracy: 0.3400\n",
            "Epoch 894/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.8104e-09 - accuracy: 1.0000 - val_loss: 18.9185 - val_accuracy: 0.3400\n",
            "Epoch 895/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 5.8518e-09 - accuracy: 1.0000 - val_loss: 18.9344 - val_accuracy: 0.3400\n",
            "Epoch 896/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6860e-09 - accuracy: 1.0000 - val_loss: 18.9255 - val_accuracy: 0.3400\n",
            "Epoch 897/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.7770e-09 - accuracy: 1.0000 - val_loss: 18.9119 - val_accuracy: 0.3400\n",
            "Epoch 898/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.7773e-09 - accuracy: 1.0000 - val_loss: 18.9244 - val_accuracy: 0.3400\n",
            "Epoch 899/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.8016e-09 - accuracy: 1.0000 - val_loss: 18.9344 - val_accuracy: 0.3400\n",
            "Epoch 900/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.7296e-09 - accuracy: 1.0000 - val_loss: 18.9242 - val_accuracy: 0.3400\n",
            "Epoch 901/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.7549e-09 - accuracy: 1.0000 - val_loss: 18.9192 - val_accuracy: 0.3400\n",
            "Epoch 902/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.7547e-09 - accuracy: 1.0000 - val_loss: 18.9171 - val_accuracy: 0.3400\n",
            "Epoch 903/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.7922e-09 - accuracy: 1.0000 - val_loss: 18.9222 - val_accuracy: 0.3400\n",
            "Epoch 904/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.7796e-09 - accuracy: 1.0000 - val_loss: 18.9408 - val_accuracy: 0.3400\n",
            "Epoch 905/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6911e-09 - accuracy: 1.0000 - val_loss: 18.9535 - val_accuracy: 0.3400\n",
            "Epoch 906/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.7767e-09 - accuracy: 1.0000 - val_loss: 18.9410 - val_accuracy: 0.3400\n",
            "Epoch 907/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.7718e-09 - accuracy: 1.0000 - val_loss: 18.9379 - val_accuracy: 0.3400\n",
            "Epoch 908/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.7882e-09 - accuracy: 1.0000 - val_loss: 18.9511 - val_accuracy: 0.3400\n",
            "Epoch 909/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.7391e-09 - accuracy: 1.0000 - val_loss: 18.9377 - val_accuracy: 0.3400\n",
            "Epoch 910/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.7277e-09 - accuracy: 1.0000 - val_loss: 18.9310 - val_accuracy: 0.3400\n",
            "Epoch 911/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.8081e-09 - accuracy: 1.0000 - val_loss: 18.9476 - val_accuracy: 0.3400\n",
            "Epoch 912/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.7582e-09 - accuracy: 1.0000 - val_loss: 18.9358 - val_accuracy: 0.3400\n",
            "Epoch 913/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.7742e-09 - accuracy: 1.0000 - val_loss: 18.9420 - val_accuracy: 0.3400\n",
            "Epoch 914/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.7708e-09 - accuracy: 1.0000 - val_loss: 18.9420 - val_accuracy: 0.3400\n",
            "Epoch 915/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.7021e-09 - accuracy: 1.0000 - val_loss: 18.9434 - val_accuracy: 0.3400\n",
            "Epoch 916/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.7651e-09 - accuracy: 1.0000 - val_loss: 18.9433 - val_accuracy: 0.3400\n",
            "Epoch 917/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6199e-09 - accuracy: 1.0000 - val_loss: 18.9695 - val_accuracy: 0.3400\n",
            "Epoch 918/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6013e-09 - accuracy: 1.0000 - val_loss: 18.9495 - val_accuracy: 0.3400\n",
            "Epoch 919/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6598e-09 - accuracy: 1.0000 - val_loss: 18.9599 - val_accuracy: 0.3400\n",
            "Epoch 920/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6681e-09 - accuracy: 1.0000 - val_loss: 18.9507 - val_accuracy: 0.3400\n",
            "Epoch 921/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.7329e-09 - accuracy: 1.0000 - val_loss: 18.9417 - val_accuracy: 0.3400\n",
            "Epoch 922/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.6124e-09 - accuracy: 1.0000 - val_loss: 18.9551 - val_accuracy: 0.3400\n",
            "Epoch 923/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5753e-09 - accuracy: 1.0000 - val_loss: 18.9505 - val_accuracy: 0.3400\n",
            "Epoch 924/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.6968e-09 - accuracy: 1.0000 - val_loss: 18.9489 - val_accuracy: 0.3400\n",
            "Epoch 925/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6778e-09 - accuracy: 1.0000 - val_loss: 18.9467 - val_accuracy: 0.3400\n",
            "Epoch 926/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.6836e-09 - accuracy: 1.0000 - val_loss: 18.9479 - val_accuracy: 0.3400\n",
            "Epoch 927/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6547e-09 - accuracy: 1.0000 - val_loss: 18.9687 - val_accuracy: 0.3400\n",
            "Epoch 928/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.6217e-09 - accuracy: 1.0000 - val_loss: 18.9682 - val_accuracy: 0.3400\n",
            "Epoch 929/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6592e-09 - accuracy: 1.0000 - val_loss: 18.9604 - val_accuracy: 0.3400\n",
            "Epoch 930/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.5801e-09 - accuracy: 1.0000 - val_loss: 18.9685 - val_accuracy: 0.3400\n",
            "Epoch 931/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6692e-09 - accuracy: 1.0000 - val_loss: 18.9694 - val_accuracy: 0.3400\n",
            "Epoch 932/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.5795e-09 - accuracy: 1.0000 - val_loss: 18.9762 - val_accuracy: 0.3400\n",
            "Epoch 933/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.6106e-09 - accuracy: 1.0000 - val_loss: 18.9688 - val_accuracy: 0.3400\n",
            "Epoch 934/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.5129e-09 - accuracy: 1.0000 - val_loss: 18.9648 - val_accuracy: 0.3400\n",
            "Epoch 935/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5584e-09 - accuracy: 1.0000 - val_loss: 18.9620 - val_accuracy: 0.3400\n",
            "Epoch 936/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.6634e-09 - accuracy: 1.0000 - val_loss: 18.9670 - val_accuracy: 0.3400\n",
            "Epoch 937/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6375e-09 - accuracy: 1.0000 - val_loss: 18.9677 - val_accuracy: 0.3400\n",
            "Epoch 938/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6032e-09 - accuracy: 1.0000 - val_loss: 18.9547 - val_accuracy: 0.3400\n",
            "Epoch 939/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6382e-09 - accuracy: 1.0000 - val_loss: 18.9651 - val_accuracy: 0.3400\n",
            "Epoch 940/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6213e-09 - accuracy: 1.0000 - val_loss: 18.9607 - val_accuracy: 0.3400\n",
            "Epoch 941/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.6420e-09 - accuracy: 1.0000 - val_loss: 18.9517 - val_accuracy: 0.3400\n",
            "Epoch 942/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.4781e-09 - accuracy: 1.0000 - val_loss: 18.9602 - val_accuracy: 0.3400\n",
            "Epoch 943/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6216e-09 - accuracy: 1.0000 - val_loss: 18.9702 - val_accuracy: 0.3400\n",
            "Epoch 944/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.6447e-09 - accuracy: 1.0000 - val_loss: 18.9792 - val_accuracy: 0.3400\n",
            "Epoch 945/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6020e-09 - accuracy: 1.0000 - val_loss: 18.9627 - val_accuracy: 0.3400\n",
            "Epoch 946/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5694e-09 - accuracy: 1.0000 - val_loss: 18.9883 - val_accuracy: 0.3400\n",
            "Epoch 947/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5006e-09 - accuracy: 1.0000 - val_loss: 18.9825 - val_accuracy: 0.3400\n",
            "Epoch 948/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6058e-09 - accuracy: 1.0000 - val_loss: 18.9708 - val_accuracy: 0.3400\n",
            "Epoch 949/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 5.5922e-09 - accuracy: 1.0000 - val_loss: 18.9707 - val_accuracy: 0.3400\n",
            "Epoch 950/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.5584e-09 - accuracy: 1.0000 - val_loss: 18.9779 - val_accuracy: 0.3400\n",
            "Epoch 951/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.4622e-09 - accuracy: 1.0000 - val_loss: 18.9818 - val_accuracy: 0.3400\n",
            "Epoch 952/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.4451e-09 - accuracy: 1.0000 - val_loss: 18.9854 - val_accuracy: 0.3400\n",
            "Epoch 953/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5689e-09 - accuracy: 1.0000 - val_loss: 18.9761 - val_accuracy: 0.3400\n",
            "Epoch 954/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.5620e-09 - accuracy: 1.0000 - val_loss: 18.9833 - val_accuracy: 0.3400\n",
            "Epoch 955/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5802e-09 - accuracy: 1.0000 - val_loss: 18.9858 - val_accuracy: 0.3400\n",
            "Epoch 956/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5924e-09 - accuracy: 1.0000 - val_loss: 18.9769 - val_accuracy: 0.3400\n",
            "Epoch 957/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6344e-09 - accuracy: 1.0000 - val_loss: 18.9888 - val_accuracy: 0.3400\n",
            "Epoch 958/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5896e-09 - accuracy: 1.0000 - val_loss: 18.9844 - val_accuracy: 0.3400\n",
            "Epoch 959/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.5681e-09 - accuracy: 1.0000 - val_loss: 18.9907 - val_accuracy: 0.3400\n",
            "Epoch 960/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.4181e-09 - accuracy: 1.0000 - val_loss: 18.9900 - val_accuracy: 0.3400\n",
            "Epoch 961/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5358e-09 - accuracy: 1.0000 - val_loss: 18.9818 - val_accuracy: 0.3400\n",
            "Epoch 962/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5635e-09 - accuracy: 1.0000 - val_loss: 18.9861 - val_accuracy: 0.3400\n",
            "Epoch 963/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.5184e-09 - accuracy: 1.0000 - val_loss: 18.9964 - val_accuracy: 0.3400\n",
            "Epoch 964/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5568e-09 - accuracy: 1.0000 - val_loss: 18.9898 - val_accuracy: 0.3400\n",
            "Epoch 965/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.6138e-09 - accuracy: 1.0000 - val_loss: 19.0073 - val_accuracy: 0.3400\n",
            "Epoch 966/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.4734e-09 - accuracy: 1.0000 - val_loss: 18.9878 - val_accuracy: 0.3400\n",
            "Epoch 967/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.5414e-09 - accuracy: 1.0000 - val_loss: 18.9929 - val_accuracy: 0.3400\n",
            "Epoch 968/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5791e-09 - accuracy: 1.0000 - val_loss: 18.9957 - val_accuracy: 0.3400\n",
            "Epoch 969/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.4467e-09 - accuracy: 1.0000 - val_loss: 19.0070 - val_accuracy: 0.3400\n",
            "Epoch 970/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.5043e-09 - accuracy: 1.0000 - val_loss: 18.9901 - val_accuracy: 0.3400\n",
            "Epoch 971/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.5295e-09 - accuracy: 1.0000 - val_loss: 19.0086 - val_accuracy: 0.3400\n",
            "Epoch 972/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.4445e-09 - accuracy: 1.0000 - val_loss: 19.0100 - val_accuracy: 0.3400\n",
            "Epoch 973/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5226e-09 - accuracy: 1.0000 - val_loss: 18.9989 - val_accuracy: 0.3400\n",
            "Epoch 974/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.4866e-09 - accuracy: 1.0000 - val_loss: 19.0050 - val_accuracy: 0.3400\n",
            "Epoch 975/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.5704e-09 - accuracy: 1.0000 - val_loss: 19.0037 - val_accuracy: 0.3400\n",
            "Epoch 976/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.5443e-09 - accuracy: 1.0000 - val_loss: 18.9970 - val_accuracy: 0.3400\n",
            "Epoch 977/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.5241e-09 - accuracy: 1.0000 - val_loss: 19.0071 - val_accuracy: 0.3400\n",
            "Epoch 978/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.5431e-09 - accuracy: 1.0000 - val_loss: 19.0100 - val_accuracy: 0.3400\n",
            "Epoch 979/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.4491e-09 - accuracy: 1.0000 - val_loss: 19.0078 - val_accuracy: 0.3400\n",
            "Epoch 980/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.5164e-09 - accuracy: 1.0000 - val_loss: 19.0114 - val_accuracy: 0.3400\n",
            "Epoch 981/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.5377e-09 - accuracy: 1.0000 - val_loss: 19.0062 - val_accuracy: 0.3400\n",
            "Epoch 982/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5221e-09 - accuracy: 1.0000 - val_loss: 19.0143 - val_accuracy: 0.3400\n",
            "Epoch 983/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5528e-09 - accuracy: 1.0000 - val_loss: 19.0148 - val_accuracy: 0.3400\n",
            "Epoch 984/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.4154e-09 - accuracy: 1.0000 - val_loss: 19.0220 - val_accuracy: 0.3400\n",
            "Epoch 985/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5047e-09 - accuracy: 1.0000 - val_loss: 19.0127 - val_accuracy: 0.3400\n",
            "Epoch 986/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 5.4693e-09 - accuracy: 1.0000 - val_loss: 19.0105 - val_accuracy: 0.3400\n",
            "Epoch 987/1000\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 5.5098e-09 - accuracy: 1.0000 - val_loss: 19.0077 - val_accuracy: 0.3400\n",
            "Epoch 988/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.4700e-09 - accuracy: 1.0000 - val_loss: 19.0027 - val_accuracy: 0.3400\n",
            "Epoch 989/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.4620e-09 - accuracy: 1.0000 - val_loss: 19.0080 - val_accuracy: 0.3400\n",
            "Epoch 990/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.4996e-09 - accuracy: 1.0000 - val_loss: 19.0188 - val_accuracy: 0.3400\n",
            "Epoch 991/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.4165e-09 - accuracy: 1.0000 - val_loss: 19.0126 - val_accuracy: 0.3400\n",
            "Epoch 992/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.4529e-09 - accuracy: 1.0000 - val_loss: 19.0113 - val_accuracy: 0.3400\n",
            "Epoch 993/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.4890e-09 - accuracy: 1.0000 - val_loss: 19.0125 - val_accuracy: 0.3400\n",
            "Epoch 994/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.4901e-09 - accuracy: 1.0000 - val_loss: 19.0250 - val_accuracy: 0.3400\n",
            "Epoch 995/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 5.5037e-09 - accuracy: 1.0000 - val_loss: 19.0171 - val_accuracy: 0.3400\n",
            "Epoch 996/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.4217e-09 - accuracy: 1.0000 - val_loss: 19.0155 - val_accuracy: 0.3400\n",
            "Epoch 997/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.5021e-09 - accuracy: 1.0000 - val_loss: 19.0145 - val_accuracy: 0.3400\n",
            "Epoch 998/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 5.5051e-09 - accuracy: 1.0000 - val_loss: 19.0196 - val_accuracy: 0.3400\n",
            "Epoch 999/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 5.4123e-09 - accuracy: 1.0000 - val_loss: 19.0168 - val_accuracy: 0.3400\n",
            "Epoch 1000/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 5.4718e-09 - accuracy: 1.0000 - val_loss: 19.0299 - val_accuracy: 0.3400\n"
          ]
        }
      ],
      "source": [
        "#docs_infra: no_execute\n",
        "pqk_history = pqk_model.fit(tf.reshape(x_train_pqk, [N_TRAIN, -1]),\n",
        "          y_train_new,\n",
        "          batch_size=32,\n",
        "          epochs=1000,\n",
        "          verbose=1,\n",
        "          validation_data=(tf.reshape(x_test_pqk, [N_TEST, -1]), y_test_new))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN4Wqa-iLri9"
      },
      "source": [
        "### 3.2 Create a classical model\n",
        "Similar to the code above you can now also create a classical model that doesn't have access to the PQK features in your stilted dataset. This model can be trained using `x_train` and `y_label_new`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHhUYWVh9kGE",
        "outputId": "86556365-bf69-4e00-ce2b-4f9470237109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 32)                352       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 897\n",
            "Trainable params: 897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#docs_infra: no_execute\n",
        "def create_fair_classical_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(32, activation='sigmoid', input_shape=[DATASET_DIM,]))\n",
        "    model.add(tf.keras.layers.Dense(16, activation='sigmoid'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "model = create_fair_classical_model()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.03),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8N54jMau-1L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873b02de-d1ac-4012-bf89-96b6fec71072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "32/32 [==============================] - 1s 15ms/step - loss: 0.6933 - accuracy: 0.5196 - val_loss: 0.7157 - val_accuracy: 0.7600\n",
            "Epoch 2/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6435 - accuracy: 0.5832 - val_loss: 0.6891 - val_accuracy: 0.8150\n",
            "Epoch 3/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6586 - accuracy: 0.5327 - val_loss: 0.7392 - val_accuracy: 0.7100\n",
            "Epoch 4/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6651 - accuracy: 0.5653 - val_loss: 0.7887 - val_accuracy: 0.6600\n",
            "Epoch 5/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6475 - accuracy: 0.5972 - val_loss: 0.8332 - val_accuracy: 0.6500\n",
            "Epoch 6/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.5642 - val_loss: 0.8064 - val_accuracy: 0.6000\n",
            "Epoch 7/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6558 - accuracy: 0.6043 - val_loss: 0.8563 - val_accuracy: 0.6300\n",
            "Epoch 8/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6280 - val_loss: 0.7192 - val_accuracy: 0.7650\n",
            "Epoch 9/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6438 - accuracy: 0.5456 - val_loss: 0.8429 - val_accuracy: 0.6050\n",
            "Epoch 10/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.6310 - val_loss: 0.7864 - val_accuracy: 0.6900\n",
            "Epoch 11/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6259 - accuracy: 0.6109 - val_loss: 0.7482 - val_accuracy: 0.7450\n",
            "Epoch 12/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.6208 - val_loss: 0.9324 - val_accuracy: 0.5750\n",
            "Epoch 13/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6058 - accuracy: 0.6616 - val_loss: 0.7552 - val_accuracy: 0.7100\n",
            "Epoch 14/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.6231 - val_loss: 0.7679 - val_accuracy: 0.6700\n",
            "Epoch 15/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6127 - accuracy: 0.6211 - val_loss: 0.8326 - val_accuracy: 0.6600\n",
            "Epoch 16/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.6127 - val_loss: 0.9868 - val_accuracy: 0.5100\n",
            "Epoch 17/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5923 - accuracy: 0.6394 - val_loss: 0.7867 - val_accuracy: 0.6650\n",
            "Epoch 18/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.6059 - accuracy: 0.6119 - val_loss: 0.9168 - val_accuracy: 0.6050\n",
            "Epoch 19/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5677 - accuracy: 0.6785 - val_loss: 0.7898 - val_accuracy: 0.6950\n",
            "Epoch 20/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5662 - accuracy: 0.6909 - val_loss: 0.8965 - val_accuracy: 0.6250\n",
            "Epoch 21/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5553 - accuracy: 0.6640 - val_loss: 0.8315 - val_accuracy: 0.6750\n",
            "Epoch 22/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5499 - accuracy: 0.6906 - val_loss: 0.8461 - val_accuracy: 0.6450\n",
            "Epoch 23/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.6762 - val_loss: 0.9454 - val_accuracy: 0.6100\n",
            "Epoch 24/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.6858 - val_loss: 0.9271 - val_accuracy: 0.6100\n",
            "Epoch 25/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5221 - accuracy: 0.7509 - val_loss: 0.7175 - val_accuracy: 0.7000\n",
            "Epoch 26/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7009 - val_loss: 1.0196 - val_accuracy: 0.4900\n",
            "Epoch 27/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7833 - val_loss: 0.8700 - val_accuracy: 0.6050\n",
            "Epoch 28/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.7171 - val_loss: 0.9201 - val_accuracy: 0.6450\n",
            "Epoch 29/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7141 - val_loss: 1.0695 - val_accuracy: 0.5750\n",
            "Epoch 30/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7523 - val_loss: 1.0925 - val_accuracy: 0.5650\n",
            "Epoch 31/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7628 - val_loss: 0.9979 - val_accuracy: 0.6050\n",
            "Epoch 32/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7977 - val_loss: 0.7646 - val_accuracy: 0.6600\n",
            "Epoch 33/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7656 - val_loss: 0.9667 - val_accuracy: 0.5800\n",
            "Epoch 34/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8082 - val_loss: 1.0725 - val_accuracy: 0.5600\n",
            "Epoch 35/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8000 - val_loss: 1.1235 - val_accuracy: 0.5600\n",
            "Epoch 36/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8097 - val_loss: 1.1780 - val_accuracy: 0.5800\n",
            "Epoch 37/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8002 - val_loss: 1.0584 - val_accuracy: 0.5700\n",
            "Epoch 38/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.7921 - val_loss: 1.3240 - val_accuracy: 0.5000\n",
            "Epoch 39/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.3702 - accuracy: 0.8166 - val_loss: 1.1772 - val_accuracy: 0.5900\n",
            "Epoch 40/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8215 - val_loss: 1.1689 - val_accuracy: 0.6200\n",
            "Epoch 41/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8376 - val_loss: 1.2616 - val_accuracy: 0.5600\n",
            "Epoch 42/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8101 - val_loss: 1.3107 - val_accuracy: 0.5250\n",
            "Epoch 43/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8292 - val_loss: 1.2544 - val_accuracy: 0.5750\n",
            "Epoch 44/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8175 - val_loss: 1.5720 - val_accuracy: 0.4750\n",
            "Epoch 45/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8547 - val_loss: 1.1591 - val_accuracy: 0.5600\n",
            "Epoch 46/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8249 - val_loss: 1.4276 - val_accuracy: 0.5100\n",
            "Epoch 47/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3022 - accuracy: 0.8563 - val_loss: 1.6347 - val_accuracy: 0.4850\n",
            "Epoch 48/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.3156 - accuracy: 0.8649 - val_loss: 1.2162 - val_accuracy: 0.5750\n",
            "Epoch 49/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.3210 - accuracy: 0.8651 - val_loss: 1.7636 - val_accuracy: 0.4500\n",
            "Epoch 50/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.3125 - accuracy: 0.8598 - val_loss: 1.4853 - val_accuracy: 0.5200\n",
            "Epoch 51/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2783 - accuracy: 0.8743 - val_loss: 1.2761 - val_accuracy: 0.5700\n",
            "Epoch 52/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2991 - accuracy: 0.8661 - val_loss: 1.6789 - val_accuracy: 0.4750\n",
            "Epoch 53/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.8744 - val_loss: 1.5635 - val_accuracy: 0.5250\n",
            "Epoch 54/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2774 - accuracy: 0.8753 - val_loss: 1.7014 - val_accuracy: 0.4950\n",
            "Epoch 55/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2844 - accuracy: 0.8777 - val_loss: 1.4909 - val_accuracy: 0.5500\n",
            "Epoch 56/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.3135 - accuracy: 0.8704 - val_loss: 1.4802 - val_accuracy: 0.5700\n",
            "Epoch 57/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.8738 - val_loss: 1.7571 - val_accuracy: 0.5150\n",
            "Epoch 58/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2607 - accuracy: 0.8881 - val_loss: 1.6731 - val_accuracy: 0.5350\n",
            "Epoch 59/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2787 - accuracy: 0.8820 - val_loss: 1.5780 - val_accuracy: 0.5550\n",
            "Epoch 60/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2328 - accuracy: 0.8988 - val_loss: 1.9744 - val_accuracy: 0.4700\n",
            "Epoch 61/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2340 - accuracy: 0.9029 - val_loss: 1.7025 - val_accuracy: 0.5400\n",
            "Epoch 62/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2305 - accuracy: 0.8982 - val_loss: 2.2370 - val_accuracy: 0.4150\n",
            "Epoch 63/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2324 - accuracy: 0.9033 - val_loss: 1.8433 - val_accuracy: 0.5300\n",
            "Epoch 64/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2360 - accuracy: 0.8904 - val_loss: 1.8102 - val_accuracy: 0.5150\n",
            "Epoch 65/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2001 - accuracy: 0.9207 - val_loss: 1.8533 - val_accuracy: 0.5200\n",
            "Epoch 66/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1955 - accuracy: 0.9216 - val_loss: 2.1950 - val_accuracy: 0.4650\n",
            "Epoch 67/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2277 - accuracy: 0.9178 - val_loss: 1.9436 - val_accuracy: 0.5350\n",
            "Epoch 68/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2298 - accuracy: 0.9014 - val_loss: 1.9424 - val_accuracy: 0.4950\n",
            "Epoch 69/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2364 - accuracy: 0.8833 - val_loss: 2.1638 - val_accuracy: 0.4700\n",
            "Epoch 70/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2145 - accuracy: 0.9161 - val_loss: 2.0670 - val_accuracy: 0.4800\n",
            "Epoch 71/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1935 - accuracy: 0.9217 - val_loss: 2.0401 - val_accuracy: 0.5000\n",
            "Epoch 72/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1941 - accuracy: 0.9275 - val_loss: 1.9203 - val_accuracy: 0.5100\n",
            "Epoch 73/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1919 - accuracy: 0.9212 - val_loss: 2.0216 - val_accuracy: 0.5050\n",
            "Epoch 74/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1888 - accuracy: 0.9259 - val_loss: 1.9968 - val_accuracy: 0.5150\n",
            "Epoch 75/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1900 - accuracy: 0.9159 - val_loss: 2.1720 - val_accuracy: 0.5000\n",
            "Epoch 76/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9274 - val_loss: 1.9846 - val_accuracy: 0.5200\n",
            "Epoch 77/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1602 - accuracy: 0.9349 - val_loss: 2.1514 - val_accuracy: 0.5050\n",
            "Epoch 78/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1917 - accuracy: 0.9169 - val_loss: 2.4155 - val_accuracy: 0.4400\n",
            "Epoch 79/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1959 - accuracy: 0.9217 - val_loss: 2.1312 - val_accuracy: 0.5250\n",
            "Epoch 80/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1789 - accuracy: 0.9228 - val_loss: 2.1396 - val_accuracy: 0.5050\n",
            "Epoch 81/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1786 - accuracy: 0.9227 - val_loss: 2.3582 - val_accuracy: 0.4750\n",
            "Epoch 82/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1834 - accuracy: 0.9230 - val_loss: 2.1856 - val_accuracy: 0.5100\n",
            "Epoch 83/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1663 - accuracy: 0.9393 - val_loss: 2.5828 - val_accuracy: 0.4500\n",
            "Epoch 84/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.9404 - val_loss: 2.4196 - val_accuracy: 0.4600\n",
            "Epoch 85/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1497 - accuracy: 0.9422 - val_loss: 2.3686 - val_accuracy: 0.4600\n",
            "Epoch 86/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1449 - accuracy: 0.9494 - val_loss: 2.3346 - val_accuracy: 0.4650\n",
            "Epoch 87/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 0.9627 - val_loss: 2.3556 - val_accuracy: 0.4900\n",
            "Epoch 88/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1777 - accuracy: 0.9118 - val_loss: 2.3936 - val_accuracy: 0.5100\n",
            "Epoch 89/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1694 - accuracy: 0.9253 - val_loss: 2.3552 - val_accuracy: 0.4750\n",
            "Epoch 90/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1668 - accuracy: 0.9373 - val_loss: 2.8228 - val_accuracy: 0.4250\n",
            "Epoch 91/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1810 - accuracy: 0.9233 - val_loss: 2.1269 - val_accuracy: 0.5500\n",
            "Epoch 92/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1971 - accuracy: 0.9092 - val_loss: 2.2915 - val_accuracy: 0.4950\n",
            "Epoch 93/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1592 - accuracy: 0.9262 - val_loss: 2.2821 - val_accuracy: 0.5100\n",
            "Epoch 94/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1453 - accuracy: 0.9346 - val_loss: 2.5660 - val_accuracy: 0.4600\n",
            "Epoch 95/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1302 - accuracy: 0.9557 - val_loss: 2.5558 - val_accuracy: 0.4850\n",
            "Epoch 96/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1214 - accuracy: 0.9661 - val_loss: 2.6957 - val_accuracy: 0.4600\n",
            "Epoch 97/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1500 - accuracy: 0.9360 - val_loss: 2.2846 - val_accuracy: 0.5250\n",
            "Epoch 98/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1495 - accuracy: 0.9197 - val_loss: 2.7683 - val_accuracy: 0.4700\n",
            "Epoch 99/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1607 - accuracy: 0.9310 - val_loss: 2.6330 - val_accuracy: 0.5000\n",
            "Epoch 100/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1109 - accuracy: 0.9614 - val_loss: 2.5406 - val_accuracy: 0.5200\n",
            "Epoch 101/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1359 - accuracy: 0.9405 - val_loss: 2.8478 - val_accuracy: 0.4700\n",
            "Epoch 102/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1321 - accuracy: 0.9546 - val_loss: 2.7259 - val_accuracy: 0.4650\n",
            "Epoch 103/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.9616 - val_loss: 2.5189 - val_accuracy: 0.5150\n",
            "Epoch 104/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9683 - val_loss: 3.0390 - val_accuracy: 0.4400\n",
            "Epoch 105/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9568 - val_loss: 2.8015 - val_accuracy: 0.4800\n",
            "Epoch 106/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.9667 - val_loss: 3.0095 - val_accuracy: 0.4850\n",
            "Epoch 107/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.9639 - val_loss: 3.1027 - val_accuracy: 0.4700\n",
            "Epoch 108/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1240 - accuracy: 0.9530 - val_loss: 2.8328 - val_accuracy: 0.5200\n",
            "Epoch 109/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1442 - accuracy: 0.9363 - val_loss: 2.9536 - val_accuracy: 0.4600\n",
            "Epoch 110/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1238 - accuracy: 0.9598 - val_loss: 3.0166 - val_accuracy: 0.4650\n",
            "Epoch 111/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.9667 - val_loss: 2.7787 - val_accuracy: 0.4950\n",
            "Epoch 112/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9450 - val_loss: 2.8867 - val_accuracy: 0.5150\n",
            "Epoch 113/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1247 - accuracy: 0.9529 - val_loss: 2.7686 - val_accuracy: 0.4850\n",
            "Epoch 114/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9421 - val_loss: 2.8577 - val_accuracy: 0.4700\n",
            "Epoch 115/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1182 - accuracy: 0.9530 - val_loss: 2.8596 - val_accuracy: 0.4650\n",
            "Epoch 116/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 0.9520 - val_loss: 2.6322 - val_accuracy: 0.5050\n",
            "Epoch 117/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1437 - accuracy: 0.9450 - val_loss: 3.1194 - val_accuracy: 0.4750\n",
            "Epoch 118/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.9425 - val_loss: 2.8248 - val_accuracy: 0.5150\n",
            "Epoch 119/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9620 - val_loss: 2.9953 - val_accuracy: 0.4700\n",
            "Epoch 120/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0802 - accuracy: 0.9789 - val_loss: 2.8680 - val_accuracy: 0.4900\n",
            "Epoch 121/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9588 - val_loss: 3.0440 - val_accuracy: 0.4900\n",
            "Epoch 122/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9745 - val_loss: 3.0528 - val_accuracy: 0.5100\n",
            "Epoch 123/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.9633 - val_loss: 2.7638 - val_accuracy: 0.5150\n",
            "Epoch 124/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0966 - accuracy: 0.9614 - val_loss: 2.8035 - val_accuracy: 0.5150\n",
            "Epoch 125/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9702 - val_loss: 3.2755 - val_accuracy: 0.4700\n",
            "Epoch 126/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9738 - val_loss: 3.0635 - val_accuracy: 0.5100\n",
            "Epoch 127/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9862 - val_loss: 3.0834 - val_accuracy: 0.5100\n",
            "Epoch 128/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9779 - val_loss: 3.1495 - val_accuracy: 0.5100\n",
            "Epoch 129/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9715 - val_loss: 2.9789 - val_accuracy: 0.5200\n",
            "Epoch 130/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0789 - accuracy: 0.9710 - val_loss: 3.2864 - val_accuracy: 0.4750\n",
            "Epoch 131/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9772 - val_loss: 3.2064 - val_accuracy: 0.4900\n",
            "Epoch 132/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9746 - val_loss: 3.4716 - val_accuracy: 0.4850\n",
            "Epoch 133/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0743 - accuracy: 0.9775 - val_loss: 3.3488 - val_accuracy: 0.5050\n",
            "Epoch 134/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.9538 - val_loss: 2.6367 - val_accuracy: 0.5800\n",
            "Epoch 135/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1359 - accuracy: 0.9399 - val_loss: 3.3801 - val_accuracy: 0.4400\n",
            "Epoch 136/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1569 - accuracy: 0.9327 - val_loss: 3.0958 - val_accuracy: 0.4900\n",
            "Epoch 137/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1272 - accuracy: 0.9454 - val_loss: 2.9868 - val_accuracy: 0.4850\n",
            "Epoch 138/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1119 - accuracy: 0.9668 - val_loss: 2.7216 - val_accuracy: 0.5150\n",
            "Epoch 139/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2060 - accuracy: 0.9267 - val_loss: 3.5452 - val_accuracy: 0.4250\n",
            "Epoch 140/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1531 - accuracy: 0.9425 - val_loss: 2.6779 - val_accuracy: 0.5350\n",
            "Epoch 141/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.9614 - val_loss: 3.0152 - val_accuracy: 0.4950\n",
            "Epoch 142/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.9758 - val_loss: 3.0973 - val_accuracy: 0.5050\n",
            "Epoch 143/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0645 - accuracy: 0.9782 - val_loss: 3.1883 - val_accuracy: 0.5100\n",
            "Epoch 144/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0619 - accuracy: 0.9820 - val_loss: 3.1556 - val_accuracy: 0.5200\n",
            "Epoch 145/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0732 - accuracy: 0.9752 - val_loss: 3.2477 - val_accuracy: 0.5100\n",
            "Epoch 146/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0987 - accuracy: 0.9651 - val_loss: 3.4288 - val_accuracy: 0.5150\n",
            "Epoch 147/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0639 - accuracy: 0.9820 - val_loss: 3.2825 - val_accuracy: 0.5250\n",
            "Epoch 148/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 0.9900 - val_loss: 3.3499 - val_accuracy: 0.5150\n",
            "Epoch 149/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0661 - accuracy: 0.9812 - val_loss: 3.3169 - val_accuracy: 0.5150\n",
            "Epoch 150/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9854 - val_loss: 3.5229 - val_accuracy: 0.5100\n",
            "Epoch 151/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.9825 - val_loss: 3.4827 - val_accuracy: 0.5100\n",
            "Epoch 152/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9818 - val_loss: 3.1434 - val_accuracy: 0.5350\n",
            "Epoch 153/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9799 - val_loss: 3.0069 - val_accuracy: 0.5350\n",
            "Epoch 154/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9665 - val_loss: 3.6361 - val_accuracy: 0.4650\n",
            "Epoch 155/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9769 - val_loss: 3.2106 - val_accuracy: 0.5150\n",
            "Epoch 156/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9717 - val_loss: 3.2127 - val_accuracy: 0.5450\n",
            "Epoch 157/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9637 - val_loss: 3.5157 - val_accuracy: 0.4950\n",
            "Epoch 158/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 0.9693 - val_loss: 3.1750 - val_accuracy: 0.5500\n",
            "Epoch 159/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9844 - val_loss: 3.3594 - val_accuracy: 0.5400\n",
            "Epoch 160/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9728 - val_loss: 3.8893 - val_accuracy: 0.4900\n",
            "Epoch 161/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0666 - accuracy: 0.9813 - val_loss: 3.7526 - val_accuracy: 0.4950\n",
            "Epoch 162/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.9833 - val_loss: 3.5514 - val_accuracy: 0.4800\n",
            "Epoch 163/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 3.4585 - val_accuracy: 0.5000\n",
            "Epoch 164/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0472 - accuracy: 0.9876 - val_loss: 3.5093 - val_accuracy: 0.5200\n",
            "Epoch 165/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0549 - accuracy: 0.9803 - val_loss: 3.3322 - val_accuracy: 0.5000\n",
            "Epoch 166/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0692 - accuracy: 0.9754 - val_loss: 3.6989 - val_accuracy: 0.4700\n",
            "Epoch 167/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0922 - accuracy: 0.9708 - val_loss: 3.6773 - val_accuracy: 0.4900\n",
            "Epoch 168/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 0.9776 - val_loss: 3.7922 - val_accuracy: 0.4600\n",
            "Epoch 169/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9854 - val_loss: 3.5609 - val_accuracy: 0.5050\n",
            "Epoch 170/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0459 - accuracy: 0.9883 - val_loss: 3.3943 - val_accuracy: 0.5250\n",
            "Epoch 171/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0519 - accuracy: 0.9864 - val_loss: 3.5577 - val_accuracy: 0.5150\n",
            "Epoch 172/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0415 - accuracy: 0.9900 - val_loss: 3.6629 - val_accuracy: 0.5200\n",
            "Epoch 173/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.9916 - val_loss: 3.8588 - val_accuracy: 0.5050\n",
            "Epoch 174/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0358 - accuracy: 0.9918 - val_loss: 3.6753 - val_accuracy: 0.5150\n",
            "Epoch 175/1000\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 3.6519 - val_accuracy: 0.5300\n",
            "Epoch 176/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0297 - accuracy: 0.9944 - val_loss: 3.6731 - val_accuracy: 0.5250\n",
            "Epoch 177/1000\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 3.5305 - val_accuracy: 0.5250\n",
            "Epoch 178/1000\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0402 - accuracy: 0.9902 - val_loss: 3.7252 - val_accuracy: 0.5050\n",
            "Epoch 179/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0517 - accuracy: 0.9852 - val_loss: 3.7309 - val_accuracy: 0.5000\n",
            "Epoch 180/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0589 - accuracy: 0.9735 - val_loss: 3.3686 - val_accuracy: 0.5350\n",
            "Epoch 181/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9720 - val_loss: 3.7456 - val_accuracy: 0.5100\n",
            "Epoch 182/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.9575 - val_loss: 3.7401 - val_accuracy: 0.5250\n",
            "Epoch 183/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1635 - accuracy: 0.9453 - val_loss: 3.9991 - val_accuracy: 0.4550\n",
            "Epoch 184/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1826 - accuracy: 0.9268 - val_loss: 3.3582 - val_accuracy: 0.5200\n",
            "Epoch 185/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1074 - accuracy: 0.9606 - val_loss: 3.5339 - val_accuracy: 0.4800\n",
            "Epoch 186/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0943 - accuracy: 0.9684 - val_loss: 3.5176 - val_accuracy: 0.5200\n",
            "Epoch 187/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.9603 - val_loss: 3.6458 - val_accuracy: 0.4900\n",
            "Epoch 188/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 3.6279 - val_accuracy: 0.5150\n",
            "Epoch 189/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9818 - val_loss: 3.6656 - val_accuracy: 0.5150\n",
            "Epoch 190/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 3.6515 - val_accuracy: 0.5200\n",
            "Epoch 191/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 3.7885 - val_accuracy: 0.4900\n",
            "Epoch 192/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0348 - accuracy: 0.9902 - val_loss: 3.8120 - val_accuracy: 0.5000\n",
            "Epoch 193/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0374 - accuracy: 0.9871 - val_loss: 3.8526 - val_accuracy: 0.5050\n",
            "Epoch 194/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 0.9941 - val_loss: 3.8373 - val_accuracy: 0.5000\n",
            "Epoch 195/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 3.8563 - val_accuracy: 0.5050\n",
            "Epoch 196/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0250 - accuracy: 0.9877 - val_loss: 3.7861 - val_accuracy: 0.5000\n",
            "Epoch 197/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9907 - val_loss: 3.9008 - val_accuracy: 0.5000\n",
            "Epoch 198/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0296 - accuracy: 0.9879 - val_loss: 3.8891 - val_accuracy: 0.5100\n",
            "Epoch 199/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9940 - val_loss: 3.8414 - val_accuracy: 0.5100\n",
            "Epoch 200/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 3.8930 - val_accuracy: 0.5100\n",
            "Epoch 201/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9950 - val_loss: 3.9343 - val_accuracy: 0.5100\n",
            "Epoch 202/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 3.9894 - val_accuracy: 0.5000\n",
            "Epoch 203/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 4.1072 - val_accuracy: 0.5000\n",
            "Epoch 204/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 4.0414 - val_accuracy: 0.5000\n",
            "Epoch 205/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 4.1173 - val_accuracy: 0.4800\n",
            "Epoch 206/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 0.9916 - val_loss: 3.9877 - val_accuracy: 0.5100\n",
            "Epoch 207/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 0.9972 - val_loss: 4.0049 - val_accuracy: 0.5150\n",
            "Epoch 208/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9985 - val_loss: 4.0669 - val_accuracy: 0.5100\n",
            "Epoch 209/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9951 - val_loss: 4.2146 - val_accuracy: 0.4950\n",
            "Epoch 210/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9972 - val_loss: 4.1876 - val_accuracy: 0.5000\n",
            "Epoch 211/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 4.2036 - val_accuracy: 0.4950\n",
            "Epoch 212/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9961 - val_loss: 4.3110 - val_accuracy: 0.4900\n",
            "Epoch 213/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 4.3165 - val_accuracy: 0.4800\n",
            "Epoch 214/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9987 - val_loss: 4.3966 - val_accuracy: 0.4800\n",
            "Epoch 215/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9980 - val_loss: 4.4192 - val_accuracy: 0.4850\n",
            "Epoch 216/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0170 - accuracy: 0.9966 - val_loss: 4.2930 - val_accuracy: 0.5050\n",
            "Epoch 217/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0161 - accuracy: 0.9968 - val_loss: 4.3532 - val_accuracy: 0.4800\n",
            "Epoch 218/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 4.2501 - val_accuracy: 0.5100\n",
            "Epoch 219/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0530 - accuracy: 0.9839 - val_loss: 4.1451 - val_accuracy: 0.5050\n",
            "Epoch 220/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1576 - accuracy: 0.9523 - val_loss: 3.9159 - val_accuracy: 0.5350\n",
            "Epoch 221/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8743 - val_loss: 3.4623 - val_accuracy: 0.4950\n",
            "Epoch 222/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.8227 - val_loss: 3.4971 - val_accuracy: 0.4550\n",
            "Epoch 223/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3268 - accuracy: 0.8792 - val_loss: 3.1946 - val_accuracy: 0.5600\n",
            "Epoch 224/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2199 - accuracy: 0.9146 - val_loss: 3.1498 - val_accuracy: 0.5250\n",
            "Epoch 225/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.9516 - val_loss: 3.9540 - val_accuracy: 0.4700\n",
            "Epoch 226/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.9561 - val_loss: 3.5146 - val_accuracy: 0.5050\n",
            "Epoch 227/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9827 - val_loss: 3.5210 - val_accuracy: 0.5100\n",
            "Epoch 228/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0562 - accuracy: 0.9832 - val_loss: 3.4163 - val_accuracy: 0.5250\n",
            "Epoch 229/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9872 - val_loss: 3.7668 - val_accuracy: 0.4950\n",
            "Epoch 230/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9869 - val_loss: 3.6484 - val_accuracy: 0.5200\n",
            "Epoch 231/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9925 - val_loss: 3.7193 - val_accuracy: 0.5100\n",
            "Epoch 232/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9959 - val_loss: 3.8134 - val_accuracy: 0.5100\n",
            "Epoch 233/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 3.7907 - val_accuracy: 0.5050\n",
            "Epoch 234/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9968 - val_loss: 3.7500 - val_accuracy: 0.5100\n",
            "Epoch 235/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9970 - val_loss: 3.9200 - val_accuracy: 0.4950\n",
            "Epoch 236/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 0.9940 - val_loss: 4.0616 - val_accuracy: 0.4950\n",
            "Epoch 237/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9968 - val_loss: 3.8374 - val_accuracy: 0.5250\n",
            "Epoch 238/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 3.9726 - val_accuracy: 0.4900\n",
            "Epoch 239/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9968 - val_loss: 4.1368 - val_accuracy: 0.4800\n",
            "Epoch 240/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9993 - val_loss: 4.0739 - val_accuracy: 0.4850\n",
            "Epoch 241/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 0.9995 - val_loss: 4.2075 - val_accuracy: 0.4850\n",
            "Epoch 242/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 0.9989 - val_loss: 4.0287 - val_accuracy: 0.5050\n",
            "Epoch 243/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0162 - accuracy: 0.9981 - val_loss: 4.1151 - val_accuracy: 0.5000\n",
            "Epoch 244/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0120 - accuracy: 0.9996 - val_loss: 4.2393 - val_accuracy: 0.4950\n",
            "Epoch 245/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9997 - val_loss: 4.2461 - val_accuracy: 0.4950\n",
            "Epoch 246/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 0.9987 - val_loss: 4.2229 - val_accuracy: 0.5050\n",
            "Epoch 247/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 4.2642 - val_accuracy: 0.5050\n",
            "Epoch 248/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 4.1911 - val_accuracy: 0.5150\n",
            "Epoch 249/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 4.3645 - val_accuracy: 0.4950\n",
            "Epoch 250/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 4.3300 - val_accuracy: 0.5000\n",
            "Epoch 251/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 4.2945 - val_accuracy: 0.5200\n",
            "Epoch 252/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9996 - val_loss: 4.5009 - val_accuracy: 0.4900\n",
            "Epoch 253/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9997 - val_loss: 4.4267 - val_accuracy: 0.4950\n",
            "Epoch 254/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 4.2919 - val_accuracy: 0.5250\n",
            "Epoch 255/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9995 - val_loss: 4.4047 - val_accuracy: 0.5050\n",
            "Epoch 256/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 4.4835 - val_accuracy: 0.4800\n",
            "Epoch 257/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9918 - val_loss: 4.3945 - val_accuracy: 0.5000\n",
            "Epoch 258/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0336 - accuracy: 0.9906 - val_loss: 4.4050 - val_accuracy: 0.5050\n",
            "Epoch 259/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 4.6451 - val_accuracy: 0.4900\n",
            "Epoch 260/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 4.3076 - val_accuracy: 0.5150\n",
            "Epoch 261/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9926 - val_loss: 4.9549 - val_accuracy: 0.4650\n",
            "Epoch 262/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9854 - val_loss: 4.2642 - val_accuracy: 0.5250\n",
            "Epoch 263/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1440 - accuracy: 0.9564 - val_loss: 4.8437 - val_accuracy: 0.4550\n",
            "Epoch 264/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9316 - val_loss: 5.3307 - val_accuracy: 0.3800\n",
            "Epoch 265/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1848 - accuracy: 0.9434 - val_loss: 3.7784 - val_accuracy: 0.5350\n",
            "Epoch 266/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1671 - accuracy: 0.9251 - val_loss: 4.1368 - val_accuracy: 0.5400\n",
            "Epoch 267/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9670 - val_loss: 3.8986 - val_accuracy: 0.5550\n",
            "Epoch 268/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9720 - val_loss: 4.0419 - val_accuracy: 0.5200\n",
            "Epoch 269/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9746 - val_loss: 4.0692 - val_accuracy: 0.5000\n",
            "Epoch 270/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9798 - val_loss: 4.3653 - val_accuracy: 0.4800\n",
            "Epoch 271/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0483 - accuracy: 0.9842 - val_loss: 4.5132 - val_accuracy: 0.5150\n",
            "Epoch 272/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 4.3699 - val_accuracy: 0.5100\n",
            "Epoch 273/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9957 - val_loss: 4.6409 - val_accuracy: 0.5000\n",
            "Epoch 274/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9939 - val_loss: 4.2647 - val_accuracy: 0.5000\n",
            "Epoch 275/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9878 - val_loss: 4.2539 - val_accuracy: 0.5250\n",
            "Epoch 276/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0294 - accuracy: 0.9955 - val_loss: 4.4530 - val_accuracy: 0.5150\n",
            "Epoch 277/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 4.5415 - val_accuracy: 0.5150\n",
            "Epoch 278/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9859 - val_loss: 4.5731 - val_accuracy: 0.5250\n",
            "Epoch 279/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 0.9965 - val_loss: 4.5564 - val_accuracy: 0.5200\n",
            "Epoch 280/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9997 - val_loss: 4.4371 - val_accuracy: 0.5250\n",
            "Epoch 281/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 0.9995 - val_loss: 4.4790 - val_accuracy: 0.5150\n",
            "Epoch 282/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9991 - val_loss: 4.4133 - val_accuracy: 0.5250\n",
            "Epoch 283/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 4.5634 - val_accuracy: 0.5200\n",
            "Epoch 284/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 4.6050 - val_accuracy: 0.5200\n",
            "Epoch 285/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9997 - val_loss: 4.6464 - val_accuracy: 0.5150\n",
            "Epoch 286/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9997 - val_loss: 4.6402 - val_accuracy: 0.5100\n",
            "Epoch 287/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 0.9996 - val_loss: 4.7232 - val_accuracy: 0.5150\n",
            "Epoch 288/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 4.6740 - val_accuracy: 0.5200\n",
            "Epoch 289/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 4.7245 - val_accuracy: 0.5200\n",
            "Epoch 290/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 4.6252 - val_accuracy: 0.5200\n",
            "Epoch 291/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 4.7277 - val_accuracy: 0.5200\n",
            "Epoch 292/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 4.7412 - val_accuracy: 0.5150\n",
            "Epoch 293/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 4.8638 - val_accuracy: 0.5100\n",
            "Epoch 294/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 4.9841 - val_accuracy: 0.5050\n",
            "Epoch 295/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.9968 - val_loss: 4.8975 - val_accuracy: 0.5050\n",
            "Epoch 296/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.9802 - val_loss: 5.1594 - val_accuracy: 0.4950\n",
            "Epoch 297/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9728 - val_loss: 4.8725 - val_accuracy: 0.4950\n",
            "Epoch 298/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9705 - val_loss: 4.1156 - val_accuracy: 0.5350\n",
            "Epoch 299/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9677 - val_loss: 4.6593 - val_accuracy: 0.4600\n",
            "Epoch 300/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0630 - accuracy: 0.9809 - val_loss: 4.2908 - val_accuracy: 0.5050\n",
            "Epoch 301/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9617 - val_loss: 4.6798 - val_accuracy: 0.4750\n",
            "Epoch 302/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1835 - accuracy: 0.9505 - val_loss: 4.2298 - val_accuracy: 0.5150\n",
            "Epoch 303/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2320 - accuracy: 0.9307 - val_loss: 3.8751 - val_accuracy: 0.5300\n",
            "Epoch 304/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1602 - accuracy: 0.9444 - val_loss: 4.0836 - val_accuracy: 0.4900\n",
            "Epoch 305/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 0.9766 - val_loss: 4.1428 - val_accuracy: 0.5050\n",
            "Epoch 306/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9830 - val_loss: 4.1904 - val_accuracy: 0.5050\n",
            "Epoch 307/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 0.9871 - val_loss: 4.4356 - val_accuracy: 0.4750\n",
            "Epoch 308/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9878 - val_loss: 4.1468 - val_accuracy: 0.5100\n",
            "Epoch 309/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 4.2566 - val_accuracy: 0.5000\n",
            "Epoch 310/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 0.9998 - val_loss: 4.1066 - val_accuracy: 0.5100\n",
            "Epoch 311/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9998 - val_loss: 4.2054 - val_accuracy: 0.5050\n",
            "Epoch 312/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9994 - val_loss: 4.2722 - val_accuracy: 0.5050\n",
            "Epoch 313/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 4.2533 - val_accuracy: 0.5050\n",
            "Epoch 314/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9998 - val_loss: 4.3016 - val_accuracy: 0.5050\n",
            "Epoch 315/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 0.9998 - val_loss: 4.3223 - val_accuracy: 0.5100\n",
            "Epoch 316/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 4.3422 - val_accuracy: 0.5100\n",
            "Epoch 317/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9997 - val_loss: 4.3937 - val_accuracy: 0.5100\n",
            "Epoch 318/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9998 - val_loss: 4.3593 - val_accuracy: 0.5100\n",
            "Epoch 319/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9997 - val_loss: 4.3897 - val_accuracy: 0.5150\n",
            "Epoch 320/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 4.3580 - val_accuracy: 0.5250\n",
            "Epoch 321/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 4.4332 - val_accuracy: 0.5150\n",
            "Epoch 322/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 4.4196 - val_accuracy: 0.5250\n",
            "Epoch 323/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9996 - val_loss: 4.4882 - val_accuracy: 0.5250\n",
            "Epoch 324/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 4.4786 - val_accuracy: 0.5250\n",
            "Epoch 325/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 4.5077 - val_accuracy: 0.5200\n",
            "Epoch 326/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.4944 - val_accuracy: 0.5200\n",
            "Epoch 327/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.5284 - val_accuracy: 0.5250\n",
            "Epoch 328/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 4.5767 - val_accuracy: 0.5250\n",
            "Epoch 329/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 4.5306 - val_accuracy: 0.5200\n",
            "Epoch 330/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 4.6021 - val_accuracy: 0.5200\n",
            "Epoch 331/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.5542 - val_accuracy: 0.5200\n",
            "Epoch 332/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 4.6613 - val_accuracy: 0.5150\n",
            "Epoch 333/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.6087 - val_accuracy: 0.5200\n",
            "Epoch 334/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 4.6568 - val_accuracy: 0.5200\n",
            "Epoch 335/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.6555 - val_accuracy: 0.5150\n",
            "Epoch 336/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.6790 - val_accuracy: 0.5150\n",
            "Epoch 337/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.7119 - val_accuracy: 0.5150\n",
            "Epoch 338/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.6857 - val_accuracy: 0.5100\n",
            "Epoch 339/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.7209 - val_accuracy: 0.5150\n",
            "Epoch 340/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.7363 - val_accuracy: 0.5150\n",
            "Epoch 341/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.7455 - val_accuracy: 0.5150\n",
            "Epoch 342/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.8027 - val_accuracy: 0.5150\n",
            "Epoch 343/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.8172 - val_accuracy: 0.5150\n",
            "Epoch 344/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.8158 - val_accuracy: 0.5100\n",
            "Epoch 345/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.8521 - val_accuracy: 0.5050\n",
            "Epoch 346/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.8625 - val_accuracy: 0.5100\n",
            "Epoch 347/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.8210 - val_accuracy: 0.5150\n",
            "Epoch 348/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.8764 - val_accuracy: 0.5150\n",
            "Epoch 349/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.8949 - val_accuracy: 0.5100\n",
            "Epoch 350/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.9215 - val_accuracy: 0.5100\n",
            "Epoch 351/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.9263 - val_accuracy: 0.5050\n",
            "Epoch 352/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.9520 - val_accuracy: 0.5050\n",
            "Epoch 353/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.9425 - val_accuracy: 0.5100\n",
            "Epoch 354/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.9560 - val_accuracy: 0.5100\n",
            "Epoch 355/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.9766 - val_accuracy: 0.5100\n",
            "Epoch 356/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.0647 - val_accuracy: 0.5050\n",
            "Epoch 357/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.0353 - val_accuracy: 0.5050\n",
            "Epoch 358/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.0237 - val_accuracy: 0.5050\n",
            "Epoch 359/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.0740 - val_accuracy: 0.5050\n",
            "Epoch 360/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.0498 - val_accuracy: 0.5050\n",
            "Epoch 361/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.0915 - val_accuracy: 0.5050\n",
            "Epoch 362/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.0979 - val_accuracy: 0.5050\n",
            "Epoch 363/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.0933 - val_accuracy: 0.5050\n",
            "Epoch 364/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.1302 - val_accuracy: 0.5050\n",
            "Epoch 365/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.1084 - val_accuracy: 0.5100\n",
            "Epoch 366/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.1413 - val_accuracy: 0.5050\n",
            "Epoch 367/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.1589 - val_accuracy: 0.5050\n",
            "Epoch 368/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.2111 - val_accuracy: 0.5050\n",
            "Epoch 369/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.2049 - val_accuracy: 0.5050\n",
            "Epoch 370/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.2204 - val_accuracy: 0.5050\n",
            "Epoch 371/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.2165 - val_accuracy: 0.5100\n",
            "Epoch 372/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.2238 - val_accuracy: 0.5100\n",
            "Epoch 373/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.2864 - val_accuracy: 0.5100\n",
            "Epoch 374/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.2739 - val_accuracy: 0.5100\n",
            "Epoch 375/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.2925 - val_accuracy: 0.5150\n",
            "Epoch 376/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.2908 - val_accuracy: 0.5150\n",
            "Epoch 377/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.3225 - val_accuracy: 0.5100\n",
            "Epoch 378/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.3261 - val_accuracy: 0.5150\n",
            "Epoch 379/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.3832 - val_accuracy: 0.5150\n",
            "Epoch 380/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.3624 - val_accuracy: 0.5150\n",
            "Epoch 381/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.3574 - val_accuracy: 0.5150\n",
            "Epoch 382/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.4363 - val_accuracy: 0.5150\n",
            "Epoch 383/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.4003 - val_accuracy: 0.5150\n",
            "Epoch 384/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.4379 - val_accuracy: 0.5150\n",
            "Epoch 385/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.4361 - val_accuracy: 0.5100\n",
            "Epoch 386/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.4419 - val_accuracy: 0.5100\n",
            "Epoch 387/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 5.7180 - val_accuracy: 0.4800\n",
            "Epoch 388/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1710 - accuracy: 0.9624 - val_loss: 4.1518 - val_accuracy: 0.5000\n",
            "Epoch 389/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.7255 - accuracy: 0.8403 - val_loss: 3.1612 - val_accuracy: 0.4850\n",
            "Epoch 390/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5538 - accuracy: 0.8355 - val_loss: 4.3223 - val_accuracy: 0.3850\n",
            "Epoch 391/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8613 - val_loss: 3.0972 - val_accuracy: 0.5050\n",
            "Epoch 392/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.8849 - val_loss: 3.2308 - val_accuracy: 0.4550\n",
            "Epoch 393/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1945 - accuracy: 0.9285 - val_loss: 3.0790 - val_accuracy: 0.4700\n",
            "Epoch 394/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1396 - accuracy: 0.9308 - val_loss: 2.7748 - val_accuracy: 0.5250\n",
            "Epoch 395/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1370 - accuracy: 0.9353 - val_loss: 2.7945 - val_accuracy: 0.5400\n",
            "Epoch 396/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0927 - accuracy: 0.9613 - val_loss: 2.9689 - val_accuracy: 0.5600\n",
            "Epoch 397/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9721 - val_loss: 3.1205 - val_accuracy: 0.5250\n",
            "Epoch 398/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.9758 - val_loss: 3.1184 - val_accuracy: 0.5200\n",
            "Epoch 399/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0586 - accuracy: 0.9778 - val_loss: 3.5336 - val_accuracy: 0.4600\n",
            "Epoch 400/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0614 - accuracy: 0.9803 - val_loss: 3.3985 - val_accuracy: 0.5050\n",
            "Epoch 401/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0642 - accuracy: 0.9790 - val_loss: 3.3928 - val_accuracy: 0.4900\n",
            "Epoch 402/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9824 - val_loss: 3.1569 - val_accuracy: 0.5200\n",
            "Epoch 403/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9770 - val_loss: 3.4297 - val_accuracy: 0.4900\n",
            "Epoch 404/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9888 - val_loss: 3.4765 - val_accuracy: 0.4900\n",
            "Epoch 405/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9920 - val_loss: 3.6750 - val_accuracy: 0.4550\n",
            "Epoch 406/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9874 - val_loss: 3.6805 - val_accuracy: 0.4950\n",
            "Epoch 407/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0455 - accuracy: 0.9817 - val_loss: 3.5026 - val_accuracy: 0.4800\n",
            "Epoch 408/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0416 - accuracy: 0.9847 - val_loss: 3.6673 - val_accuracy: 0.5050\n",
            "Epoch 409/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 3.7009 - val_accuracy: 0.4900\n",
            "Epoch 410/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9883 - val_loss: 3.9942 - val_accuracy: 0.4800\n",
            "Epoch 411/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 3.7313 - val_accuracy: 0.5000\n",
            "Epoch 412/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 4.2081 - val_accuracy: 0.4500\n",
            "Epoch 413/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9924 - val_loss: 3.9755 - val_accuracy: 0.4650\n",
            "Epoch 414/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9881 - val_loss: 4.1694 - val_accuracy: 0.4650\n",
            "Epoch 415/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9901 - val_loss: 4.2671 - val_accuracy: 0.4500\n",
            "Epoch 416/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 0.9884 - val_loss: 4.3646 - val_accuracy: 0.4550\n",
            "Epoch 417/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 4.2853 - val_accuracy: 0.4550\n",
            "Epoch 418/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0381 - accuracy: 0.9862 - val_loss: 4.2390 - val_accuracy: 0.4550\n",
            "Epoch 419/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9885 - val_loss: 4.2811 - val_accuracy: 0.4650\n",
            "Epoch 420/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0475 - accuracy: 0.9957 - val_loss: 4.3482 - val_accuracy: 0.4400\n",
            "Epoch 421/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9904 - val_loss: 4.2555 - val_accuracy: 0.4600\n",
            "Epoch 422/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.9879 - val_loss: 4.0302 - val_accuracy: 0.4800\n",
            "Epoch 423/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 4.2764 - val_accuracy: 0.4700\n",
            "Epoch 424/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0210 - accuracy: 0.9972 - val_loss: 4.4615 - val_accuracy: 0.4400\n",
            "Epoch 425/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 4.2403 - val_accuracy: 0.4700\n",
            "Epoch 426/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9951 - val_loss: 4.4420 - val_accuracy: 0.4700\n",
            "Epoch 427/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 0.9959 - val_loss: 4.4186 - val_accuracy: 0.4500\n",
            "Epoch 428/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 0.9975 - val_loss: 4.3328 - val_accuracy: 0.4850\n",
            "Epoch 429/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 4.3478 - val_accuracy: 0.4750\n",
            "Epoch 430/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 4.0849 - val_accuracy: 0.5050\n",
            "Epoch 431/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9910 - val_loss: 4.5216 - val_accuracy: 0.4850\n",
            "Epoch 432/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9934 - val_loss: 4.6886 - val_accuracy: 0.4600\n",
            "Epoch 433/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9759 - val_loss: 4.4071 - val_accuracy: 0.4800\n",
            "Epoch 434/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9636 - val_loss: 4.5309 - val_accuracy: 0.5200\n",
            "Epoch 435/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0603 - accuracy: 0.9770 - val_loss: 3.9897 - val_accuracy: 0.5100\n",
            "Epoch 436/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.9751 - val_loss: 4.0786 - val_accuracy: 0.5300\n",
            "Epoch 437/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9792 - val_loss: 4.4222 - val_accuracy: 0.4850\n",
            "Epoch 438/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9847 - val_loss: 4.9541 - val_accuracy: 0.4500\n",
            "Epoch 439/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9873 - val_loss: 4.4012 - val_accuracy: 0.4900\n",
            "Epoch 440/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0621 - accuracy: 0.9812 - val_loss: 4.9255 - val_accuracy: 0.4400\n",
            "Epoch 441/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.9603 - val_loss: 4.5093 - val_accuracy: 0.5100\n",
            "Epoch 442/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9707 - val_loss: 4.1521 - val_accuracy: 0.4850\n",
            "Epoch 443/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1516 - accuracy: 0.9532 - val_loss: 4.0763 - val_accuracy: 0.5400\n",
            "Epoch 444/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1792 - accuracy: 0.9481 - val_loss: 3.8245 - val_accuracy: 0.5300\n",
            "Epoch 445/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0930 - accuracy: 0.9628 - val_loss: 3.6065 - val_accuracy: 0.5300\n",
            "Epoch 446/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.9740 - val_loss: 3.9736 - val_accuracy: 0.5400\n",
            "Epoch 447/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.9818 - val_loss: 4.1267 - val_accuracy: 0.5100\n",
            "Epoch 448/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9953 - val_loss: 4.2220 - val_accuracy: 0.5100\n",
            "Epoch 449/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 0.9995 - val_loss: 4.1839 - val_accuracy: 0.5300\n",
            "Epoch 450/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9869 - val_loss: 4.5321 - val_accuracy: 0.4850\n",
            "Epoch 451/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 4.3311 - val_accuracy: 0.4950\n",
            "Epoch 452/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9894 - val_loss: 4.1267 - val_accuracy: 0.5250\n",
            "Epoch 453/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 4.5034 - val_accuracy: 0.4850\n",
            "Epoch 454/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9970 - val_loss: 4.5091 - val_accuracy: 0.5000\n",
            "Epoch 455/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9954 - val_loss: 4.4489 - val_accuracy: 0.5050\n",
            "Epoch 456/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 0.9993 - val_loss: 4.2656 - val_accuracy: 0.5150\n",
            "Epoch 457/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 4.5905 - val_accuracy: 0.5000\n",
            "Epoch 458/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 4.4912 - val_accuracy: 0.5050\n",
            "Epoch 459/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 0.9986 - val_loss: 4.5010 - val_accuracy: 0.5100\n",
            "Epoch 460/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9999 - val_loss: 4.5815 - val_accuracy: 0.5000\n",
            "Epoch 461/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 4.5316 - val_accuracy: 0.5200\n",
            "Epoch 462/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 4.5591 - val_accuracy: 0.5150\n",
            "Epoch 463/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 4.6187 - val_accuracy: 0.5150\n",
            "Epoch 464/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 4.6380 - val_accuracy: 0.5150\n",
            "Epoch 465/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 4.6941 - val_accuracy: 0.5150\n",
            "Epoch 466/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 4.6193 - val_accuracy: 0.5150\n",
            "Epoch 467/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 4.7386 - val_accuracy: 0.5100\n",
            "Epoch 468/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 4.6761 - val_accuracy: 0.5150\n",
            "Epoch 469/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 4.7240 - val_accuracy: 0.5100\n",
            "Epoch 470/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 4.7614 - val_accuracy: 0.5100\n",
            "Epoch 471/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 4.7523 - val_accuracy: 0.5100\n",
            "Epoch 472/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 4.8205 - val_accuracy: 0.5050\n",
            "Epoch 473/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.7640 - val_accuracy: 0.5100\n",
            "Epoch 474/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 4.8196 - val_accuracy: 0.5050\n",
            "Epoch 475/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 4.8040 - val_accuracy: 0.5050\n",
            "Epoch 476/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 4.8006 - val_accuracy: 0.5050\n",
            "Epoch 477/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 4.9473 - val_accuracy: 0.5050\n",
            "Epoch 478/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 4.8519 - val_accuracy: 0.5050\n",
            "Epoch 479/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 4.9111 - val_accuracy: 0.5050\n",
            "Epoch 480/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 4.8494 - val_accuracy: 0.5050\n",
            "Epoch 481/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.9971 - val_loss: 4.9106 - val_accuracy: 0.5050\n",
            "Epoch 482/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 4.9202 - val_accuracy: 0.5050\n",
            "Epoch 483/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 5.0359 - val_accuracy: 0.5000\n",
            "Epoch 484/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.9235 - val_accuracy: 0.5050\n",
            "Epoch 485/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 5.0698 - val_accuracy: 0.4950\n",
            "Epoch 486/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.9220 - val_accuracy: 0.5100\n",
            "Epoch 487/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 5.0444 - val_accuracy: 0.5000\n",
            "Epoch 488/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 5.0977 - val_accuracy: 0.4950\n",
            "Epoch 489/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.9412 - val_accuracy: 0.5000\n",
            "Epoch 490/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 5.1556 - val_accuracy: 0.4900\n",
            "Epoch 491/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 5.0595 - val_accuracy: 0.4950\n",
            "Epoch 492/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 5.0977 - val_accuracy: 0.4950\n",
            "Epoch 493/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 4.9448 - val_accuracy: 0.5050\n",
            "Epoch 494/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 5.1480 - val_accuracy: 0.5000\n",
            "Epoch 495/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 5.1506 - val_accuracy: 0.4950\n",
            "Epoch 496/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 5.0834 - val_accuracy: 0.4950\n",
            "Epoch 497/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 5.1275 - val_accuracy: 0.4900\n",
            "Epoch 498/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 5.2076 - val_accuracy: 0.4900\n",
            "Epoch 499/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 5.1806 - val_accuracy: 0.4950\n",
            "Epoch 500/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.1749 - val_accuracy: 0.4950\n",
            "Epoch 501/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 5.2287 - val_accuracy: 0.4900\n",
            "Epoch 502/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 5.2195 - val_accuracy: 0.4900\n",
            "Epoch 503/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 5.2619 - val_accuracy: 0.4900\n",
            "Epoch 504/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 5.3511 - val_accuracy: 0.4900\n",
            "Epoch 505/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 5.3105 - val_accuracy: 0.4900\n",
            "Epoch 506/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 5.3249 - val_accuracy: 0.4850\n",
            "Epoch 507/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 5.4501 - val_accuracy: 0.4900\n",
            "Epoch 508/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 5.3163 - val_accuracy: 0.4700\n",
            "Epoch 509/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 0.9938 - val_loss: 5.3469 - val_accuracy: 0.4750\n",
            "Epoch 510/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9678 - val_loss: 6.0158 - val_accuracy: 0.3950\n",
            "Epoch 511/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6488 - accuracy: 0.8585 - val_loss: 4.4255 - val_accuracy: 0.4550\n",
            "Epoch 512/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6197 - accuracy: 0.8308 - val_loss: 3.0310 - val_accuracy: 0.5450\n",
            "Epoch 513/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.8712 - val_loss: 3.1021 - val_accuracy: 0.5650\n",
            "Epoch 514/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.3195 - accuracy: 0.8950 - val_loss: 2.8507 - val_accuracy: 0.5900\n",
            "Epoch 515/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2902 - accuracy: 0.9065 - val_loss: 3.2294 - val_accuracy: 0.5300\n",
            "Epoch 516/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1879 - accuracy: 0.9324 - val_loss: 2.9102 - val_accuracy: 0.5750\n",
            "Epoch 517/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1243 - accuracy: 0.9585 - val_loss: 3.2210 - val_accuracy: 0.5400\n",
            "Epoch 518/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0837 - accuracy: 0.9709 - val_loss: 3.5692 - val_accuracy: 0.5300\n",
            "Epoch 519/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9757 - val_loss: 3.7337 - val_accuracy: 0.4750\n",
            "Epoch 520/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9755 - val_loss: 3.4925 - val_accuracy: 0.5500\n",
            "Epoch 521/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9684 - val_loss: 3.7806 - val_accuracy: 0.4850\n",
            "Epoch 522/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9825 - val_loss: 3.7811 - val_accuracy: 0.5000\n",
            "Epoch 523/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0445 - accuracy: 0.9916 - val_loss: 3.7204 - val_accuracy: 0.5100\n",
            "Epoch 524/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0708 - accuracy: 0.9814 - val_loss: 3.9100 - val_accuracy: 0.5000\n",
            "Epoch 525/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9908 - val_loss: 3.8914 - val_accuracy: 0.5150\n",
            "Epoch 526/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9903 - val_loss: 3.6894 - val_accuracy: 0.5200\n",
            "Epoch 527/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0228 - accuracy: 0.9976 - val_loss: 3.8401 - val_accuracy: 0.5200\n",
            "Epoch 528/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0265 - accuracy: 0.9954 - val_loss: 3.7363 - val_accuracy: 0.5250\n",
            "Epoch 529/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 0.9964 - val_loss: 3.8583 - val_accuracy: 0.5200\n",
            "Epoch 530/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0229 - accuracy: 0.9970 - val_loss: 3.9176 - val_accuracy: 0.5250\n",
            "Epoch 531/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 0.9975 - val_loss: 3.8120 - val_accuracy: 0.5300\n",
            "Epoch 532/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 3.9545 - val_accuracy: 0.5300\n",
            "Epoch 533/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 4.0515 - val_accuracy: 0.5150\n",
            "Epoch 534/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 4.0467 - val_accuracy: 0.5150\n",
            "Epoch 535/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 4.1455 - val_accuracy: 0.5150\n",
            "Epoch 536/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 4.0575 - val_accuracy: 0.5200\n",
            "Epoch 537/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 4.1402 - val_accuracy: 0.5150\n",
            "Epoch 538/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 4.2348 - val_accuracy: 0.5050\n",
            "Epoch 539/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.5100\n",
            "Epoch 540/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 4.2082 - val_accuracy: 0.5150\n",
            "Epoch 541/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 4.2610 - val_accuracy: 0.5050\n",
            "Epoch 542/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.2578 - val_accuracy: 0.5100\n",
            "Epoch 543/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 4.2911 - val_accuracy: 0.5100\n",
            "Epoch 544/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 4.3025 - val_accuracy: 0.5050\n",
            "Epoch 545/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 4.3376 - val_accuracy: 0.5100\n",
            "Epoch 546/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.3776 - val_accuracy: 0.5100\n",
            "Epoch 547/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.3853 - val_accuracy: 0.5050\n",
            "Epoch 548/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.3897 - val_accuracy: 0.5050\n",
            "Epoch 549/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 4.4442 - val_accuracy: 0.5100\n",
            "Epoch 550/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.4523 - val_accuracy: 0.5150\n",
            "Epoch 551/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.4554 - val_accuracy: 0.5150\n",
            "Epoch 552/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.4898 - val_accuracy: 0.5150\n",
            "Epoch 553/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.4969 - val_accuracy: 0.5200\n",
            "Epoch 554/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.4915 - val_accuracy: 0.5200\n",
            "Epoch 555/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.4908 - val_accuracy: 0.5250\n",
            "Epoch 556/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.5871 - val_accuracy: 0.5200\n",
            "Epoch 557/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.5606 - val_accuracy: 0.5200\n",
            "Epoch 558/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.5864 - val_accuracy: 0.5150\n",
            "Epoch 559/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.6053 - val_accuracy: 0.5150\n",
            "Epoch 560/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.5723 - val_accuracy: 0.5150\n",
            "Epoch 561/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.6518 - val_accuracy: 0.5150\n",
            "Epoch 562/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.6549 - val_accuracy: 0.5100\n",
            "Epoch 563/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.6531 - val_accuracy: 0.5100\n",
            "Epoch 564/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.6705 - val_accuracy: 0.5100\n",
            "Epoch 565/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.7143 - val_accuracy: 0.5100\n",
            "Epoch 566/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.6796 - val_accuracy: 0.5100\n",
            "Epoch 567/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.7164 - val_accuracy: 0.5150\n",
            "Epoch 568/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.7406 - val_accuracy: 0.5100\n",
            "Epoch 569/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.7410 - val_accuracy: 0.5150\n",
            "Epoch 570/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.7502 - val_accuracy: 0.5100\n",
            "Epoch 571/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.7834 - val_accuracy: 0.5050\n",
            "Epoch 572/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.7787 - val_accuracy: 0.5100\n",
            "Epoch 573/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.8293 - val_accuracy: 0.5100\n",
            "Epoch 574/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.8118 - val_accuracy: 0.5100\n",
            "Epoch 575/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.7891 - val_accuracy: 0.5100\n",
            "Epoch 576/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.8783 - val_accuracy: 0.5050\n",
            "Epoch 577/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.8236 - val_accuracy: 0.5100\n",
            "Epoch 578/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.8705 - val_accuracy: 0.5100\n",
            "Epoch 579/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.8709 - val_accuracy: 0.5100\n",
            "Epoch 580/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.8971 - val_accuracy: 0.5100\n",
            "Epoch 581/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.9067 - val_accuracy: 0.5150\n",
            "Epoch 582/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.9274 - val_accuracy: 0.5150\n",
            "Epoch 583/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.9186 - val_accuracy: 0.5150\n",
            "Epoch 584/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.9562 - val_accuracy: 0.5150\n",
            "Epoch 585/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.9622 - val_accuracy: 0.5100\n",
            "Epoch 586/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.0183 - val_accuracy: 0.5050\n",
            "Epoch 587/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.9340 - val_accuracy: 0.5100\n",
            "Epoch 588/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.0081 - val_accuracy: 0.5050\n",
            "Epoch 589/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.0222 - val_accuracy: 0.5100\n",
            "Epoch 590/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.0408 - val_accuracy: 0.5000\n",
            "Epoch 591/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.0196 - val_accuracy: 0.5050\n",
            "Epoch 592/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.0417 - val_accuracy: 0.5050\n",
            "Epoch 593/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.0669 - val_accuracy: 0.5000\n",
            "Epoch 594/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.0827 - val_accuracy: 0.5050\n",
            "Epoch 595/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.1133 - val_accuracy: 0.5000\n",
            "Epoch 596/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.0914 - val_accuracy: 0.5050\n",
            "Epoch 597/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.1192 - val_accuracy: 0.5050\n",
            "Epoch 598/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.1228 - val_accuracy: 0.5050\n",
            "Epoch 599/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.1357 - val_accuracy: 0.5050\n",
            "Epoch 600/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.1554 - val_accuracy: 0.5050\n",
            "Epoch 601/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.1393 - val_accuracy: 0.5100\n",
            "Epoch 602/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.1905 - val_accuracy: 0.5050\n",
            "Epoch 603/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.1922 - val_accuracy: 0.5050\n",
            "Epoch 604/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.2272 - val_accuracy: 0.5050\n",
            "Epoch 605/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.2192 - val_accuracy: 0.5050\n",
            "Epoch 606/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.2578 - val_accuracy: 0.5050\n",
            "Epoch 607/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.2692 - val_accuracy: 0.5050\n",
            "Epoch 608/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 5.2722 - val_accuracy: 0.5050\n",
            "Epoch 609/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 5.2974 - val_accuracy: 0.5050\n",
            "Epoch 610/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.2764 - val_accuracy: 0.5150\n",
            "Epoch 611/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.3622 - val_accuracy: 0.5000\n",
            "Epoch 612/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 5.3349 - val_accuracy: 0.5000\n",
            "Epoch 613/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.3897 - val_accuracy: 0.5050\n",
            "Epoch 614/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.3271 - val_accuracy: 0.5100\n",
            "Epoch 615/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.3968 - val_accuracy: 0.5100\n",
            "Epoch 616/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 5.5930 - val_accuracy: 0.5050\n",
            "Epoch 617/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1283 - accuracy: 0.9705 - val_loss: 4.8052 - val_accuracy: 0.4700\n",
            "Epoch 618/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6347 - accuracy: 0.8373 - val_loss: 3.0421 - val_accuracy: 0.5350\n",
            "Epoch 619/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5907 - accuracy: 0.8378 - val_loss: 3.5584 - val_accuracy: 0.4600\n",
            "Epoch 620/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5868 - accuracy: 0.8217 - val_loss: 2.9946 - val_accuracy: 0.5050\n",
            "Epoch 621/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3333 - accuracy: 0.8681 - val_loss: 3.1272 - val_accuracy: 0.4450\n",
            "Epoch 622/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2893 - accuracy: 0.8724 - val_loss: 2.7265 - val_accuracy: 0.5000\n",
            "Epoch 623/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2053 - accuracy: 0.9232 - val_loss: 2.6747 - val_accuracy: 0.5350\n",
            "Epoch 624/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1538 - accuracy: 0.9303 - val_loss: 3.4364 - val_accuracy: 0.4950\n",
            "Epoch 625/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1429 - accuracy: 0.9470 - val_loss: 3.2057 - val_accuracy: 0.5050\n",
            "Epoch 626/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1176 - accuracy: 0.9477 - val_loss: 3.1016 - val_accuracy: 0.5300\n",
            "Epoch 627/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0896 - accuracy: 0.9611 - val_loss: 3.1773 - val_accuracy: 0.5150\n",
            "Epoch 628/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0843 - accuracy: 0.9729 - val_loss: 3.3451 - val_accuracy: 0.5100\n",
            "Epoch 629/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0664 - accuracy: 0.9822 - val_loss: 3.2807 - val_accuracy: 0.5150\n",
            "Epoch 630/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0598 - accuracy: 0.9806 - val_loss: 3.4567 - val_accuracy: 0.4900\n",
            "Epoch 631/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0637 - accuracy: 0.9783 - val_loss: 3.6393 - val_accuracy: 0.4950\n",
            "Epoch 632/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0550 - accuracy: 0.9813 - val_loss: 3.6158 - val_accuracy: 0.4950\n",
            "Epoch 633/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9841 - val_loss: 3.4644 - val_accuracy: 0.5300\n",
            "Epoch 634/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9814 - val_loss: 3.6340 - val_accuracy: 0.5000\n",
            "Epoch 635/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 3.6741 - val_accuracy: 0.5150\n",
            "Epoch 636/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 3.6394 - val_accuracy: 0.5150\n",
            "Epoch 637/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 3.7273 - val_accuracy: 0.5250\n",
            "Epoch 638/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 0.9953 - val_loss: 3.7052 - val_accuracy: 0.5250\n",
            "Epoch 639/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.9967 - val_loss: 3.8482 - val_accuracy: 0.5000\n",
            "Epoch 640/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 3.7429 - val_accuracy: 0.5350\n",
            "Epoch 641/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 3.8405 - val_accuracy: 0.5250\n",
            "Epoch 642/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 3.8533 - val_accuracy: 0.5200\n",
            "Epoch 643/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 0.9974 - val_loss: 3.9245 - val_accuracy: 0.5350\n",
            "Epoch 644/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0191 - accuracy: 0.9924 - val_loss: 3.8888 - val_accuracy: 0.5300\n",
            "Epoch 645/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 3.9466 - val_accuracy: 0.5150\n",
            "Epoch 646/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 3.9346 - val_accuracy: 0.5300\n",
            "Epoch 647/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0241 - accuracy: 0.9889 - val_loss: 3.8297 - val_accuracy: 0.5400\n",
            "Epoch 648/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0172 - accuracy: 0.9965 - val_loss: 4.0199 - val_accuracy: 0.5300\n",
            "Epoch 649/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 3.9690 - val_accuracy: 0.5250\n",
            "Epoch 650/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 3.9443 - val_accuracy: 0.5300\n",
            "Epoch 651/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0204 - accuracy: 0.9980 - val_loss: 4.1315 - val_accuracy: 0.5200\n",
            "Epoch 652/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 4.0125 - val_accuracy: 0.5300\n",
            "Epoch 653/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9953 - val_loss: 4.1865 - val_accuracy: 0.5100\n",
            "Epoch 654/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9985 - val_loss: 4.0406 - val_accuracy: 0.5250\n",
            "Epoch 655/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 0.9990 - val_loss: 4.1485 - val_accuracy: 0.5200\n",
            "Epoch 656/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 4.1248 - val_accuracy: 0.5250\n",
            "Epoch 657/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 4.1364 - val_accuracy: 0.5250\n",
            "Epoch 658/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 4.2556 - val_accuracy: 0.5100\n",
            "Epoch 659/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 0.9948 - val_loss: 4.0918 - val_accuracy: 0.5250\n",
            "Epoch 660/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0242 - accuracy: 0.9946 - val_loss: 4.3585 - val_accuracy: 0.5100\n",
            "Epoch 661/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9976 - val_loss: 4.2460 - val_accuracy: 0.5200\n",
            "Epoch 662/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 4.1081 - val_accuracy: 0.5400\n",
            "Epoch 663/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 0.9942 - val_loss: 3.9575 - val_accuracy: 0.5350\n",
            "Epoch 664/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9753 - val_loss: 3.8386 - val_accuracy: 0.5350\n",
            "Epoch 665/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0934 - accuracy: 0.9595 - val_loss: 4.3294 - val_accuracy: 0.4950\n",
            "Epoch 666/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1202 - accuracy: 0.9553 - val_loss: 4.8894 - val_accuracy: 0.4350\n",
            "Epoch 667/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.3147 - accuracy: 0.9071 - val_loss: 3.4804 - val_accuracy: 0.5400\n",
            "Epoch 668/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.3627 - accuracy: 0.8925 - val_loss: 3.6873 - val_accuracy: 0.5000\n",
            "Epoch 669/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2452 - accuracy: 0.9275 - val_loss: 3.8266 - val_accuracy: 0.4750\n",
            "Epoch 670/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9617 - val_loss: 3.6278 - val_accuracy: 0.4900\n",
            "Epoch 671/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9789 - val_loss: 4.1570 - val_accuracy: 0.4600\n",
            "Epoch 672/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.9927 - val_loss: 4.1866 - val_accuracy: 0.4600\n",
            "Epoch 673/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9928 - val_loss: 4.0034 - val_accuracy: 0.4850\n",
            "Epoch 674/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0589 - accuracy: 0.9869 - val_loss: 4.2670 - val_accuracy: 0.4850\n",
            "Epoch 675/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9927 - val_loss: 4.0118 - val_accuracy: 0.5050\n",
            "Epoch 676/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9863 - val_loss: 3.8320 - val_accuracy: 0.5050\n",
            "Epoch 677/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9925 - val_loss: 4.2587 - val_accuracy: 0.4700\n",
            "Epoch 678/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.9926 - val_loss: 4.1180 - val_accuracy: 0.5100\n",
            "Epoch 679/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9930 - val_loss: 4.3376 - val_accuracy: 0.4800\n",
            "Epoch 680/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 4.2292 - val_accuracy: 0.4900\n",
            "Epoch 681/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0145 - accuracy: 0.9988 - val_loss: 4.2733 - val_accuracy: 0.4850\n",
            "Epoch 682/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9953 - val_loss: 4.2769 - val_accuracy: 0.4900\n",
            "Epoch 683/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 4.3029 - val_accuracy: 0.4900\n",
            "Epoch 684/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.9968 - val_loss: 4.2749 - val_accuracy: 0.4900\n",
            "Epoch 685/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9978 - val_loss: 4.2759 - val_accuracy: 0.4750\n",
            "Epoch 686/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 4.3864 - val_accuracy: 0.4650\n",
            "Epoch 687/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 4.2397 - val_accuracy: 0.4800\n",
            "Epoch 688/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 0.9985 - val_loss: 4.3648 - val_accuracy: 0.4750\n",
            "Epoch 689/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.9979 - val_loss: 4.3936 - val_accuracy: 0.4700\n",
            "Epoch 690/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9975 - val_loss: 4.3638 - val_accuracy: 0.4700\n",
            "Epoch 691/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 0.9988 - val_loss: 4.4011 - val_accuracy: 0.4600\n",
            "Epoch 692/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 0.9981 - val_loss: 4.4098 - val_accuracy: 0.4650\n",
            "Epoch 693/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130 - accuracy: 0.9988 - val_loss: 4.4218 - val_accuracy: 0.4700\n",
            "Epoch 694/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9997 - val_loss: 4.3922 - val_accuracy: 0.4700\n",
            "Epoch 695/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - accuracy: 0.9998 - val_loss: 4.4097 - val_accuracy: 0.4650\n",
            "Epoch 696/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.9998 - val_loss: 4.4339 - val_accuracy: 0.4650\n",
            "Epoch 697/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 0.9998 - val_loss: 4.4395 - val_accuracy: 0.4650\n",
            "Epoch 698/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 0.9983 - val_loss: 4.4815 - val_accuracy: 0.4600\n",
            "Epoch 699/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 0.9999 - val_loss: 4.4901 - val_accuracy: 0.4650\n",
            "Epoch 700/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 4.4737 - val_accuracy: 0.4650\n",
            "Epoch 701/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9997 - val_loss: 4.4510 - val_accuracy: 0.4700\n",
            "Epoch 702/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9998 - val_loss: 4.5196 - val_accuracy: 0.4650\n",
            "Epoch 703/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 4.5147 - val_accuracy: 0.4650\n",
            "Epoch 704/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 0.9999 - val_loss: 4.5379 - val_accuracy: 0.4700\n",
            "Epoch 705/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 4.4940 - val_accuracy: 0.4750\n",
            "Epoch 706/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.9992 - val_loss: 4.5265 - val_accuracy: 0.4650\n",
            "Epoch 707/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 4.5419 - val_accuracy: 0.4700\n",
            "Epoch 708/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9993 - val_loss: 4.6398 - val_accuracy: 0.4700\n",
            "Epoch 709/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 0.9997 - val_loss: 4.5965 - val_accuracy: 0.4750\n",
            "Epoch 710/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 4.6500 - val_accuracy: 0.4750\n",
            "Epoch 711/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 4.6184 - val_accuracy: 0.4800\n",
            "Epoch 712/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 4.7069 - val_accuracy: 0.4750\n",
            "Epoch 713/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 0.9961 - val_loss: 4.6944 - val_accuracy: 0.4700\n",
            "Epoch 714/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 4.6766 - val_accuracy: 0.4750\n",
            "Epoch 715/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9998 - val_loss: 4.6970 - val_accuracy: 0.4750\n",
            "Epoch 716/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9984 - val_loss: 4.6830 - val_accuracy: 0.4800\n",
            "Epoch 717/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9999 - val_loss: 4.7852 - val_accuracy: 0.4700\n",
            "Epoch 718/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9996 - val_loss: 4.7315 - val_accuracy: 0.4750\n",
            "Epoch 719/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 4.7645 - val_accuracy: 0.4700\n",
            "Epoch 720/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 4.7339 - val_accuracy: 0.4750\n",
            "Epoch 721/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 4.7903 - val_accuracy: 0.4700\n",
            "Epoch 722/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 4.8219 - val_accuracy: 0.4700\n",
            "Epoch 723/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9987 - val_loss: 4.8357 - val_accuracy: 0.4700\n",
            "Epoch 724/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.9997 - val_loss: 4.8468 - val_accuracy: 0.4750\n",
            "Epoch 725/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 0.9990 - val_loss: 4.8106 - val_accuracy: 0.4700\n",
            "Epoch 726/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 4.8820 - val_accuracy: 0.4700\n",
            "Epoch 727/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 4.8998 - val_accuracy: 0.4650\n",
            "Epoch 728/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 4.9201 - val_accuracy: 0.4650\n",
            "Epoch 729/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 4.9739 - val_accuracy: 0.4650\n",
            "Epoch 730/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 4.9433 - val_accuracy: 0.4650\n",
            "Epoch 731/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9984 - val_loss: 5.0539 - val_accuracy: 0.4650\n",
            "Epoch 732/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 5.1028 - val_accuracy: 0.4650\n",
            "Epoch 733/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0474 - accuracy: 0.9886 - val_loss: 4.8437 - val_accuracy: 0.4750\n",
            "Epoch 734/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2683 - accuracy: 0.9265 - val_loss: 4.4262 - val_accuracy: 0.5000\n",
            "Epoch 735/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8899 - val_loss: 3.4916 - val_accuracy: 0.5000\n",
            "Epoch 736/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3221 - accuracy: 0.8859 - val_loss: 3.4497 - val_accuracy: 0.5350\n",
            "Epoch 737/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2579 - accuracy: 0.9022 - val_loss: 3.9631 - val_accuracy: 0.4800\n",
            "Epoch 738/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1500 - accuracy: 0.9408 - val_loss: 4.0094 - val_accuracy: 0.4900\n",
            "Epoch 739/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1288 - accuracy: 0.9573 - val_loss: 3.5266 - val_accuracy: 0.5450\n",
            "Epoch 740/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1187 - accuracy: 0.9543 - val_loss: 4.1324 - val_accuracy: 0.5000\n",
            "Epoch 741/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.9658 - val_loss: 4.0018 - val_accuracy: 0.4750\n",
            "Epoch 742/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0586 - accuracy: 0.9818 - val_loss: 3.8251 - val_accuracy: 0.5100\n",
            "Epoch 743/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9915 - val_loss: 3.6745 - val_accuracy: 0.5250\n",
            "Epoch 744/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 3.8191 - val_accuracy: 0.5000\n",
            "Epoch 745/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 0.9905 - val_loss: 4.0042 - val_accuracy: 0.5000\n",
            "Epoch 746/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 0.9983 - val_loss: 3.8739 - val_accuracy: 0.5200\n",
            "Epoch 747/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 0.9980 - val_loss: 3.9824 - val_accuracy: 0.5150\n",
            "Epoch 748/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9979 - val_loss: 3.9275 - val_accuracy: 0.5050\n",
            "Epoch 749/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 0.9991 - val_loss: 3.9479 - val_accuracy: 0.5100\n",
            "Epoch 750/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9992 - val_loss: 4.0308 - val_accuracy: 0.5000\n",
            "Epoch 751/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9991 - val_loss: 4.0130 - val_accuracy: 0.5100\n",
            "Epoch 752/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9966 - val_loss: 4.0592 - val_accuracy: 0.5000\n",
            "Epoch 753/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 0.9993 - val_loss: 4.0186 - val_accuracy: 0.5100\n",
            "Epoch 754/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.9984 - val_loss: 4.1034 - val_accuracy: 0.5100\n",
            "Epoch 755/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 3.9979 - val_accuracy: 0.5050\n",
            "Epoch 756/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9967 - val_loss: 3.9595 - val_accuracy: 0.5150\n",
            "Epoch 757/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.9984 - val_loss: 4.1235 - val_accuracy: 0.5050\n",
            "Epoch 758/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9997 - val_loss: 4.0611 - val_accuracy: 0.5100\n",
            "Epoch 759/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9975 - val_loss: 4.1078 - val_accuracy: 0.5050\n",
            "Epoch 760/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0222 - accuracy: 0.9961 - val_loss: 4.0924 - val_accuracy: 0.5150\n",
            "Epoch 761/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 4.0830 - val_accuracy: 0.5100\n",
            "Epoch 762/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 4.1207 - val_accuracy: 0.5100\n",
            "Epoch 763/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0152 - accuracy: 0.9975 - val_loss: 4.1367 - val_accuracy: 0.5100\n",
            "Epoch 764/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 0.9996 - val_loss: 4.1252 - val_accuracy: 0.5100\n",
            "Epoch 765/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 0.9986 - val_loss: 4.1144 - val_accuracy: 0.5100\n",
            "Epoch 766/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 0.9998 - val_loss: 4.1599 - val_accuracy: 0.5100\n",
            "Epoch 767/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.9999 - val_loss: 4.1475 - val_accuracy: 0.5100\n",
            "Epoch 768/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9999 - val_loss: 4.1433 - val_accuracy: 0.5100\n",
            "Epoch 769/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 0.9998 - val_loss: 4.1452 - val_accuracy: 0.5100\n",
            "Epoch 770/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 4.1455 - val_accuracy: 0.5100\n",
            "Epoch 771/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 0.9997 - val_loss: 4.1985 - val_accuracy: 0.4950\n",
            "Epoch 772/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 4.1946 - val_accuracy: 0.5000\n",
            "Epoch 773/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 4.2581 - val_accuracy: 0.4900\n",
            "Epoch 774/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 4.2196 - val_accuracy: 0.4950\n",
            "Epoch 775/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 4.2265 - val_accuracy: 0.5000\n",
            "Epoch 776/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9986 - val_loss: 4.2504 - val_accuracy: 0.4950\n",
            "Epoch 777/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 4.2678 - val_accuracy: 0.4900\n",
            "Epoch 778/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9998 - val_loss: 4.2748 - val_accuracy: 0.4950\n",
            "Epoch 779/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 4.2456 - val_accuracy: 0.5050\n",
            "Epoch 780/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9991 - val_loss: 4.2877 - val_accuracy: 0.4950\n",
            "Epoch 781/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 4.2882 - val_accuracy: 0.4950\n",
            "Epoch 782/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 4.3185 - val_accuracy: 0.4900\n",
            "Epoch 783/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 4.3081 - val_accuracy: 0.5050\n",
            "Epoch 784/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 4.3218 - val_accuracy: 0.5050\n",
            "Epoch 785/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9990 - val_loss: 4.3459 - val_accuracy: 0.5000\n",
            "Epoch 786/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 4.3652 - val_accuracy: 0.5000\n",
            "Epoch 787/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0190 - accuracy: 0.9961 - val_loss: 4.3814 - val_accuracy: 0.4950\n",
            "Epoch 788/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 4.3201 - val_accuracy: 0.5150\n",
            "Epoch 789/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 4.3811 - val_accuracy: 0.5050\n",
            "Epoch 790/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 4.3778 - val_accuracy: 0.4950\n",
            "Epoch 791/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 0.9961 - val_loss: 4.4654 - val_accuracy: 0.4900\n",
            "Epoch 792/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 4.3864 - val_accuracy: 0.4950\n",
            "Epoch 793/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 0.9975 - val_loss: 4.4691 - val_accuracy: 0.4850\n",
            "Epoch 794/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 0.9961 - val_loss: 4.4629 - val_accuracy: 0.4850\n",
            "Epoch 795/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 4.4631 - val_accuracy: 0.4850\n",
            "Epoch 796/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 4.4354 - val_accuracy: 0.4850\n",
            "Epoch 797/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 4.4804 - val_accuracy: 0.4850\n",
            "Epoch 798/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0189 - accuracy: 0.9961 - val_loss: 4.5163 - val_accuracy: 0.4800\n",
            "Epoch 799/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 4.5092 - val_accuracy: 0.4850\n",
            "Epoch 800/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 4.5481 - val_accuracy: 0.4800\n",
            "Epoch 801/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 4.5549 - val_accuracy: 0.4900\n",
            "Epoch 802/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 4.5479 - val_accuracy: 0.4800\n",
            "Epoch 803/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 4.5821 - val_accuracy: 0.4850\n",
            "Epoch 804/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 4.5605 - val_accuracy: 0.4950\n",
            "Epoch 805/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 4.5996 - val_accuracy: 0.4950\n",
            "Epoch 806/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 4.5587 - val_accuracy: 0.5000\n",
            "Epoch 807/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 4.6098 - val_accuracy: 0.5000\n",
            "Epoch 808/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 4.5923 - val_accuracy: 0.5000\n",
            "Epoch 809/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 4.5908 - val_accuracy: 0.5100\n",
            "Epoch 810/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 4.5470 - val_accuracy: 0.5100\n",
            "Epoch 811/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 4.6416 - val_accuracy: 0.5100\n",
            "Epoch 812/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.6958 - val_accuracy: 0.5050\n",
            "Epoch 813/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 4.7796 - val_accuracy: 0.4900\n",
            "Epoch 814/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1744 - accuracy: 0.9640 - val_loss: 3.9943 - val_accuracy: 0.5700\n",
            "Epoch 815/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.4508 - accuracy: 0.8820 - val_loss: 3.1888 - val_accuracy: 0.5650\n",
            "Epoch 816/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5586 - accuracy: 0.8711 - val_loss: 3.4900 - val_accuracy: 0.5100\n",
            "Epoch 817/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.3671 - accuracy: 0.8728 - val_loss: 3.4439 - val_accuracy: 0.5300\n",
            "Epoch 818/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3243 - accuracy: 0.8825 - val_loss: 3.4005 - val_accuracy: 0.5150\n",
            "Epoch 819/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2007 - accuracy: 0.9383 - val_loss: 3.2981 - val_accuracy: 0.5200\n",
            "Epoch 820/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1309 - accuracy: 0.9446 - val_loss: 3.8090 - val_accuracy: 0.4700\n",
            "Epoch 821/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1058 - accuracy: 0.9672 - val_loss: 3.4750 - val_accuracy: 0.5150\n",
            "Epoch 822/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1171 - accuracy: 0.9573 - val_loss: 3.4308 - val_accuracy: 0.5100\n",
            "Epoch 823/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.9740 - val_loss: 3.6995 - val_accuracy: 0.4800\n",
            "Epoch 824/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0596 - accuracy: 0.9791 - val_loss: 3.8421 - val_accuracy: 0.4800\n",
            "Epoch 825/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0450 - accuracy: 0.9853 - val_loss: 3.6518 - val_accuracy: 0.5100\n",
            "Epoch 826/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0348 - accuracy: 0.9920 - val_loss: 3.7075 - val_accuracy: 0.5000\n",
            "Epoch 827/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 0.9915 - val_loss: 3.9237 - val_accuracy: 0.4850\n",
            "Epoch 828/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9923 - val_loss: 3.9953 - val_accuracy: 0.4900\n",
            "Epoch 829/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 4.0828 - val_accuracy: 0.4800\n",
            "Epoch 830/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9965 - val_loss: 3.8810 - val_accuracy: 0.5100\n",
            "Epoch 831/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 3.9863 - val_accuracy: 0.5000\n",
            "Epoch 832/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9957 - val_loss: 4.0057 - val_accuracy: 0.5050\n",
            "Epoch 833/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 4.0616 - val_accuracy: 0.5050\n",
            "Epoch 834/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0224 - accuracy: 0.9974 - val_loss: 3.9426 - val_accuracy: 0.5100\n",
            "Epoch 835/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 4.0720 - val_accuracy: 0.5000\n",
            "Epoch 836/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0207 - accuracy: 0.9961 - val_loss: 4.1024 - val_accuracy: 0.5050\n",
            "Epoch 837/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 0.9982 - val_loss: 4.0243 - val_accuracy: 0.5200\n",
            "Epoch 838/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0178 - accuracy: 0.9976 - val_loss: 4.1925 - val_accuracy: 0.5100\n",
            "Epoch 839/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0157 - accuracy: 0.9983 - val_loss: 4.1405 - val_accuracy: 0.5100\n",
            "Epoch 840/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9958 - val_loss: 4.1751 - val_accuracy: 0.5100\n",
            "Epoch 841/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 0.9975 - val_loss: 4.2298 - val_accuracy: 0.5000\n",
            "Epoch 842/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9959 - val_loss: 4.2297 - val_accuracy: 0.5100\n",
            "Epoch 843/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9994 - val_loss: 4.2364 - val_accuracy: 0.5100\n",
            "Epoch 844/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 4.2022 - val_accuracy: 0.5100\n",
            "Epoch 845/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9973 - val_loss: 4.3073 - val_accuracy: 0.5000\n",
            "Epoch 846/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9989 - val_loss: 4.2079 - val_accuracy: 0.5050\n",
            "Epoch 847/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 4.3916 - val_accuracy: 0.4950\n",
            "Epoch 848/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 0.9984 - val_loss: 4.2559 - val_accuracy: 0.5050\n",
            "Epoch 849/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 4.3007 - val_accuracy: 0.5050\n",
            "Epoch 850/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 4.3585 - val_accuracy: 0.5050\n",
            "Epoch 851/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 4.3400 - val_accuracy: 0.5050\n",
            "Epoch 852/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 0.9995 - val_loss: 4.3587 - val_accuracy: 0.5050\n",
            "Epoch 853/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9960 - val_loss: 4.3775 - val_accuracy: 0.5050\n",
            "Epoch 854/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0104 - accuracy: 0.9992 - val_loss: 4.4014 - val_accuracy: 0.5100\n",
            "Epoch 855/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 4.4716 - val_accuracy: 0.5100\n",
            "Epoch 856/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 4.4267 - val_accuracy: 0.5100\n",
            "Epoch 857/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 4.4145 - val_accuracy: 0.5150\n",
            "Epoch 858/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 4.1363 - val_accuracy: 0.5150\n",
            "Epoch 859/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0471 - accuracy: 0.9865 - val_loss: 4.6154 - val_accuracy: 0.4950\n",
            "Epoch 860/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0516 - accuracy: 0.9888 - val_loss: 3.9632 - val_accuracy: 0.5300\n",
            "Epoch 861/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9890 - val_loss: 4.3816 - val_accuracy: 0.5000\n",
            "Epoch 862/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0865 - accuracy: 0.9773 - val_loss: 4.3889 - val_accuracy: 0.5000\n",
            "Epoch 863/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.9482 - val_loss: 4.3805 - val_accuracy: 0.5050\n",
            "Epoch 864/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1330 - accuracy: 0.9595 - val_loss: 4.3178 - val_accuracy: 0.4850\n",
            "Epoch 865/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0803 - accuracy: 0.9701 - val_loss: 4.0027 - val_accuracy: 0.5150\n",
            "Epoch 866/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9666 - val_loss: 3.8138 - val_accuracy: 0.5450\n",
            "Epoch 867/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0738 - accuracy: 0.9776 - val_loss: 4.0669 - val_accuracy: 0.5100\n",
            "Epoch 868/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9855 - val_loss: 4.1840 - val_accuracy: 0.5000\n",
            "Epoch 869/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9925 - val_loss: 3.9470 - val_accuracy: 0.5350\n",
            "Epoch 870/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 4.3802 - val_accuracy: 0.5000\n",
            "Epoch 871/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9952 - val_loss: 4.1529 - val_accuracy: 0.5050\n",
            "Epoch 872/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 4.2775 - val_accuracy: 0.5150\n",
            "Epoch 873/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9957 - val_loss: 4.2632 - val_accuracy: 0.5000\n",
            "Epoch 874/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130 - accuracy: 0.9996 - val_loss: 4.2163 - val_accuracy: 0.5000\n",
            "Epoch 875/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9997 - val_loss: 4.2962 - val_accuracy: 0.4950\n",
            "Epoch 876/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9987 - val_loss: 4.3600 - val_accuracy: 0.5000\n",
            "Epoch 877/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 0.9998 - val_loss: 4.2668 - val_accuracy: 0.5150\n",
            "Epoch 878/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0210 - accuracy: 0.9952 - val_loss: 4.4199 - val_accuracy: 0.4950\n",
            "Epoch 879/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.9996 - val_loss: 4.3218 - val_accuracy: 0.5100\n",
            "Epoch 880/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9999 - val_loss: 4.3885 - val_accuracy: 0.5100\n",
            "Epoch 881/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 4.3420 - val_accuracy: 0.5150\n",
            "Epoch 882/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 4.4103 - val_accuracy: 0.5000\n",
            "Epoch 883/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 4.3819 - val_accuracy: 0.5100\n",
            "Epoch 884/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9988 - val_loss: 4.4400 - val_accuracy: 0.5050\n",
            "Epoch 885/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 4.4744 - val_accuracy: 0.5050\n",
            "Epoch 886/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 4.4322 - val_accuracy: 0.5150\n",
            "Epoch 887/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 4.4543 - val_accuracy: 0.5150\n",
            "Epoch 888/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9991 - val_loss: 4.4369 - val_accuracy: 0.5150\n",
            "Epoch 889/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9998 - val_loss: 4.4843 - val_accuracy: 0.5150\n",
            "Epoch 890/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 4.4464 - val_accuracy: 0.5150\n",
            "Epoch 891/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 4.4643 - val_accuracy: 0.5100\n",
            "Epoch 892/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 4.5091 - val_accuracy: 0.5100\n",
            "Epoch 893/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 4.5663 - val_accuracy: 0.5000\n",
            "Epoch 894/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 4.3872 - val_accuracy: 0.5150\n",
            "Epoch 895/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 5.0574 - val_accuracy: 0.4750\n",
            "Epoch 896/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.9907 - val_loss: 4.6969 - val_accuracy: 0.5200\n",
            "Epoch 897/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9837 - val_loss: 4.5831 - val_accuracy: 0.4900\n",
            "Epoch 898/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1333 - accuracy: 0.9693 - val_loss: 4.3886 - val_accuracy: 0.5000\n",
            "Epoch 899/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0944 - accuracy: 0.9679 - val_loss: 3.9188 - val_accuracy: 0.5300\n",
            "Epoch 900/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1515 - accuracy: 0.9434 - val_loss: 4.1986 - val_accuracy: 0.5250\n",
            "Epoch 901/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0979 - accuracy: 0.9666 - val_loss: 4.2972 - val_accuracy: 0.5200\n",
            "Epoch 902/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0749 - accuracy: 0.9711 - val_loss: 4.7043 - val_accuracy: 0.4750\n",
            "Epoch 903/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9838 - val_loss: 4.0738 - val_accuracy: 0.5300\n",
            "Epoch 904/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 4.4973 - val_accuracy: 0.5050\n",
            "Epoch 905/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 0.9931 - val_loss: 4.5864 - val_accuracy: 0.4850\n",
            "Epoch 906/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 4.5536 - val_accuracy: 0.5050\n",
            "Epoch 907/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 4.5728 - val_accuracy: 0.4950\n",
            "Epoch 908/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 4.5307 - val_accuracy: 0.5100\n",
            "Epoch 909/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9988 - val_loss: 4.6505 - val_accuracy: 0.4850\n",
            "Epoch 910/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 4.6229 - val_accuracy: 0.5000\n",
            "Epoch 911/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 0.9979 - val_loss: 4.6256 - val_accuracy: 0.5000\n",
            "Epoch 912/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0202 - accuracy: 0.9961 - val_loss: 4.6751 - val_accuracy: 0.4950\n",
            "Epoch 913/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 4.6868 - val_accuracy: 0.5000\n",
            "Epoch 914/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0116 - accuracy: 0.9986 - val_loss: 4.6786 - val_accuracy: 0.5050\n",
            "Epoch 915/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 4.6795 - val_accuracy: 0.5050\n",
            "Epoch 916/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9987 - val_loss: 4.7402 - val_accuracy: 0.5050\n",
            "Epoch 917/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 4.6934 - val_accuracy: 0.5050\n",
            "Epoch 918/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9941 - val_loss: 4.8017 - val_accuracy: 0.5100\n",
            "Epoch 919/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9997 - val_loss: 4.7482 - val_accuracy: 0.5050\n",
            "Epoch 920/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 4.7742 - val_accuracy: 0.5000\n",
            "Epoch 921/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 4.8371 - val_accuracy: 0.5000\n",
            "Epoch 922/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9961 - val_loss: 4.8832 - val_accuracy: 0.4950\n",
            "Epoch 923/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 4.8173 - val_accuracy: 0.5050\n",
            "Epoch 924/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 4.8938 - val_accuracy: 0.4950\n",
            "Epoch 925/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 4.8195 - val_accuracy: 0.5100\n",
            "Epoch 926/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 4.9117 - val_accuracy: 0.5100\n",
            "Epoch 927/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0126 - accuracy: 0.9975 - val_loss: 4.9359 - val_accuracy: 0.5100\n",
            "Epoch 928/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 4.9603 - val_accuracy: 0.5050\n",
            "Epoch 929/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0170 - accuracy: 0.9961 - val_loss: 4.9682 - val_accuracy: 0.5050\n",
            "Epoch 930/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 4.9799 - val_accuracy: 0.5050\n",
            "Epoch 931/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 4.9852 - val_accuracy: 0.5050\n",
            "Epoch 932/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 4.9077 - val_accuracy: 0.5150\n",
            "Epoch 933/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 4.9626 - val_accuracy: 0.5100\n",
            "Epoch 934/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 4.9298 - val_accuracy: 0.5100\n",
            "Epoch 935/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 4.9793 - val_accuracy: 0.5100\n",
            "Epoch 936/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 5.0015 - val_accuracy: 0.5150\n",
            "Epoch 937/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 4.9974 - val_accuracy: 0.5150\n",
            "Epoch 938/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 4.9937 - val_accuracy: 0.5150\n",
            "Epoch 939/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 5.0369 - val_accuracy: 0.5100\n",
            "Epoch 940/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 5.0280 - val_accuracy: 0.5150\n",
            "Epoch 941/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 5.0732 - val_accuracy: 0.5200\n",
            "Epoch 942/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 5.0799 - val_accuracy: 0.5200\n",
            "Epoch 943/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 5.0598 - val_accuracy: 0.5200\n",
            "Epoch 944/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 5.0488 - val_accuracy: 0.5200\n",
            "Epoch 945/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 5.0647 - val_accuracy: 0.5150\n",
            "Epoch 946/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 5.1181 - val_accuracy: 0.5150\n",
            "Epoch 947/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 5.1212 - val_accuracy: 0.5150\n",
            "Epoch 948/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 5.1266 - val_accuracy: 0.5100\n",
            "Epoch 949/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 5.1461 - val_accuracy: 0.5100\n",
            "Epoch 950/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 5.1427 - val_accuracy: 0.5100\n",
            "Epoch 951/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 5.1323 - val_accuracy: 0.5150\n",
            "Epoch 952/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 5.1319 - val_accuracy: 0.5100\n",
            "Epoch 953/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 5.1059 - val_accuracy: 0.5150\n",
            "Epoch 954/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 5.1658 - val_accuracy: 0.5150\n",
            "Epoch 955/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 5.1570 - val_accuracy: 0.5150\n",
            "Epoch 956/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 5.2046 - val_accuracy: 0.5150\n",
            "Epoch 957/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 5.1367 - val_accuracy: 0.5200\n",
            "Epoch 958/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 5.2648 - val_accuracy: 0.5150\n",
            "Epoch 959/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 5.1919 - val_accuracy: 0.5200\n",
            "Epoch 960/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 5.2134 - val_accuracy: 0.5150\n",
            "Epoch 961/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 5.2582 - val_accuracy: 0.5200\n",
            "Epoch 962/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 5.2314 - val_accuracy: 0.5200\n",
            "Epoch 963/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 5.2160 - val_accuracy: 0.5150\n",
            "Epoch 964/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 5.2296 - val_accuracy: 0.5200\n",
            "Epoch 965/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 5.2666 - val_accuracy: 0.5250\n",
            "Epoch 966/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 5.2414 - val_accuracy: 0.5150\n",
            "Epoch 967/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 5.2982 - val_accuracy: 0.5150\n",
            "Epoch 968/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 5.2993 - val_accuracy: 0.5200\n",
            "Epoch 969/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 5.2550 - val_accuracy: 0.5150\n",
            "Epoch 970/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 5.3167 - val_accuracy: 0.5150\n",
            "Epoch 971/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 5.2796 - val_accuracy: 0.5200\n",
            "Epoch 972/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 5.2968 - val_accuracy: 0.5200\n",
            "Epoch 973/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 5.3070 - val_accuracy: 0.5250\n",
            "Epoch 974/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 5.3762 - val_accuracy: 0.5150\n",
            "Epoch 975/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 5.3511 - val_accuracy: 0.5200\n",
            "Epoch 976/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 5.3490 - val_accuracy: 0.5300\n",
            "Epoch 977/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 5.3395 - val_accuracy: 0.5200\n",
            "Epoch 978/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 5.4294 - val_accuracy: 0.5200\n",
            "Epoch 979/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 5.4153 - val_accuracy: 0.5100\n",
            "Epoch 980/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 5.3718 - val_accuracy: 0.5200\n",
            "Epoch 981/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 5.4272 - val_accuracy: 0.5250\n",
            "Epoch 982/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 5.3245 - val_accuracy: 0.5250\n",
            "Epoch 983/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 5.3638 - val_accuracy: 0.5250\n",
            "Epoch 984/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 5.3439 - val_accuracy: 0.5350\n",
            "Epoch 985/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 5.3911 - val_accuracy: 0.5300\n",
            "Epoch 986/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 5.4265 - val_accuracy: 0.5200\n",
            "Epoch 987/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 5.4028 - val_accuracy: 0.5300\n",
            "Epoch 988/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 5.4328 - val_accuracy: 0.5300\n",
            "Epoch 989/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 5.3313 - val_accuracy: 0.5250\n",
            "Epoch 990/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 5.4748 - val_accuracy: 0.5250\n",
            "Epoch 991/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 5.4652 - val_accuracy: 0.5200\n",
            "Epoch 992/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1714 - accuracy: 0.9660 - val_loss: 6.3288 - val_accuracy: 0.4400\n",
            "Epoch 993/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5005 - accuracy: 0.8747 - val_loss: 4.3310 - val_accuracy: 0.5300\n",
            "Epoch 994/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.8582 - val_loss: 3.9209 - val_accuracy: 0.5600\n",
            "Epoch 995/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3718 - accuracy: 0.8665 - val_loss: 4.2498 - val_accuracy: 0.4800\n",
            "Epoch 996/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.8760 - val_loss: 3.2533 - val_accuracy: 0.5700\n",
            "Epoch 997/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1950 - accuracy: 0.9105 - val_loss: 3.4547 - val_accuracy: 0.5700\n",
            "Epoch 998/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2278 - accuracy: 0.9094 - val_loss: 4.4017 - val_accuracy: 0.4650\n",
            "Epoch 999/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1629 - accuracy: 0.9421 - val_loss: 3.6854 - val_accuracy: 0.5450\n",
            "Epoch 1000/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1094 - accuracy: 0.9581 - val_loss: 3.3870 - val_accuracy: 0.5550\n"
          ]
        }
      ],
      "source": [
        "#docs_infra: no_execute\n",
        "classical_history = model.fit(x_train,\n",
        "          y_train_new,\n",
        "          batch_size=32,\n",
        "          epochs=1000,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test_new))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzhs1_CjL_f8"
      },
      "source": [
        "### 3.3 Compare performance\n",
        "Now that you have trained the two models you can quickly plot the performance gaps in the validation data between the two. Typically both models will achieve > 0.9 accuaracy on the training data. However on the validation data it becomes clear that only the information found in the PQK features is enough to make the model generalize well to unseen instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "t9CDiHTmAEu-",
        "outputId": "5f590473-299a-4afb-d6a9-74193ff45ec8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f603c537a10>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#docs_infra: no_execute\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(classical_history.history['accuracy'], label='accuracy_classical')\n",
        "plt.plot(classical_history.history['val_accuracy'], label='val_accuracy_classical')\n",
        "plt.plot(pqk_history.history['accuracy'], label='accuracy_quantum')\n",
        "plt.plot(pqk_history.history['val_accuracy'], label='val_accuracy_quantum')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h9p44uCMzHQ"
      },
      "source": [
        "Success: You have engineered a stilted quantum dataset that can intentionally defeat classical models in a fair (but contrived) setting. Try comparing results using other types of classical models. The next step is to try and see if you can find new and interesting datasets that can defeat classical models without needing to engineer them yourself!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HObJC2fVlhgg"
      },
      "source": [
        "## 4. Important conclusions\n",
        "\n",
        "There are several important conclusions you can draw from this and the [MNIST](https://www.tensorflow.org/quantum/tutorials/mnist) experiments:\n",
        "\n",
        "1. It's very unlikely that the quantum models of today will beat classical model performance on classical data. Especially on today's classical datasets that can have upwards of a million datapoints.\n",
        "\n",
        "2. Just because the data might come from a hard to classically simulate quantum circuit, doesn't necessarily make the data hard to learn for a classical model.\n",
        "\n",
        "3. Datasets (ultimately quantum in nature) that are easy for quantum models to learn and hard for classical models to learn do exist, regardless of model architecture or training algorithms used."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "quantum_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}