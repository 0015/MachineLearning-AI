# 100 days of Artificial Intelligence

This is the 100 days of Machine Learning, Deep Learning, Artificial Intelligence, and Optimization mini-projects that I picked up at the start of January 2022. I have used various environments and Google Colab for this work as it required various libraries and datasets to be downloaded. The following are the problems that I tackled: 

* **Day 1 (01/01/2022)**: [GradCAM Implementation on Dogs v/s Cats using VGG16 pretrained models](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/001_GradCAM_basics)

Classification for Cat (GradCAM-based Explainability)          |  Classification for Dog (GradCAM-based Explainability)
:-------------------------:|:-------------------------:
![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/001_GradCAM_basics/gradcam_cat.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/001_GradCAM_basics/gradcam_dog.jpg)

* **Day 2 (01/02/2022)**: [Multi-task Learning (focussed on Object Localization)](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/002_Multi_task_Learning)

<img src="https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/002_Multi_task_Learning/Image_predict.png" width="500" height="450">
<!-- %% ![](){:height="700px" width="700px"} -->

* **Day 3 (01/03/2022)**: [Implementing GradCAM on Computer Vision problems](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/003_GradCAM_for_CV)
  1. GradCAM for Semantic Segmentation
  2. GradCAM for ObjectDetection

Computer Vision domains         |  CAM methods used         | Detected Images         | CAM-based images
:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:
Semantic Segmentation  | GradCAM  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/003_GradCAM_for_CV/SemanticSegmentation.png)  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/003_GradCAM_for_CV/GradCAMonSS.png)
Object Detection      | EigenCAM  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/003_GradCAM_for_CV/ObjectDetection.png)  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/003_GradCAM_for_CV/EigenCAMonOD.png)
Object Detection      | AblationCAM  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/003_GradCAM_for_CV/ObjectDetection.png)  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/003_GradCAM_for_CV/AblationCAMonOD.png)

* **Day 4 (01/04/2022)**: [Deep Learning using PointNet-based Dataset](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/004_PointNet_Deep_Learning)
  1. Classification

3D Point Clouds         |  Meshes Used         | Sampled Meshes        
:-------------------------:|:-------------------------:|:-------------------------:
Beds          | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/004_PointNet_Deep_Learning/Bed_Actual_off.gif)  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/004_PointNet_Deep_Learning/Bed_sampled_faces_on.gif)  
Chair      | TBA   |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/004_PointNet_Deep_Learning/Chair_Actual_off.gif)


  2. Segmentation

<img src="https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/004_PointNet_Deep_Learning/Airplane_Actual_off.gif" width="1024" height="640">
<!-- ![]() -->

* **Day 5 (01/05/2022)**: [Graph Neural Network on YouChoose dataset](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/005_Graph_Neural_Network)
1. Implementing GNNs on YouChoose-Click dataset
2. Implementing GNNs on YouChoose-Buy dataset

Dataset         |  Loss Curve         | Accuracy Curve        
:-------------------------:|:-------------------------:|:-------------------------:
YouChoose-Click          | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/005_Graph_Neural_Network/loss_1.png)  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/005_Graph_Neural_Network/accuracy_1.png)  
YouChoose-Buy      | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/005_Graph_Neural_Network/loss_2.png)   |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/005_Graph_Neural_Network/accuracy_2.png)

* **Day 6 (01/06/2022)**: [Graph neural Network for Recommnedation Systems](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/006_Graph_Neural_Network_for_Recommender_System)
* **Day 7 (01/07/2022)**: [Vision Transformers for efficient Image Classification](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/007_Vision_Transformer)

SN         |  Training and Validation Metrices              
:-------------------------:|:-------------------------:
1  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/007_Vision_Transformer/accuracy_1.png)  
2  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/007_Vision_Transformer/loss_1.png)

* **Day 8 (01/08/2022)**: [Graph Neural Networks for Molecular Machine Learning](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/008_GNNs_on_Molecular_ML)

Loss Metrices              
:-------------------------:
![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/008_GNNs_on_Molecular_ML/loss_1.png) 

* **Day 9 (01/09/2022)**: [Latent 3D Point Cloud Generation using GANs and Auto Encoders](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/009_Latent_3D_PointCloud_Generation_using_GANs)

* **Day 10 (01/10/2022)**: [Deep Learning introduced on Audio Signal](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/010_Deep_Learning_for_Audio_Signals)

* **Day 11 (01/11/2022)**: [Ant-Colony Optimization](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/011_Ant_Colony_Optimization)

Explore Difference between Ant Colony Optimization and Genetic Algorithms for Travelling Salesman Problem. 

Methods Used         |  Geo-locaion graph              
:-------------------------:|:-------------------------:
Ant Colony Optimization | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/011_Ant_Colony_Optimization/AntColonyOptimization.png)  
Genetic Algorithm       | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/011_Ant_Colony_Optimization/GeneticAlgorithm.png)


* **Day 12 (01/12/2022)**: [Particle Swarm Optimization](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/012_Particle_Swarm_Optimization) 

* **Day 13 (01/13/2022)**: [Cuckoo Search Optimization](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/013_Cuckoo_Search_Optimization)

* **Day 14 (01/14/2022)**: [Physics-based Optimization algorithms](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/014_Physicsbased_Optimization_Algos)
Explored the contents of Physics-based optimization techniques such as: 
1. Tug-Of-War Optimization (Kaveh, A., & Zolghadr, A. (2016). A novel meta-heuristic algorithm: tug of war optimization. Iran University of Science & Technology, 6(4), 469-492.)
2. Nuclear Reaction Optimization (Wei, Z., Huang, C., Wang, X., Han, T., & Li, Y. (2019). Nuclear Reaction Optimization: A novel and powerful physics-based algorithm for global optimization. IEEE Access.)
``` 
    + So many equations and loops - take time to run on larger dimension 
    + General O (g * n * d) 
    + Good convergence curse because the used of gaussian-distribution and levy-flight trajectory
    + Use the variant of Differential Evolution
```
3. Henry Gas Solubility Optimization (Hashim, F. A., Houssein, E. H., Mabrouk, M. S., Al-Atabany, W., & Mirjalili, S. (2019). Henry gas solubility optimization: A novel physics-based algorithm. Future Generation Computer Systems, 101, 646-667.)

```
    + Too much constants and variables
    + Still have some unclear point in Eq. 9 and Algorithm. 1
    + Can improve this algorithm by opposition-based and levy-flight
    + A wrong logic code in line 91 "j = id % self.n_elements" => to "j = id % self.n_clusters" can make algorithm converge faster. I don't know why?
    + Good results come from CEC 2014
```

* **Day 15 (01/15/2022)**: [Human Activity-based Optimization algorithms](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/015_Human_Activitybased_Optimization_Algo)
Explored the contents of Human Activity-based optimization techniques such as: 
1. Queuing Search Algorithm (Zhang, J., Xiao, M., Gao, L., & Pan, Q. (2018). Queuing search algorithm: A novel metaheuristic algorithm for solving engineering optimization problems. Applied Mathematical Modelling, 63, 464-490.)

* **Day 16 (01/16/2022)**: [Evolutionary Optimization algorithms](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/016_Evoluationarybased_Optimization_Algos)
Explored the contents of Human Activity-based optimization techniques such as:
Genetic Algorithms (Holland, J. H. (1992). Genetic algorithms. Scientific american, 267(1), 66-73)
Differential Evolution (Storn, R., & Price, K. (1997). Differential evolution–a simple and efficient heuristic for global optimization over continuous spaces. Journal of global optimization, 11(4), 341-359)
Coral Reefs Optimization Algorithm (Salcedo-Sanz, S., Del Ser, J., Landa-Torres, I., Gil-López, S., & Portilla-Figueras, J. A. (2014). The coral reefs optimization algorithm: a novel metaheuristic for efficiently solving optimization problems. The Scientific World Journal, 2014)

* **Day 17 (01/17/2022)**: [Swarm-based Optimization algorithms]()
Explored the contents of Swarm-based optimization techniques such as: 
1. Particle Swarm Optimization (Eberhart, R., & Kennedy, J. (1995, October). A new optimizer using particle swarm theory. In MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science (pp. 39-43). IEEE)
2. Cat Swarm Optimization (Chu, S. C., Tsai, P. W., & Pan, J. S. (2006, August). Cat swarm optimization. In Pacific Rim international conference on artificial intelligence (pp. 854-858). Springer, Berlin, Heidelberg)
3. Whale Optimization (Mirjalili, S., & Lewis, A. (2016). The whale optimization algorithm. Advances in engineering software, 95, 51-67)
4. Bacterial Foraging Optimization (Passino, K. M. (2002). Biomimicry of bacterial foraging for distributed optimization and control. IEEE control systems magazine, 22(3), 52-67)
5. Adaptive Bacterial Foraging Optimization (Yan, X., Zhu, Y., Zhang, H., Chen, H., & Niu, B. (2012). An adaptive bacterial foraging optimization algorithm with lifecycle and social learning. Discrete Dynamics in Nature and Society, 2012)
6. Artificial Bee Colony (Karaboga, D., & Basturk, B. (2007, June). Artificial bee colony (ABC) optimization algorithm for solving constrained optimization problems. In International fuzzy systems association world congress (pp. 789-798). Springer, Berlin, Heidelberg)
7. Pathfinder Algorithm (Yapici, H., & Cetinkaya, N. (2019). A new meta-heuristic optimizer: Pathfinder algorithm. Applied Soft Computing, 78, 545-568)
8. Harris Hawks Optimization (Heidari, A. A., Mirjalili, S., Faris, H., Aljarah, I., Mafarja, M., & Chen, H. (2019). Harris hawks optimization: Algorithm and applications. Future Generation Computer Systems, 97, 849-872)
9. Sailfish Optimizer (Shadravan, S., Naji, H. R., & Bardsiri, V. K. (2019). The Sailfish Optimizer: A novel nature-inspired metaheuristic algorithm for solving constrained engineering optimization problems. Engineering Applications of Artificial Intelligence, 80, 20-34)

*Credits (from Day 14--17): Learnt a lot due to [Nguyen Van Thieu](https://github.com/thieu1995/metaheuristics) and his repository that deals with metaheuristic algorithms. Plan to use these algorithms in the problems enountered later onwards.*

* **Day 18 (01/18/2022)**: [Grey Wolf Optimization Algorithm](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/018_Grey_Wolf_Optimizer)

* **Day 19 (01/19/2022)**: [Firefly Optimization Algorithm](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/019_Firefly_Algorithm)

* **Day 20 (01/20/2022)**: [Covariance Matrix Adaptation Evolution Strategy](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/020_Covariance_Matrix_Adaptation_Evolution_Strategy) Referenced from CMA (can be installed using ```pip install cma```)

CMAES without bounds          |  CMAES with bounds
:-------------------------:|:-------------------------:
![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/020_Covariance_Matrix_Adaptation_Evolution_Strategy/CMAES.png)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/020_Covariance_Matrix_Adaptation_Evolution_Strategy/CMAES_with_bounds.png)

Refered from: Nikolaus Hansen, Dirk Arnold, Anne Auger. Evolution Strategies. Janusz Kacprzyk; Witold Pedrycz. Handbook of Computational Intelligence, Springer, 2015, 978-3-622-43504-5. ffhal-01155533f

* **Day 21 (01/21/2022)**: [Copy Move Forgery Detection using SIFT Features](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/021_Copy_Move_Forgery_Detection)

S. No          |  Forged Images          |  Forgery Detection in Images
:-------------:|:-----------------------:|:-------------------------:
1     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/021_Copy_Move_Forgery_Detection/Images/forged1.png)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/021_Copy_Move_Forgery_Detection/CopyMoveDetection/forged1_60_2_2022_01_30_01_05_13.png)
2     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/021_Copy_Move_Forgery_Detection/Images/forged2.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/021_Copy_Move_Forgery_Detection/CopyMoveDetection/forged2_60_2_2022_01_30_01_06_01.jpg)
3     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/021_Copy_Move_Forgery_Detection/Images/forged3.png)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/021_Copy_Move_Forgery_Detection/CopyMoveDetection/forged3_60_2_2022_01_30_01_06_18.png)


* **Day 22 (01/22/2022)**: [Contour Detection using OpenCV](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/022_Contour_Detection_using_OpenCV)

Contour Approximation Method          |  Retrieval Method          |  Actual Image          |  Contours Detected
:-------------:|:-------------:|:-----------------------:|:-------------------------:
CHAIN_APPROX_NONE     |  RETR_TREE     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/img4.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/contours_none_image4.jpg)
CHAIN_APPROX_SIMPLE   |  RETR_TREE     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/img4.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/contours_simple_image4.jpg)
CHAIN_APPROX_SIMPLE   |  RETR_CCOMP    |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/img5.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/contours_retr_ccomp_img5.jpg)
CHAIN_APPROX_SIMPLE   |  RETR_LIST     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/img5.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/contours_retr_list_img5.jpg)
CHAIN_APPROX_SIMPLE   |  RETR_EXTERNAL |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/img5.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/contours_retr_external_img5.jpg)
CHAIN_APPROX_SIMPLE   |  RETR_TREE     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/img5.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/022_Contour_Detection_using_OpenCV/Images/contours_retr_tree_img5.jpg)

Referenced from [here](https://learnopencv.com/contour-detection-using-opencv-python-c/)

* **Day 23 (01/23/2022)**: [Simple Background Detection using OpenCV](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/023_Simple_Background_Estimation)

File used          |  Actual File          |  Estimated Background
:-------------:|:-------------:|:-----------------------:
Video 1     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/023_Simple_Background_Estimation/data/video1.gif)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/023_Simple_Background_Estimation/Images/background1.jpg)

* **Day 24 (01/24/2022)**: [Basics of Quantum Machine Learning with TensorFlow-Quantum Part 1](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/024_Quantum_Machine_Learning_Part_I)

* **Day 25 (01/25/2022)**: [Basics of Quantum Machine Learning with TensorFlow-Quantum Part 2](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/025_Quantum_Machine_Learning_Part_II)

* **Day 26 (01/26/2022)**: [Latent Space Representation Part 1: AutoEncoders](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/026_LSR_I_Autoencoders)

Methods used       |  t-SNE Representation
:-------------:|:-------------:
Using PCA  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/026_LSR_I_Autoencoders/Images/tSNE-PCA-fashiondb.png)
Using Autoencoders  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/026_LSR_I_Autoencoders/Images/tSNE-Latent-fashiondb.png)


* **Day 27 (01/27/2022)**: [Latent Space Representation Part 2: Variational AutoEncoders](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/027_LSR_II_Variational_Autoencoders)

Methods used       |  Representation
:-------------:|:-------------:
Using PCA  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/026_LSR_I_Autoencoders/Images/tSNE-PCA-fashiondb.png)
Using Variational Autoencoders  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/027_LSR_II_Variational_Autoencoders/Images/vae.png)

* **Day 28 (01/28/2022)**: [Latent Space Representation Part 3: Deep Convolutional Generative Adversarial Networks](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/028_LSR_III_GANs)

Methods used       |  Representation
:-------------:|:-------------:
Using Generative Adversarial Networks  | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/028_LSR_III_GANs/bicycles.png)

* **Day 29 (01/29/2022)**: [Entity Recognition in Natural Language Processing]()

* **Day 30 (01/30/2022)**: [Head-Pose Detection using 3D coordinates for Multiple People](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/030_Face_Pose_Estimation)

Library Used          |  Actual Image          |  Facial Detection          |  Facial Landmarks           |  Head Pose Estimation
:-------------:|:-------------:|:-------------:|:-----------------------:|:-------------------------:
Haar Cascades     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/Images/faces01.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/TestImages/haar_faces01.jpg)  |  (To be done)  |  (To be done)
Haar Cascades     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/Images/faces03.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/TestImages/haar_faces03.jpg)   |  (To be done)  |  (To be done)
Mult-task Cascaded Convolutional Neural Networks   | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/Images/faces01.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/TestImages/mtcnn_faces01.jpg)   |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/LandmarkDetected/mtcnn_landmarks_faces01.jpg)   |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/HeadPosesDetected/mtcnn_headpose_faces01.jpg) 
Mult-task Cascaded Convolutional Neural Networks   | ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/Images/faces03.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/TestImages/mtcnn_faces03.jpg)   |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/LandmarkDetected/mtcnn_landmarks_faces03.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/HeadPosesDetected/mtcnn_headpose_faces03.jpg) 
OpenCV's Deep Neural Network   |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/Images/faces01.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/TestImages/dnn_faces01.jpg)   |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/LandmarkDetected/dnn_landmarks_faces01.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/HeadPosesDetected/dnn_headpose_faces01.jpg)  
OpenCV's Deep Neural Network   |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/Images/faces03.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/TestImages/dnn_faces03.jpg)   |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/LandmarkDetected/dnn_landmarks_faces03.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/030_Face_Pose_Estimation/HeadPosesDetected/dnn_headpose_faces03.jpg)  

(Yet to use Dlib for facial detection.)

* **Day 31 (01/31/2022)**: [Depth Estimation for face using OpenCV](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/031_Depth_Estimation_for_faces)

Model Used          |  Actual Image          |  Monocular Depth Estimation          |  Depth Map
:-------------:|:-------------:|:-------------:|:-------------:
MiDaS model for Depth Estimation      |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/031_Depth_Estimation_for_faces/Images/faces01.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/031_Depth_Estimation_for_faces/DepthEstimation/depth_estimation_faces01.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/031_Depth_Estimation_for_faces/DepthEstimation/depth_map_faces01.jpg)  
MiDaS model for Depth Estimation     |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/031_Depth_Estimation_for_faces/Images/faces03.jpg)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/031_Depth_Estimation_for_faces/DepthEstimation/depth_estimation_faces03.jpg)   |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/031_Depth_Estimation_for_faces/DepthEstimation/depth_map_faces03.jpg)  

Ref: (The model used was [Large Model ONNX file](https://github.com/isl-org/MiDaS/releases/tag/v2_1))

* **Day 32 - 37 (02/01/2022 - 02/06/2022)**: [Exploring Latent Spaces in Depth]

Model Used          |  Paper Link          |  Pictures
:-------------:|:-------------:|:-------------:
Auxiliary Classifier GAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Papers%20Studied/Auxiliary_Classifier_GANs.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Images/acgan.gif)
Bicycle GAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Papers%20Studied/Bicycle_GANs.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Images/bicyclegan.png)
Conditional GAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Papers%20Studied/Conditional_GANs.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Images/bicyclegan.png)
Cluster GAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Papers%20Studied/Cluster_GANs.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Images/cluster_gan.gif)
Context Conditional GAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Papers%20Studied/Context_Conditional_GANs.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Images/conditional_gan.gif)
Context Encoder      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Papers%20Studied/Context_Conditional_GANs.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Images/context_encoder.png)
Cycle GAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Papers%20Studied/Cycle_GANs.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/032_Exploring_Latent_Spaces_in_Depth_I/Images/cyclegan.png)
Deep Convolutional GAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/033_Exploring_Latent_Spaces_in_Depth_II/Papers%20Studied/dcgan.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/033_Exploring_Latent_Spaces_in_Depth_II/Images/dcgan.gif)
DiscoGANs      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/033_Exploring_Latent_Spaces_in_Depth_II/Papers%20Studied/disco_gan.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/033_Exploring_Latent_Spaces_in_Depth_II/Images/discogan.png)
Enhanced SuperRes GAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/033_Exploring_Latent_Spaces_in_Depth_II/Papers%20Studied/esrgan.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/033_Exploring_Latent_Spaces_in_Depth_II/Images/enhanced_superresgan.png)
InfoGAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/034_Exploring_Latent_Spaces_in_Depth_III/Papers%20Studied/info_gan.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/034_Exploring_Latent_Spaces_in_Depth_III/Images/infogan.gif)
MUNIT      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/034_Exploring_Latent_Spaces_in_Depth_III/Papers%20Studied/munit.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/034_Exploring_Latent_Spaces_in_Depth_III/Images/munit.png)
Pix2Pix      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/035_Exploring_Latent_Spaces_in_Depth_IV/Papers%20Studied/pix2pix.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/035_Exploring_Latent_Spaces_in_Depth_IV/Images/pix2pix.png)
PixelDA      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/035_Exploring_Latent_Spaces_in_Depth_IV/Papers%20Studied/pixelDA.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/035_Exploring_Latent_Spaces_in_Depth_IV/Images/pixelda.png)
StarGAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/036_Exploring_Latent_Spaces_in_Depth_V/papers/stargan.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/036_Exploring_Latent_Spaces_in_Depth_V/Images/stargan.png)
SuperRes GAN      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/036_Exploring_Latent_Spaces_in_Depth_V/papers/srgan.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/036_Exploring_Latent_Spaces_in_Depth_V/Images/superresgan.png)
WGAN DIV      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/037_Exploring_Latent_Spaces_in_Depth_VI/papers/wgan_div.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/037_Exploring_Latent_Spaces_in_Depth_VI/Images/wgan_div.gif)
WGAN GP      |  [Paper](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/037_Exploring_Latent_Spaces_in_Depth_VI/papers/wgan_gp.pdf)  |  ![](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/037_Exploring_Latent_Spaces_in_Depth_VI/Images/wgan_gp.gif)

* **Day 38 (02/07/2022)**: [Human Activity Recognition, Non-Maximum Supression, Object Detection](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/038_HAR_NMS_Object_Detection)
 
* **Day 39 (02/08/2022)**: [Pose Estimation using different Algorithms](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/039_Pose_Detection_using_different_methods)
 
* **Day 40 (02/09/2022)**: [Optical Flow Estimation](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/040_Optical_Flow_Estimation)

* **Day 41 (02/10/2022)**: [Vision Transformers Explainability](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/041_Vision_Transformers_Explainability)

* **Day 42 (02/11/2022)**: [Explainability in Self Driving Cars](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/042_Explainability_in_Self_Driving_Cars)

[video](https://github.com/AnshMittal1811/MachineLearning-AI/blob/master/042_Explainability_in_Self_Driving_Cars/Images/How%20a%20self%20driving%20car%20sees%20the%20world.mp4)

* **Day 43 (02/12/2022)**: [TimeSformer Intuition](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/043_TimeSformers_Intuition)

* **Day 44 (02/13/2022)**: [Image Deraining Implementation using SPANet](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/044_Image_Deraining_Implementation)
Referred from: RESCAN by Xia Li et al. The CUDA extension references pyinn by Sergey Zagoruyko and DSC(CF-Caffe) by Xiaowei Hu!!

* **Day 45 (02/14/2022)**: [G-SimCLR Intuition](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/045_G-SimCLR%20Intuition)

* **Day 46 (02/15/2022)**: [Topic Modelling in Natural Language Processing]()

* **Day 47 (02/16/2022)**: [img2pose: Face Alignment and Detection via 6DoF, Face Pose Estimation](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/047_img2pose_Intuition) This repository draws directly from the one mentioned here. I've tried implementing it on different datasets such as the BIWI ad AWFL dataset. Furthermore, the models weren't trained from scratch. The run was meant to be a way to report the numbers in the paper.

**Paper accepted to the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2021**

<figure>
  <img src="./047_img2pose_Intuition/teaser.jpeg" style="width:100%">
  <figcaption>Figure 1: We estimate the 6DoF rigid transformation of a 3D face (rendered in silver), aligning it with even the tiniest faces, without face detection or facial landmark localization. Our estimated 3D face locations are rendered by descending distances from the camera, for coherent visualization.</figcaption>
</figure>

**Summary:** This repository provides a novel method for six degrees of fredoom (6DoF) detection on multiple faces without the need of prior face detection. After prediction, one can visualize the detections (as show in the figure above), customize projected bounding boxes, or crop and align each face for further processing. See details below.


**Paper details**

[Vítor Albiero](https://vitoralbiero.netlify.app), Xingyu Chen, [Xi Yin](https://xiyinmsu.github.io/), Guan Pang, [Tal Hassner](https://talhassner.github.io/home/), "*img2pose: Face Alignment and Detection via 6DoF, Face Pose Estimation,*" CVPR, 2021, [arXiv:2012.07791](https://arxiv.org/abs/2012.07791)


**Abstract**
> We propose real-time, six degrees of freedom (6DoF), 3D face pose estimation without face detection or landmark localization. We observe that estimating the 6DoF rigid transformation of a face is a simpler problem than facial landmark detection, often used for 3D face alignment. In addition, 6DoF offers more information than face bounding box labels. We leverage these observations to make multiple contributions: (a) We describe an easily trained, efficient, Faster R-CNN--based model which regresses 6DoF pose for all faces in the photo, without preliminary face detection. (b) We explain how pose is converted and kept consistent between the input photo and arbitrary crops created while training and evaluating our model. (c) Finally, we show how face poses can replace detection bounding box training labels. Tests on AFLW2000-3D and BIWI show that our method runs at real-time and outperforms state of the art (SotA) face pose estimators. Remarkably, our method also surpasses SotA models of comparable complexity on the WIDER FACE detection benchmark, despite not been optimized on bounding box labels.

**Video Spotlight**
[CVPR 2021 Spotlight](https://youtu.be/vDGlvpnzXGo)


**Installation**

Install dependecies with Python 3.
```
pip install -r requirements.txt
```
Install the renderer, which is used to visualize predictions. The renderer implementation is forked from [here](https://github.com/cleardusk/3DDFA_V2/tree/master/Sim3DR).
```
cd Sim3DR
sh build_sim3dr.sh
```

**Training**
**Prepare WIDER FACE dataset**
First, download our annotations as instructed in [Annotations](https://github.com/vitoralbiero/img2pose/wiki/Annotations).

Download [WIDER FACE](http://shuoyang1213.me/WIDERFACE/) dataset and extract to datasets/WIDER_Face.

Then, to create the train and validation files (LMDB), run the following scripts.

```
python3 convert_json_list_to_lmdb.py \
--json_list ./annotations/WIDER_train_annotations.txt \
--dataset_path ./datasets/WIDER_Face/WIDER_train/images/ \
--dest ./datasets/lmdb/ \
-—train
```
This first script will generate a LMDB dataset, which contains the training images along with annotations. It will also output a pose mean and std deviation files, which will be used for training and testing.
```
python3 convert_json_list_to_lmdb.py  \
--json_list ./annotations/WIDER_val_annotations.txt  \
--dataset_path ./datasets/WIDER_Face/WIDER_val/images/  \
--dest ./datasets/lmdb
```
This second script will create a LMDB containing the validation images along with annotations.

**Train**
Once the LMDB train/val files are created, to start training simple run the script below.
```
CUDA_VISIBLE_DEVICES=0 python3 train.py \
--pose_mean ./datasets/lmdb/WIDER_train_annotations_pose_mean.npy \
--pose_stddev ./datasets/lmdb/WIDER_train_annotations_pose_stddev.npy \
--workspace ./workspace/ \
--train_source ./datasets/lmdb/WIDER_train_annotations.lmdb \
--val_source ./datasets/lmdb/WIDER_val_annotations.lmdb \
--prefix trial_1 \
--batch_size 2 \
--lr_plateau \
--early_stop \
--random_flip \
--random_crop \
--max_size 1400
```
To train with multiple GPUs (in the example below 4 GPUs), use the script below.
```
python3 -m torch.distributed.launch --nproc_per_node=4 --use_env train.py \
--pose_mean ./datasets/lmdb/WIDER_train_annotations_pose_mean.npy \
--pose_stddev ./datasets/lmdb/WIDER_train_annotations_pose_stddev.npy \
--workspace ./workspace/ \
--train_source ./datasets/lmdb/WIDER_train_annotations.lmdb \
--val_source ./datasets/lmdb/WIDER_val_annotations.lmdb \
--prefix trial_1 \
--batch_size 2 \
--lr_plateau \
--early_stop \
--random_flip \
--random_crop \
--max_size 1400 \
--distributed
```

**Training on your own dataset**
If your dataset has facial landmarks and bounding boxes already annotated, store them into JSON files following the same format as in the [WIDER FACE annotations](https://github.com/vitoralbiero/img2pose/wiki/Annotations).

If not, run the script below to annotate your dataset. You will need a detector and import it inside the script.
```
python3 utils/annotate_dataset.py 
--image_list list_of_images.txt 
--output_path ./annotations/dataset_name
```
After the dataset is annotated, create a list pointing to the JSON files there were saved. Then, follow the steps in [Prepare WIDER FACE dataset](https://github.com/vitoralbiero/img2pose#prepare-wider-face-dataset) replacing the WIDER annotations with your own dataset annotations. Once the LMDB and pose files are created, follow the steps in [Train](https://github.com/vitoralbiero/img2pose#train) replacing the WIDER LMDB and pose files with your dataset own files.

**Testing**
To evaluate with the pretrained model, download the model from [Model Zoo](https://github.com/vitoralbiero/img2pose/wiki/Model-Zoo), and extract it to the main folder. It will create a folder called models, which contains the model weights and the pose mean and std dev that was used for training.

If evaluating with own trained model, change the pose mean and standard deviation to the ones trained with.

**Visualizing trained model**
To visualize a trained model on the WIDER FACE validation set run the notebook [visualize_trained_model_predictions](evaluation/jupyter_notebooks/visualize_trained_model_predictions.ipynb).

**WIDER FACE dataset evaluation**
If you haven't done already, download the [WIDER FACE](http://shuoyang1213.me/WIDERFACE/) dataset and extract to datasets/WIDER_Face.

Download the [pre-trained model](https://drive.google.com/file/d/1OvnZ7OUQFg2bAgFADhT7UnCkSaXst10O/view?usp=sharing).

```
python3 evaluation/evaluate_wider.py \
--dataset_path datasets/WIDER_Face/WIDER_val/images/ \
--dataset_list datasets/WIDER_Face/wider_face_split/wider_face_val_bbx_gt.txt \
--pose_mean models/WIDER_train_pose_mean_v1.npy \
--pose_stddev models/WIDER_train_pose_stddev_v1.npy \
--pretrained_path models/img2pose_v1.pth \
--output_path results/WIDER_FACE/Val/
```

To check mAP and plot curves, download the [eval tools](http://shuoyang1213.me/WIDERFACE/) and point to results/WIDER_FACE/Val.

**AFLW2000-3D dataset evaluation**
Download the [AFLW2000-3D](http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/Database/AFLW2000-3D.zip) dataset and unzip to datasets/AFLW2000.

Download the [fine-tuned model](https://drive.google.com/file/d/1wSqPr9h1x_TOaxuN-Nu3OlTmhqnuf6rZ/view?usp=sharing).

Run the notebook [aflw_2000_3d_evaluation](./evaluation/jupyter_notebooks/aflw_2000_3d_evaluation.ipynb).

**BIWI dataset evaluation**
Download the [BIWI](http://data.vision.ee.ethz.ch/cvl/gfanelli/kinect_head_pose_db.tgz) dataset and unzip to datasets/BIWI.

Download the [fine-tuned model](https://drive.google.com/file/d/1wSqPr9h1x_TOaxuN-Nu3OlTmhqnuf6rZ/view?usp=sharing).

Run the notebook [biwi_evaluation](./evaluation/jupyter_notebooks/biwi_evaluation.ipynb).

**Testing on your own images**

Run the notebook [test_own_images](./047_img2pose_Intuition/evaluation/jupyter_notebooks/test_own_images.ipynb).

**Output customization**

For every face detected, the model outputs by default:
- Pose: r<sub>x</sub>, r<sub>y</sub>, r<sub>z</sub>, t<sub>x</sub>, t<sub>y</sub>, t<sub>z</sub>
- Projected bounding boxes: left, top, right, bottom
- Face scores: 0 to 1

Since the projected bounding box without expansion ends at the start of the forehead, we provide a way of expanding the forehead invidually, along with default x and y expansion. 

To customize the size of the projected bounding boxes, when creating the model change any of the bounding box expansion variables as shown below (a complete example can be seen at [visualize_trained_model_predictions](evaluation/jupyter_notebooks/visualize_trained_model_predictions.ipynb)).
```python
# how much to expand in width
bbox_x_factor = 1.1
# how much to expand in height
bbox_y_factor = 1.1
# how much to expand in the forehead
expand_forehead = 0.3

img2pose_model = img2poseModel(
    ...,    
    bbox_x_factor=bbox_x_factor,
    bbox_y_factor=bbox_y_factor,
    expand_forehead=expand_forehead,
)
```

**Align faces**
To detect and align faces, simply run the command below, passing the path to the images you want to detect and align and the path to save them.
```
python3 run_face_alignment.py \
--pose_mean models/WIDER_train_pose_mean_v1.npy \
--pose_stddev models/WIDER_train_pose_stddev_v1.npy \
--pretrained_path models/img2pose_v1.pth \
--images_path image_path_or_list \
--output_path path_to_save_aligned_faces
```

**Resources**
1. [Model Zoo](https://github.com/vitoralbiero/img2pose/wiki/Model-Zoo)

2. [Annotations](https://github.com/vitoralbiero/img2pose/wiki/Annotations)

3. [Data Zoo](https://github.com/vitoralbiero/img2pose/wiki/Data-Zoo)

Referred from [here](https://github.com/vitoralbiero/img2pose) directly.

* **Day 48 (02/17/2022)**: [Geometric Deep Learning Tutorials Part I](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/048_Geometric_Deep_Learning_Tutorials_I)
This folder contains the tutorials that I watched and implemented on Day 48th of 100 days of AI. I also referred to some of the papers, medium articles, and distill hub articles to improve my basics of Geometric Deep Learning.

* **Day 49 (02/18/2022)**: [Geometric Deep Learning Tutorials Part II](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/049_Geometric_Deep_Learning_Tutorials_II)
This was the follow-up for the Geometric Deep Learning that I did on Day 48th. Today I read few research papers from ICML for Geometric Deep Learning and Graph Representation Learning. 

* **Day 50 (02/19/2022)**: [Topic Modelling using LSI](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/050_Topic_Modelling_using_LSI)

* **Day 51 (02/20/2022)**: [Semantic Segmentation using Multimodal Learning Intuition](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/051_Semantic_Segmentation_using_Multimodal_Learning)

* **Day 52 (02/21/2022)**: [Visually Indicated Sound-Generation Intuition](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/052_Visually_Indicated_Sound_Generation)

* **Day 53 (02/22/2022)**: [Diverse and Specific Image Captioning Intuition](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/053_Diverse_and_Specific_Image_Captioning)

* **Day 54 (02/23/2022)**: [Brain Activity Classification and Regressive Analysis](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/054_Brain_activity_CAR)

* **Day 55 (02/24/2022)**: [Singular Value Decomposition applications in Image Processing](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/055_SVD_in_Computer_Vision)

* **Day 56 (02/25/2022)**: [Knowledge Distillation Introduction](ing-AI/tree/master/056_Knowledge_distillation_in_Pytorch_on_MNIST_Intuition)


**knowledge-distillation-pytorch**
* Exploring knowledge distillation of DNNs for efficient hardware solutions
* Author Credits: Haitong Li
* Dataset: CIFAR-10


**Features**
* A framework for exploring "shallow" and "deep" knowledge distillation (KD) experiments
* Hyperparameters defined by "params.json" universally (avoiding long argparser commands)
* Hyperparameter searching and result synthesizing (as a table)
* Progress bar, tensorboard support, and checkpoint saving/loading (utils.py)
* Pretrained teacher models available for download 


**Install**
* Install the dependencies (including Pytorch)
  ```
  pip install -r requirements.txt
  ```


**Organizatoin:**
* ./train.py: main entrance for train/eval with or without KD on CIFAR-10
* ./experiments/: json files for each experiment; dir for hypersearch
* ./model/: teacher and student DNNs, knowledge distillation (KD) loss defination, dataloader 


**Key notes about usage for your experiments:**

* Download the zip file for pretrained teacher model checkpoints from this [Box folder](https://stanford.box.com/s/5lwrieh9g1upju0iz9ru93m9d7uo3sox)
* Simply move the unzipped subfolders into 'knowledge-distillation-pytorch/experiments/' (replacing the existing ones if necessary; follow the default path naming)
* Call train.py to start training 5-layer CNN with ResNet-18's dark knowledge, or training ResNet-18 with state-of-the-art deeper models distilled
* Use search_hyperparams.py for hypersearch
* Hyperparameters are defined in params.json files universally. Refer to the header of search_hyperparams.py for details


**Train (dataset: CIFAR-10)**

Note: all the hyperparameters can be found and modified in 'params.json' under 'model_dir'

-- Train a 5-layer CNN with knowledge distilled from a pre-trained ResNet-18 model
```
python train.py --model_dir experiments/cnn_distill
```

-- Train a ResNet-18 model with knowledge distilled from a pre-trained ResNext-29 teacher
```
python train.py --model_dir experiments/resnet18_distill/resnext_teacher
```

-- Hyperparameter search for a specified experiment ('parent_dir/params.json')
```
python search_hyperparams.py --parent_dir experiments/cnn_distill_alpha_temp
```

--Synthesize results of the recent hypersearch experiments
```
python synthesize_results.py --parent_dir experiments/cnn_distill_alpha_temp
```

**Results: "Shallow" and "Deep" Distillation**

Quick takeaways (more details to be added):

* Knowledge distillation provides regularization for both shallow DNNs and state-of-the-art DNNs
* Having unlabeled or partial dataset can benefit from dark knowledge of teacher models


-**Knowledge distillation from ResNet-18 to 5-layer CNN**

| Model                   | Dropout = 0.5      |  No Dropout        | 
| :------------------:    | :----------------: | :-----------------:|
| 5-layer CNN             | 83.51%             |  84.74%            | 
| 5-layer CNN w/ ResNet18 | 84.49%             |  **85.69%**        |

-**Knowledge distillation from deeper models to ResNet-18**

|Model                      |  Test Accuracy|
|:--------:                 |   :---------: |
|Baseline ResNet-18         | 94.175%       |
|+ KD WideResNet-28-10      | 94.333%       |
|+ KD PreResNet-110         | 94.531%       |
|+ KD DenseNet-100          | 94.729%       |
|+ KD ResNext-29-8          | **94.788%**   |

**References**

H. Li, "Exploring knowledge distillation of Deep neural nets for efficient hardware solutions," [CS230 Report](http://cs230.stanford.edu/files_winter_2018/projects/6940224.pdf), 2018

Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. "Distilling the knowledge in a neural network." arXiv preprint arXiv:1503.02531 (2015).

Romero, A., Ballas, N., Kahou, S. E., Chassang, A., Gatta, C., & Bengio, Y. (2014). Fitnets: Hints for thin deep nets. arXiv preprint arXiv:1412.6550.

https://github.com/cs230-stanford/cs230-stanford.github.io

https://github.com/bearpaw/pytorch-classification


* **Day 57 (02/26/2022)**: [Named Entity Recognition and Slot Filling]()

* **Day 58 (02/27/2022)**: [Federated Learning]()

* **Day 59 (02/28/2022)**: [Deep Learning compilation and how does it work?]()

* **Day 60 (03/01/2022)**: []()

* **Day 61 (03/02/2022)**: []()

* **Day 62 (03/03/2022)**: [LiDAR and 3D Computer Vision](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/062_LIDAR_and_3D_Computer_Vision/Papers%2BReadings)

* **Day 63 (03/04/2022)**: []()

* **Day 64 (03/05/2022)**: []()

* **Day 65 (03/06/2022)**: []()

* **Day 66 (03/07/2022)**: [Face Frontalization]()

* **Day 67 (03/08/2022)**: [SWIN Transformer Intuition]()

* **Day 68 (03/09/2022)**: [TransDepth Intuition]()

* **Day 69 (03/10/2022)**: [TansPose Intuition]()

* **Day 70 (03/11/2022)**: [Scene Understanding]()
* 


<!-- * **Day 32 (02/01/2022)**: [Adversarial Attacks in Natural Language Processing](https://github.com/AnshMittal1811/MachineLearning-AI/tree/master/032_Adversarial_Learning_in_Natural_Language_Processing_I)
* **Day 33 (02/05/2022)**: [Adversarial Attacks in Natural Language Processing]()
* **Day 34 (02/03/2022)**: [Adversarial Learning in Natural Language Processing Part I]()
* **Day 35 (02/04/2022)**: [Adversarial Learning in Natural Language Processing Part II]()
 -->
<!-- * **Day 31 (01/22/2022)**: [News Text Summarization using Transformers]()
 -->
 
 <!--[StyleGANs]()-->
 <!---* **Day 100** (04/10/2022)**: DINO and PAWS implementation for GeoSpatial Imagery--->
